{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmtpp import rmtpp\n",
    "from hrmtpp import hrmtpp\n",
    "from utils_ import generate_mpp\n",
    "from trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, data = None, val_data=None, lr= 1e-3, epoch = 500, batch_size = 100):\n",
    "    if data == None:\n",
    "        data, val_data = generate_mpp()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch_number in range(epoch):\n",
    "        train(model, epoch_number, data, optimizer, batch_size, val_data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = hrmtpp().to(device)\n",
    "    data, _ = generate_mpp(num_sample=200)\n",
    "    val_data, _ = generate_mpp(num_sample = 150)\n",
    "    trainer(model, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, NLL Loss: 10472282.56, Val Loss: 198583808.0, Time took: 0.2938199043273926\n",
      "Train loss Meta Info:  [1426.3246875, 3671758.72, 0.0765150785446167]\n",
      "Val Loss Meta Info:  [4287.6678125, 198579548.16, 0.2402200508117676]\n",
      "\n",
      "Epoch: 1, NLL Loss: 10679576.32, Val Loss: 212252624.0, Time took: 0.26996350288391113\n",
      "Train loss Meta Info:  [1426.21015625, 3674614.4, 0.07890589714050293]\n",
      "Val Loss Meta Info:  [4284.678125, 212248330.24, 0.25164142608642576]\n",
      "\n",
      "Epoch: 2, NLL Loss: 10171414.72, Val Loss: 181571968.0, Time took: 0.3584580421447754\n",
      "Train loss Meta Info:  [1425.9325, 3416398.72, 0.08255096435546876]\n",
      "Val Loss Meta Info:  [4284.9590625, 181567692.8, 0.2626958847045898]\n",
      "\n",
      "Epoch: 3, NLL Loss: 9000747.2, Val Loss: 180838544.0, Time took: 0.2894246578216553\n",
      "Train loss Meta Info:  [1425.5434375, 2837686.4, 0.08611777305603027]\n",
      "Val Loss Meta Info:  [4283.5553125, 180834242.56, 0.27338180541992185]\n",
      "\n",
      "Epoch: 4, NLL Loss: 8792030.08, Val Loss: 174517040.0, Time took: 0.2690753936767578\n",
      "Train loss Meta Info:  [1425.5646875, 3062555.84, 0.08955781936645507]\n",
      "Val Loss Meta Info:  [4283.5915625, 174512742.4, 0.2869329833984375]\n",
      "\n",
      "Epoch: 5, NLL Loss: 7846242.88, Val Loss: 154436432.0, Time took: 0.27336716651916504\n",
      "Train loss Meta Info:  [1424.745625, 2794016.96, 0.09394754409790039]\n",
      "Val Loss Meta Info:  [4282.531875, 154432133.12, 0.3042026710510254]\n",
      "\n",
      "Epoch: 6, NLL Loss: 7168022.24, Val Loss: 141854704.0, Time took: 0.2896878719329834\n",
      "Train loss Meta Info:  [1425.13421875, 2559476.96, 0.09953855514526368]\n",
      "Val Loss Meta Info:  [4282.38375, 141850419.2, 0.3241778564453125]\n",
      "\n",
      "Epoch: 7, NLL Loss: 7506049.28, Val Loss: 138247744.0, Time took: 0.2793769836425781\n",
      "Train loss Meta Info:  [1424.394375, 2698379.2, 0.1059767723083496]\n",
      "Val Loss Meta Info:  [4282.510625, 138243450.88, 0.34874195098876953]\n",
      "\n",
      "Epoch: 8, NLL Loss: 6530249.28, Val Loss: 119827688.0, Time took: 0.3164634704589844\n",
      "Train loss Meta Info:  [1424.790625, 2550810.24, 0.1139326286315918]\n",
      "Val Loss Meta Info:  [4282.8015625, 119823400.96, 0.3804372406005859]\n",
      "\n",
      "Epoch: 9, NLL Loss: 6145994.24, Val Loss: 138202240.0, Time took: 0.3425285816192627\n",
      "Train loss Meta Info:  [1424.99375, 2311625.28, 0.12422344207763672]\n",
      "Val Loss Meta Info:  [4282.390625, 138197954.56, 0.4187564468383789]\n",
      "\n",
      "Epoch: 10, NLL Loss: 5139353.28, Val Loss: 103167720.0, Time took: 0.2535247802734375\n",
      "Train loss Meta Info:  [1424.869375, 1777032.96, 0.13669468879699706]\n",
      "Val Loss Meta Info:  [4282.44375, 103163432.96, 0.4637982177734375]\n",
      "\n",
      "Epoch: 11, NLL Loss: 6068023.84, Val Loss: 91937128.0, Time took: 0.2532539367675781\n",
      "Train loss Meta Info:  [1425.445625, 2031288.32, 0.15135730743408204]\n",
      "Val Loss Meta Info:  [4284.604375, 91932835.84, 0.5170652770996094]\n",
      "\n",
      "Epoch: 12, NLL Loss: 5394376.32, Val Loss: 97331656.0, Time took: 0.26644110679626465\n",
      "Train loss Meta Info:  [1425.02828125, 1724931.84, 0.16866512298583985]\n",
      "Val Loss Meta Info:  [4285.0940625, 97327360.0, 0.5770793914794922]\n",
      "\n",
      "Epoch: 13, NLL Loss: 4872106.08, Val Loss: 70729504.0, Time took: 0.36005139350891113\n",
      "Train loss Meta Info:  [1425.48453125, 1420671.2, 0.18817676544189454]\n",
      "Val Loss Meta Info:  [4285.12625, 70725222.4, 0.6495631408691406]\n",
      "\n",
      "Epoch: 14, NLL Loss: 4505811.52, Val Loss: 77201328.0, Time took: 0.3803098201751709\n",
      "Train loss Meta Info:  [1425.54734375, 1631646.08, 0.21180917739868163]\n",
      "Val Loss Meta Info:  [4285.0659375, 77197040.64, 0.7381756591796875]\n",
      "\n",
      "Epoch: 15, NLL Loss: 4072503.44, Val Loss: 60914888.0, Time took: 0.37365078926086426\n",
      "Train loss Meta Info:  [1425.51296875, 1316108.56, 0.24077789306640626]\n",
      "Val Loss Meta Info:  [4285.940625, 60910597.12, 0.8462895202636719]\n",
      "\n",
      "Epoch: 16, NLL Loss: 3432725.52, Val Loss: 74922712.0, Time took: 0.3529958724975586\n",
      "Train loss Meta Info:  [1426.1328125, 995758.72, 0.2760660362243652]\n",
      "Val Loss Meta Info:  [4286.040625, 74918440.96, 0.9755937957763672]\n",
      "\n",
      "Epoch: 17, NLL Loss: 3389126.0, Val Loss: 65364928.0, Time took: 0.3708057403564453\n",
      "Train loss Meta Info:  [1426.099375, 1246197.12, 0.31820905685424805]\n",
      "Val Loss Meta Info:  [4286.9965625, 65360645.12, 1.1334200286865235]\n",
      "\n",
      "Epoch: 18, NLL Loss: 3698979.44, Val Loss: 51536264.0, Time took: 0.37054896354675293\n",
      "Train loss Meta Info:  [1426.07125, 987267.12, 0.3697159957885742]\n",
      "Val Loss Meta Info:  [4287.41625, 51531975.68, 1.3236477661132813]\n",
      "\n",
      "Epoch: 19, NLL Loss: 2918525.36, Val Loss: 52391396.0, Time took: 0.32648491859436035\n",
      "Train loss Meta Info:  [1425.5665625, 1147154.88, 0.4318564987182617]\n",
      "Val Loss Meta Info:  [4287.7375, 52387118.08, 1.5529904174804687]\n",
      "\n",
      "Epoch: 20, NLL Loss: 2002019.52, Val Loss: 23324902.0, Time took: 0.30411338806152344\n",
      "Train loss Meta Info:  [1425.94125, 637852.52, 0.5067243957519532]\n",
      "Val Loss Meta Info:  [4288.4225, 23320611.84, 1.8254766845703125]\n",
      "\n",
      "Epoch: 21, NLL Loss: 1969160.32, Val Loss: 39412692.0, Time took: 0.3161804676055908\n",
      "Train loss Meta Info:  [1425.120625, 615717.28, 0.5958116149902344]\n",
      "Val Loss Meta Info:  [4285.3475, 39408404.48, 2.146916809082031]\n",
      "\n",
      "Epoch: 22, NLL Loss: 1929609.28, Val Loss: 26967278.0, Time took: 0.2805674076080322\n",
      "Train loss Meta Info:  [1426.25, 695627.92, 0.7010043334960937]\n",
      "Val Loss Meta Info:  [4286.923125, 26962995.2, 2.530782470703125]\n",
      "\n",
      "Epoch: 23, NLL Loss: 1671075.72, Val Loss: 28983516.0, Time took: 0.30187273025512695\n",
      "Train loss Meta Info:  [1425.094375, 643605.8, 0.8267233276367187]\n",
      "Val Loss Meta Info:  [4284.0728125, 28979230.72, 2.98601318359375]\n",
      "\n",
      "Epoch: 24, NLL Loss: 1024111.04, Val Loss: 21800038.0, Time took: 0.2998363971710205\n",
      "Train loss Meta Info:  [1424.9425, 391876.48, 0.9759043884277344]\n",
      "Val Loss Meta Info:  [4286.38125, 21795752.96, 3.517270812988281]\n",
      "\n",
      "Epoch: 25, NLL Loss: 1274889.4, Val Loss: 22200836.0, Time took: 0.2976071834564209\n",
      "Train loss Meta Info:  [1424.58125, 377601.72, 1.1500847625732422]\n",
      "Val Loss Meta Info:  [4285.82, 22196544.0, 4.144032592773438]\n",
      "\n",
      "Epoch: 26, NLL Loss: 763894.76, Val Loss: 16598784.0, Time took: 0.33160972595214844\n",
      "Train loss Meta Info:  [1425.475625, 271377.98, 1.355638427734375]\n",
      "Val Loss Meta Info:  [4282.989375, 16594496.0, 4.875524291992187]\n",
      "\n",
      "Epoch: 27, NLL Loss: 951453.52, Val Loss: 12340494.0, Time took: 0.36521267890930176\n",
      "Train loss Meta Info:  [1424.211875, 260817.78, 1.5956161499023438]\n",
      "Val Loss Meta Info:  [4281.6953125, 12336208.64, 5.7299261474609375]\n",
      "\n",
      "Epoch: 28, NLL Loss: 739778.46, Val Loss: 18209164.0, Time took: 0.3264586925506592\n",
      "Train loss Meta Info:  [1424.2340625, 257193.96, 1.8760208129882812]\n",
      "Val Loss Meta Info:  [4281.61625, 18204875.52, 6.718095703125]\n",
      "\n",
      "Epoch: 29, NLL Loss: 802982.02, Val Loss: 7082983.0, Time took: 0.31899309158325195\n",
      "Train loss Meta Info:  [1424.1684375, 197995.32, 2.2003793334960937]\n",
      "Val Loss Meta Info:  [4282.850625, 7078693.12, 7.86299072265625]\n",
      "\n",
      "Epoch: 30, NLL Loss: 310630.4, Val Loss: 7601718.0, Time took: 0.3101820945739746\n",
      "Train loss Meta Info:  [1424.60484375, 151898.19, 2.5765472412109376]\n",
      "Val Loss Meta Info:  [4282.988125, 7597427.2, 9.151923828125]\n",
      "\n",
      "Epoch: 31, NLL Loss: 462421.065, Val Loss: 9872856.0, Time took: 0.3244473934173584\n",
      "Train loss Meta Info:  [1424.26546875, 74455.965, 3.0004266357421874]\n",
      "Val Loss Meta Info:  [4284.3940625, 9868561.28, 10.6207568359375]\n",
      "\n",
      "Epoch: 32, NLL Loss: 330206.52, Val Loss: 6021086.0, Time took: 0.30298662185668945\n",
      "Train loss Meta Info:  [1425.09484375, 131173.94, 3.483867492675781]\n",
      "Val Loss Meta Info:  [4283.915625, 6016791.04, 12.2811767578125]\n",
      "\n",
      "Epoch: 33, NLL Loss: 346305.345, Val Loss: 5431547.5, Time took: 0.3039436340332031\n",
      "Train loss Meta Info:  [1424.39234375, 57032.26, 4.030665893554687]\n",
      "Val Loss Meta Info:  [4283.7003125, 5427249.92, 14.13087646484375]\n",
      "\n",
      "Epoch: 34, NLL Loss: 259486.925, Val Loss: 2846029.0, Time took: 0.29564714431762695\n",
      "Train loss Meta Info:  [1424.5909375, 76384.905, 4.640718383789062]\n",
      "Val Loss Meta Info:  [4285.409375, 2841726.72, 16.186756591796875]\n",
      "\n",
      "Epoch: 35, NLL Loss: 131028.98, Val Loss: 1711092.875, Time took: 0.3665316104888916\n",
      "Train loss Meta Info:  [1424.1975, 48641.53, 5.319428100585937]\n",
      "Val Loss Meta Info:  [4283.666875, 1706790.88, 18.4201904296875]\n",
      "\n",
      "Epoch: 36, NLL Loss: 193702.0825, Val Loss: 3126923.5, Time took: 0.30176734924316406\n",
      "Train loss Meta Info:  [1424.128125, 29913.2775, 6.057168579101562]\n",
      "Val Loss Meta Info:  [4281.571875, 3122620.8, 20.87289306640625]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, NLL Loss: 117660.105, Val Loss: 1286691.5, Time took: 0.3420841693878174\n",
      "Train loss Meta Info:  [1424.3790625, 43327.165, 6.868051147460937]\n",
      "Val Loss Meta Info:  [4280.893125, 1282387.2, 23.51146484375]\n",
      "\n",
      "Epoch: 38, NLL Loss: 108020.21, Val Loss: 721314.0, Time took: 0.2928292751312256\n",
      "Train loss Meta Info:  [1423.86109375, 35573.48, 7.74058837890625]\n",
      "Val Loss Meta Info:  [4282.875625, 717004.96, 26.33405517578125]\n",
      "\n",
      "Epoch: 39, NLL Loss: 50434.1675, Val Loss: 1618475.75, Time took: 0.2817368507385254\n",
      "Train loss Meta Info:  [1424.29796875, 22301.6, 8.674326171875]\n",
      "Val Loss Meta Info:  [4281.008125, 1614164.96, 29.2595654296875]\n",
      "\n",
      "Epoch: 40, NLL Loss: 98197.815, Val Loss: 1414080.625, Time took: 0.3331162929534912\n",
      "Train loss Meta Info:  [1424.45578125, 49396.33, 9.642974853515625]\n",
      "Val Loss Meta Info:  [4283.203125, 1409764.96, 32.3709130859375]\n",
      "\n",
      "Epoch: 41, NLL Loss: 112004.07375, Val Loss: 1402988.5, Time took: 0.30349111557006836\n",
      "Train loss Meta Info:  [1425.314375, 17083.1375, 10.67330322265625]\n",
      "Val Loss Meta Info:  [4283.84875, 1398669.12, 35.68919921875]\n",
      "\n",
      "Epoch: 42, NLL Loss: 44712.2925, Val Loss: 707155.1875, Time took: 0.29842209815979004\n",
      "Train loss Meta Info:  [1424.790625, 13763.63125, 11.77253662109375]\n",
      "Val Loss Meta Info:  [4284.881875, 702831.28, 39.112451171875]\n",
      "\n",
      "Epoch: 43, NLL Loss: 40529.84, Val Loss: 586039.8125, Time took: 0.29907727241516113\n",
      "Train loss Meta Info:  [1426.07609375, 18624.6775, 12.90699951171875]\n",
      "Val Loss Meta Info:  [4282.839375, 581714.4, 42.654794921875]\n",
      "\n",
      "Epoch: 44, NLL Loss: 12956.180625, Val Loss: 376226.28125, Time took: 0.3239262104034424\n",
      "Train loss Meta Info:  [1425.0775, 4541.0215625, 14.08128662109375]\n",
      "Val Loss Meta Info:  [4283.5534375, 371896.52, 46.19375]\n",
      "\n",
      "Epoch: 45, NLL Loss: 26299.96625, Val Loss: 382133.5625, Time took: 0.2744886875152588\n",
      "Train loss Meta Info:  [1424.48203125, 4783.2146875, 15.25487060546875]\n",
      "Val Loss Meta Info:  [4281.796875, 377802.0, 49.784521484375]\n",
      "\n",
      "Epoch: 46, NLL Loss: 23249.31625, Val Loss: 84187.1171875, Time took: 0.3081631660461426\n",
      "Train loss Meta Info:  [1424.1978125, 10700.26125, 16.4460107421875]\n",
      "Val Loss Meta Info:  [4281.825625, 79851.88, 53.40537109375]\n",
      "\n",
      "Epoch: 47, NLL Loss: 11244.4559375, Val Loss: 135486.953125, Time took: 0.2845735549926758\n",
      "Train loss Meta Info:  [1424.3409375, 4997.41625, 17.64750244140625]\n",
      "Val Loss Meta Info:  [4284.046875, 131145.91, 56.984951171875]\n",
      "\n",
      "Epoch: 48, NLL Loss: 11240.4834375, Val Loss: 71554.8828125, Time took: 0.27599000930786133\n",
      "Train loss Meta Info:  [1425.00109375, 2873.7034375, 18.835714111328127]\n",
      "Val Loss Meta Info:  [4283.8925, 67210.475, 60.520908203125]\n",
      "\n",
      "Epoch: 49, NLL Loss: 10498.8209375, Val Loss: 68944.890625, Time took: 0.33641791343688965\n",
      "Train loss Meta Info:  [1425.3221875, 2481.9578125, 20.009752197265627]\n",
      "Val Loss Meta Info:  [4284.855625, 64596.05, 63.985517578125]\n",
      "\n",
      "Epoch: 50, NLL Loss: 8800.9128125, Val Loss: 119529.15625, Time took: 0.3089172840118408\n",
      "Train loss Meta Info:  [1424.84625, 3238.4290625, 21.160390625]\n",
      "Val Loss Meta Info:  [4285.48375, 115176.32, 67.3568701171875]\n",
      "\n",
      "Epoch: 51, NLL Loss: 6266.104375, Val Loss: 153684.0, Time took: 0.2863349914550781\n",
      "Train loss Meta Info:  [1425.32390625, 2468.61359375, 22.2802783203125]\n",
      "Val Loss Meta Info:  [4284.0425, 149329.35, 70.6051513671875]\n",
      "\n",
      "Epoch: 52, NLL Loss: 6452.6325, Val Loss: 45121.50390625, Time took: 0.3135871887207031\n",
      "Train loss Meta Info:  [1424.7640625, 1490.9315625, 23.3595068359375]\n",
      "Val Loss Meta Info:  [4285.015, 40762.7525, 73.73390625]\n",
      "\n",
      "Epoch: 53, NLL Loss: 8614.77375, Val Loss: 198953.4375, Time took: 0.31424975395202637\n",
      "Train loss Meta Info:  [1425.2403125, 3270.941875, 24.39919677734375]\n",
      "Val Loss Meta Info:  [4286.8053125, 194589.82, 76.7745703125]\n",
      "\n",
      "Epoch: 54, NLL Loss: 8015.405625, Val Loss: 16403.755859375, Time took: 0.32018113136291504\n",
      "Train loss Meta Info:  [1425.26046875, 1357.48453125, 25.40978515625]\n",
      "Val Loss Meta Info:  [4284.31375, 12039.72625, 79.7156640625]\n",
      "\n",
      "Epoch: 55, NLL Loss: 8743.038125, Val Loss: 32330.126953125, Time took: 0.2979605197906494\n",
      "Train loss Meta Info:  [1424.25625, 1424.6296875, 26.387421875]\n",
      "Val Loss Meta Info:  [4286.89125, 27960.6625, 82.5740234375]\n",
      "\n",
      "Epoch: 56, NLL Loss: 16124.5178125, Val Loss: 81407.7890625, Time took: 0.30731940269470215\n",
      "Train loss Meta Info:  [1425.2484375, 1671.9640625, 27.33771240234375]\n",
      "Val Loss Meta Info:  [4285.1671875, 77037.18, 85.45197265625]\n",
      "\n",
      "Epoch: 57, NLL Loss: 6764.39625, Val Loss: 129112.140625, Time took: 0.24109959602355957\n",
      "Train loss Meta Info:  [1425.09078125, 1250.727734375, 28.2946337890625]\n",
      "Val Loss Meta Info:  [4285.636875, 124738.32, 88.197529296875]\n",
      "\n",
      "Epoch: 58, NLL Loss: 4757.87265625, Val Loss: 58395.27734375, Time took: 0.23726701736450195\n",
      "Train loss Meta Info:  [1425.38203125, 973.045625, 29.20720703125]\n",
      "Val Loss Meta Info:  [4284.3796875, 54020.065, 90.841025390625]\n",
      "\n",
      "Epoch: 59, NLL Loss: 7484.329375, Val Loss: 58318.3671875, Time took: 0.2780873775482178\n",
      "Train loss Meta Info:  [1425.1378125, 948.568125, 30.08667236328125]\n",
      "Val Loss Meta Info:  [4284.36, 53940.635, 93.3705078125]\n",
      "\n",
      "Epoch: 60, NLL Loss: 4134.595, Val Loss: 34553.05078125, Time took: 0.2992208003997803\n",
      "Train loss Meta Info:  [1425.480625, 540.7902734375, 30.92783203125]\n",
      "Val Loss Meta Info:  [4286.1334375, 30171.1725, 95.744072265625]\n",
      "\n",
      "Epoch: 61, NLL Loss: 4564.42125, Val Loss: 13735.361328125, Time took: 0.3069620132446289\n",
      "Train loss Meta Info:  [1425.36234375, 648.7278515625, 31.71709228515625]\n",
      "Val Loss Meta Info:  [4284.6421875, 9352.7375, 97.97951171875]\n",
      "\n",
      "Epoch: 62, NLL Loss: 6077.0934375, Val Loss: 24153.189453125, Time took: 0.2844374179840088\n",
      "Train loss Meta Info:  [1425.384375, 1231.5475, 32.460498046875]\n",
      "Val Loss Meta Info:  [4284.99375, 19768.0875, 100.11150390625]\n",
      "\n",
      "Epoch: 63, NLL Loss: 5707.925625, Val Loss: 15897.0693359375, Time took: 0.3034248352050781\n",
      "Train loss Meta Info:  [1423.94296875, 903.3646875, 33.16947998046875]\n",
      "Val Loss Meta Info:  [4283.7390625, 11511.19375, 102.13923828125]\n",
      "\n",
      "Epoch: 64, NLL Loss: 5794.8625, Val Loss: 9281.6669921875, Time took: 0.31055688858032227\n",
      "Train loss Meta Info:  [1424.69828125, 1045.87453125, 33.84374267578125]\n",
      "Val Loss Meta Info:  [4281.89125, 4895.695625, 104.07998046875]\n",
      "\n",
      "Epoch: 65, NLL Loss: 4503.82578125, Val Loss: 19792.25390625, Time took: 0.3060438632965088\n",
      "Train loss Meta Info:  [1425.519375, 741.07453125, 34.488994140625]\n",
      "Val Loss Meta Info:  [4284.260625, 15402.09125, 105.89814453125]\n",
      "\n",
      "Epoch: 66, NLL Loss: 4460.14625, Val Loss: 23598.064453125, Time took: 0.28517723083496094\n",
      "Train loss Meta Info:  [1424.668125, 644.94765625, 35.09341552734375]\n",
      "Val Loss Meta Info:  [4282.306875, 19208.155, 107.60162109375]\n",
      "\n",
      "Epoch: 67, NLL Loss: 4342.7053125, Val Loss: 21293.01953125, Time took: 0.3126404285430908\n",
      "Train loss Meta Info:  [1424.86640625, 825.20625, 35.65964111328125]\n",
      "Val Loss Meta Info:  [4282.766875, 16901.0625, 109.190625]\n",
      "\n",
      "Epoch: 68, NLL Loss: 4735.10046875, Val Loss: 33621.1953125, Time took: 0.3096742630004883\n",
      "Train loss Meta Info:  [1424.8725, 693.05875, 36.187744140625]\n",
      "Val Loss Meta Info:  [4284.958125, 29225.555, 110.68806640625]\n",
      "\n",
      "Epoch: 69, NLL Loss: 3934.1859375, Val Loss: 10745.3759765625, Time took: 0.32241034507751465\n",
      "Train loss Meta Info:  [1424.9209375, 569.131953125, 36.68532958984375]\n",
      "Val Loss Meta Info:  [4282.215625, 6351.09, 112.069794921875]\n",
      "\n",
      "Epoch: 70, NLL Loss: 4877.8484375, Val Loss: 21587.798828125, Time took: 0.26115942001342773\n",
      "Train loss Meta Info:  [1424.39640625, 892.424140625, 37.14438720703125]\n",
      "Val Loss Meta Info:  [4281.27375, 17193.14625, 113.37896484375]\n",
      "\n",
      "Epoch: 71, NLL Loss: 4691.93671875, Val Loss: 19151.9765625, Time took: 0.28078389167785645\n",
      "Train loss Meta Info:  [1424.83265625, 913.52234375, 37.57925048828125]\n",
      "Val Loss Meta Info:  [4281.831875, 14755.5325, 114.61416015625]\n",
      "\n",
      "Epoch: 72, NLL Loss: 4801.48625, Val Loss: 12336.9462890625, Time took: 0.33116602897644043\n",
      "Train loss Meta Info:  [1424.2546875, 675.02984375, 37.989453125]\n",
      "Val Loss Meta Info:  [4279.135, 7942.02625, 115.786171875]\n",
      "\n",
      "Epoch: 73, NLL Loss: 4611.13453125, Val Loss: 13594.185546875, Time took: 0.3362891674041748\n",
      "Train loss Meta Info:  [1424.1459375, 668.43484375, 38.37857177734375]\n",
      "Val Loss Meta Info:  [4282.6596875, 9194.63375, 116.893671875]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, NLL Loss: 4281.1159375, Val Loss: 20158.224609375, Time took: 0.34035444259643555\n",
      "Train loss Meta Info:  [1424.0834375, 567.5715625, 38.746181640625]\n",
      "Val Loss Meta Info:  [4281.8940625, 15758.40375, 117.92796875]\n",
      "\n",
      "Epoch: 75, NLL Loss: 5641.46875, Val Loss: 15896.3359375, Time took: 0.35614514350891113\n",
      "Train loss Meta Info:  [1424.6459375, 760.6328125, 39.0893896484375]\n",
      "Val Loss Meta Info:  [4281.39375, 11496.00125, 118.939912109375]\n",
      "\n",
      "Epoch: 76, NLL Loss: 3981.9696875, Val Loss: 12515.46484375, Time took: 0.3647449016571045\n",
      "Train loss Meta Info:  [1424.676875, 473.887109375, 39.425078125]\n",
      "Val Loss Meta Info:  [4282.183125, 8113.4075, 119.8749609375]\n",
      "\n",
      "Epoch: 77, NLL Loss: 5162.59515625, Val Loss: 18010.958984375, Time took: 0.3499288558959961\n",
      "Train loss Meta Info:  [1422.81703125, 1784.50125, 39.735146484375]\n",
      "Val Loss Meta Info:  [4278.65875, 13611.53625, 120.7693359375]\n",
      "\n",
      "Epoch: 78, NLL Loss: 4314.039375, Val Loss: 26828.18359375, Time took: 0.40427327156066895\n",
      "Train loss Meta Info:  [1423.40734375, 655.246796875, 40.0316259765625]\n",
      "Val Loss Meta Info:  [4281.371875, 22425.21, 121.608740234375]\n",
      "\n",
      "Epoch: 79, NLL Loss: 4292.924375, Val Loss: 23139.47265625, Time took: 0.32758140563964844\n",
      "Train loss Meta Info:  [1423.756875, 702.30375, 40.30977783203125]\n",
      "Val Loss Meta Info:  [4280.24, 18736.83625, 122.398583984375]\n",
      "\n",
      "Epoch: 80, NLL Loss: 4378.8859375, Val Loss: 11431.765625, Time took: 0.31552743911743164\n",
      "Train loss Meta Info:  [1423.5696875, 871.746484375, 40.571416015625]\n",
      "Val Loss Meta Info:  [4280.4075, 7028.2175, 123.1423046875]\n",
      "\n",
      "Epoch: 81, NLL Loss: 4465.5953125, Val Loss: 9815.84765625, Time took: 0.2919156551361084\n",
      "Train loss Meta Info:  [1423.5965625, 748.401875, 40.81767822265625]\n",
      "Val Loss Meta Info:  [4278.494375, 5413.50125, 123.851640625]\n",
      "\n",
      "Epoch: 82, NLL Loss: 4163.02765625, Val Loss: 17531.705078125, Time took: 0.32964301109313965\n",
      "Train loss Meta Info:  [1423.708125, 516.79359375, 41.052431640625]\n",
      "Val Loss Meta Info:  [4280.169375, 13127.02, 124.51646484375]\n",
      "\n",
      "Epoch: 83, NLL Loss: 4110.665625, Val Loss: 12912.578125, Time took: 0.2936100959777832\n",
      "Train loss Meta Info:  [1422.18109375, 657.3734375, 41.2723974609375]\n",
      "Val Loss Meta Info:  [4278.440625, 8509.00875, 125.131669921875]\n",
      "\n",
      "Epoch: 84, NLL Loss: 4992.44203125, Val Loss: 10270.208984375, Time took: 0.35729241371154785\n",
      "Train loss Meta Info:  [1423.66265625, 541.7905078125, 41.475830078125]\n",
      "Val Loss Meta Info:  [4277.118125, 5867.343125, 125.748115234375]\n",
      "\n",
      "Epoch: 85, NLL Loss: 4501.7525, Val Loss: 13146.265625, Time took: 0.34653162956237793\n",
      "Train loss Meta Info:  [1422.891875, 543.81859375, 41.6795947265625]\n",
      "Val Loss Meta Info:  [4279.893125, 8740.02625, 126.34544921875]\n",
      "\n",
      "Epoch: 86, NLL Loss: 4079.11984375, Val Loss: 7569.248046875, Time took: 0.3546295166015625\n",
      "Train loss Meta Info:  [1422.078125, 572.381875, 41.87693359375]\n",
      "Val Loss Meta Info:  [4278.005625, 3164.340625, 126.90212890625]\n",
      "\n",
      "Epoch: 87, NLL Loss: 4257.42203125, Val Loss: 8066.7373046875, Time took: 0.4464268684387207\n",
      "Train loss Meta Info:  [1422.8803125, 521.3096875, 42.060751953125]\n",
      "Val Loss Meta Info:  [4277.653125, 3661.64875, 127.43564453125]\n",
      "\n",
      "Epoch: 88, NLL Loss: 6575.5675, Val Loss: 15251.130859375, Time took: 0.34553027153015137\n",
      "Train loss Meta Info:  [1423.5003125, 682.34703125, 42.236845703125]\n",
      "Val Loss Meta Info:  [4276.620625, 10846.49375, 128.017607421875]\n",
      "\n",
      "Epoch: 89, NLL Loss: 4585.12140625, Val Loss: 9597.9189453125, Time took: 0.3597853183746338\n",
      "Train loss Meta Info:  [1422.80828125, 472.4554296875, 42.428798828125]\n",
      "Val Loss Meta Info:  [4278.5728125, 5190.76125, 128.585048828125]\n",
      "\n",
      "Epoch: 90, NLL Loss: 4561.66921875, Val Loss: 7422.83154296875, Time took: 0.38886332511901855\n",
      "Train loss Meta Info:  [1422.654375, 474.21640625, 42.615849609375]\n",
      "Val Loss Meta Info:  [4276.7765625, 3016.92375, 129.13205078125]\n",
      "\n",
      "Epoch: 91, NLL Loss: 4205.72078125, Val Loss: 10065.4892578125, Time took: 0.33239126205444336\n",
      "Train loss Meta Info:  [1422.51890625, 549.6871875, 42.796044921875]\n",
      "Val Loss Meta Info:  [4278.6409375, 5657.199375, 129.6482421875]\n",
      "\n",
      "Epoch: 92, NLL Loss: 4193.61140625, Val Loss: 25589.634765625, Time took: 0.36720776557922363\n",
      "Train loss Meta Info:  [1422.90234375, 547.485859375, 42.965986328125]\n",
      "Val Loss Meta Info:  [4278.23625, 21181.26, 130.140693359375]\n",
      "\n",
      "Epoch: 93, NLL Loss: 4227.16953125, Val Loss: 43551.47265625, Time took: 0.3670022487640381\n",
      "Train loss Meta Info:  [1422.1625, 766.961015625, 43.128037109375]\n",
      "Val Loss Meta Info:  [4277.703125, 39143.16, 130.60626953125]\n",
      "\n",
      "Epoch: 94, NLL Loss: 4476.103125, Val Loss: 10274.8037109375, Time took: 0.3489100933074951\n",
      "Train loss Meta Info:  [1421.74796875, 519.38140625, 43.281162109375]\n",
      "Val Loss Meta Info:  [4276.653125, 5867.081875, 131.069541015625]\n",
      "\n",
      "Epoch: 95, NLL Loss: 5209.7409375, Val Loss: 10765.0771484375, Time took: 0.41206789016723633\n",
      "Train loss Meta Info:  [1422.20609375, 1009.97515625, 43.433447265625]\n",
      "Val Loss Meta Info:  [4276.5815625, 6356.945, 131.552509765625]\n",
      "\n",
      "Epoch: 96, NLL Loss: 4541.8775, Val Loss: 11135.1796875, Time took: 0.3350043296813965\n",
      "Train loss Meta Info:  [1422.538125, 519.03421875, 43.5921240234375]\n",
      "Val Loss Meta Info:  [4276.07375, 6727.07875, 132.026923828125]\n",
      "\n",
      "Epoch: 97, NLL Loss: 4847.60890625, Val Loss: 9415.5419921875, Time took: 0.3855595588684082\n",
      "Train loss Meta Info:  [1422.0709375, 504.437109375, 43.7478955078125]\n",
      "Val Loss Meta Info:  [4275.190625, 5007.8328125, 132.519609375]\n",
      "\n",
      "Epoch: 98, NLL Loss: 3981.500625, Val Loss: 8473.8125, Time took: 0.33092498779296875\n",
      "Train loss Meta Info:  [1421.520625, 510.4402734375, 43.909580078125]\n",
      "Val Loss Meta Info:  [4276.0221875, 4064.81875, 132.972236328125]\n",
      "\n",
      "Epoch: 99, NLL Loss: 4616.86671875, Val Loss: 17051.015625, Time took: 0.3350036144256592\n",
      "Train loss Meta Info:  [1421.84, 1146.624375, 44.0580078125]\n",
      "Val Loss Meta Info:  [4275.123125, 12642.46375, 133.428525390625]\n",
      "\n",
      "Epoch: 100, NLL Loss: 4114.32875, Val Loss: 10308.640625, Time took: 0.3511946201324463\n",
      "Train loss Meta Info:  [1422.221875, 477.463046875, 44.2076416015625]\n",
      "Val Loss Meta Info:  [4274.500625, 5900.27875, 133.861591796875]\n",
      "\n",
      "Epoch: 101, NLL Loss: 4026.60203125, Val Loss: 17756.09375, Time took: 0.3021566867828369\n",
      "Train loss Meta Info:  [1421.904375, 504.561640625, 44.3495751953125]\n",
      "Val Loss Meta Info:  [4274.774375, 13347.05, 134.26822265625]\n",
      "\n",
      "Epoch: 102, NLL Loss: 4410.33421875, Val Loss: 14699.2900390625, Time took: 0.28244590759277344\n",
      "Train loss Meta Info:  [1421.27875, 490.6365234375, 44.4827685546875]\n",
      "Val Loss Meta Info:  [4275.12125, 10289.496875, 134.67216796875]\n",
      "\n",
      "Epoch: 103, NLL Loss: 3861.15109375, Val Loss: 11613.46484375, Time took: 0.334367036819458\n",
      "Train loss Meta Info:  [1421.66640625, 460.022265625, 44.61501953125]\n",
      "Val Loss Meta Info:  [4273.8953125, 7204.5375, 135.03267578125]\n",
      "\n",
      "Epoch: 104, NLL Loss: 4538.51375, Val Loss: 6602.54345703125, Time took: 0.34070420265197754\n",
      "Train loss Meta Info:  [1422.0590625, 654.091328125, 44.73294921875]\n",
      "Val Loss Meta Info:  [4274.573125, 2192.5696875, 135.40044921875]\n",
      "\n",
      "Epoch: 105, NLL Loss: 4470.64984375, Val Loss: 12055.017578125, Time took: 0.33439064025878906\n",
      "Train loss Meta Info:  [1422.33046875, 601.917109375, 44.8532177734375]\n",
      "Val Loss Meta Info:  [4274.0046875, 7645.244375, 135.769140625]\n",
      "\n",
      "Epoch: 106, NLL Loss: 4668.51875, Val Loss: 7716.40625, Time took: 0.30532050132751465\n",
      "Train loss Meta Info:  [1421.0634375, 706.988671875, 44.97375]\n",
      "Val Loss Meta Info:  [4274.1678125, 3306.0740625, 136.164130859375]\n",
      "\n",
      "Epoch: 107, NLL Loss: 5435.2315625, Val Loss: 12239.8359375, Time took: 0.33603930473327637\n",
      "Train loss Meta Info:  [1422.0746875, 829.702890625, 45.102890625]\n",
      "Val Loss Meta Info:  [4274.206875, 7829.0175, 136.6127734375]\n",
      "\n",
      "Epoch: 108, NLL Loss: 5172.79171875, Val Loss: 10690.435546875, Time took: 0.33965086936950684\n",
      "Train loss Meta Info:  [1421.2234375, 1038.34984375, 45.2495947265625]\n",
      "Val Loss Meta Info:  [4273.350625, 6279.965, 137.120546875]\n",
      "\n",
      "Epoch: 109, NLL Loss: 4480.66421875, Val Loss: 10258.705078125, Time took: 0.36515235900878906\n",
      "Train loss Meta Info:  [1421.5715625, 521.489921875, 45.415693359375]\n",
      "Val Loss Meta Info:  [4273.623125, 5847.461875, 137.620107421875]\n",
      "\n",
      "Epoch: 110, NLL Loss: 4398.91625, Val Loss: 12195.6376953125, Time took: 0.32175326347351074\n",
      "Train loss Meta Info:  [1421.14875, 972.928203125, 45.579033203125]\n",
      "Val Loss Meta Info:  [4272.8825, 7784.64875, 138.106650390625]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111, NLL Loss: 4036.53890625, Val Loss: 9478.1875, Time took: 0.255260705947876\n",
      "Train loss Meta Info:  [1421.7346875, 531.271796875, 45.738125]\n",
      "Val Loss Meta Info:  [4272.9353125, 5066.6909375, 138.5617578125]\n",
      "\n",
      "Epoch: 112, NLL Loss: 3926.62203125, Val Loss: 7977.36083984375, Time took: 0.24991226196289062\n",
      "Train loss Meta Info:  [1421.094375, 467.525, 45.886865234375]\n",
      "Val Loss Meta Info:  [4273.435, 3564.9496875, 138.97650390625]\n",
      "\n",
      "Epoch: 113, NLL Loss: 4008.113125, Val Loss: 14866.2607421875, Time took: 0.28095340728759766\n",
      "Train loss Meta Info:  [1421.0790625, 469.8251953125, 46.022333984375]\n",
      "Val Loss Meta Info:  [4273.74625, 10453.154375, 139.3591015625]\n",
      "\n",
      "Epoch: 114, NLL Loss: 3979.744375, Val Loss: 15158.3330078125, Time took: 0.26180124282836914\n",
      "Train loss Meta Info:  [1420.96140625, 547.2446875, 46.14720703125]\n",
      "Val Loss Meta Info:  [4272.8715625, 10745.75375, 139.709306640625]\n",
      "\n",
      "Epoch: 115, NLL Loss: 4208.10578125, Val Loss: 9041.376953125, Time took: 0.244187593460083\n",
      "Train loss Meta Info:  [1421.086875, 547.695625, 46.261455078125]\n",
      "Val Loss Meta Info:  [4274.045, 4627.28625, 140.046328125]\n",
      "\n",
      "Epoch: 116, NLL Loss: 4121.39453125, Val Loss: 10251.796875, Time took: 0.24460387229919434\n",
      "Train loss Meta Info:  [1421.054375, 719.576484375, 46.3713525390625]\n",
      "Val Loss Meta Info:  [4272.24375, 5839.1875, 140.36662109375]\n",
      "\n",
      "Epoch: 117, NLL Loss: 4036.46015625, Val Loss: 13883.880859375, Time took: 0.24212193489074707\n",
      "Train loss Meta Info:  [1420.871875, 497.28734375, 46.47580078125]\n",
      "Val Loss Meta Info:  [4271.73875, 9471.4775, 140.663828125]\n",
      "\n",
      "Epoch: 118, NLL Loss: 4002.71140625, Val Loss: 12043.666015625, Time took: 0.24308204650878906\n",
      "Train loss Meta Info:  [1420.87953125, 510.09125, 46.5726416015625]\n",
      "Val Loss Meta Info:  [4272.724375, 7630.005, 140.93583984375]\n",
      "\n",
      "Epoch: 119, NLL Loss: 5015.89609375, Val Loss: 14053.9755859375, Time took: 0.24397969245910645\n",
      "Train loss Meta Info:  [1420.1375, 565.8305078125, 46.6612109375]\n",
      "Val Loss Meta Info:  [4271.691875, 9641.024375, 141.26029296875]\n",
      "\n",
      "Epoch: 120, NLL Loss: 5341.521875, Val Loss: 37104.12890625, Time took: 0.27408695220947266\n",
      "Train loss Meta Info:  [1420.8128125, 716.81328125, 46.7669189453125]\n",
      "Val Loss Meta Info:  [4272.6903125, 32689.785, 141.644921875]\n",
      "\n",
      "Epoch: 121, NLL Loss: 3926.5290625, Val Loss: 9570.3525390625, Time took: 0.3512916564941406\n",
      "Train loss Meta Info:  [1420.3634375, 491.106484375, 46.89234375]\n",
      "Val Loss Meta Info:  [4271.595625, 5156.7646875, 141.991123046875]\n",
      "\n",
      "Epoch: 122, NLL Loss: 4175.58921875, Val Loss: 7098.15869140625, Time took: 0.2611374855041504\n",
      "Train loss Meta Info:  [1420.8959375, 658.18890625, 47.005146484375]\n",
      "Val Loss Meta Info:  [4270.976875, 2684.8559375, 142.326103515625]\n",
      "\n",
      "Epoch: 123, NLL Loss: 4228.118125, Val Loss: 8421.6513671875, Time took: 0.37503719329833984\n",
      "Train loss Meta Info:  [1420.9528125, 762.65328125, 47.114296875]\n",
      "Val Loss Meta Info:  [4272.309375, 4006.685625, 142.65607421875]\n",
      "\n",
      "Epoch: 124, NLL Loss: 3971.33421875, Val Loss: 11542.125, Time took: 0.31073880195617676\n",
      "Train loss Meta Info:  [1420.69796875, 473.497890625, 47.221865234375]\n",
      "Val Loss Meta Info:  [4270.7925, 7128.375, 142.95576171875]\n",
      "\n",
      "Epoch: 125, NLL Loss: 4136.25, Val Loss: 15092.5732421875, Time took: 0.32434630393981934\n",
      "Train loss Meta Info:  [1420.63734375, 506.921171875, 47.3194921875]\n",
      "Val Loss Meta Info:  [4272.010625, 10677.31375, 143.2505859375]\n",
      "\n",
      "Epoch: 126, NLL Loss: 4559.436875, Val Loss: 11112.0244140625, Time took: 0.30876922607421875\n",
      "Train loss Meta Info:  [1420.715, 517.587734375, 47.4155224609375]\n",
      "Val Loss Meta Info:  [4271.774375, 6696.685, 143.56494140625]\n",
      "\n",
      "Epoch: 127, NLL Loss: 4029.0696875, Val Loss: 8646.2919921875, Time took: 0.31018924713134766\n",
      "Train loss Meta Info:  [1420.705625, 592.99171875, 47.517939453125]\n",
      "Val Loss Meta Info:  [4271.77125, 4230.6653125, 143.85541015625]\n",
      "\n",
      "Epoch: 128, NLL Loss: 4050.8709375, Val Loss: 14424.7060546875, Time took: 0.31555891036987305\n",
      "Train loss Meta Info:  [1420.68890625, 590.2598828125, 47.6125439453125]\n",
      "Val Loss Meta Info:  [4270.2046875, 10010.373125, 144.127421875]\n",
      "\n",
      "Epoch: 129, NLL Loss: 4107.10078125, Val Loss: 11700.53515625, Time took: 0.3148164749145508\n",
      "Train loss Meta Info:  [1420.6171875, 578.6620703125, 47.701103515625]\n",
      "Val Loss Meta Info:  [4270.52625, 7285.620625, 144.3870703125]\n",
      "\n",
      "Epoch: 130, NLL Loss: 4513.45984375, Val Loss: 7900.3310546875, Time took: 0.3317279815673828\n",
      "Train loss Meta Info:  [1420.5653125, 592.5756640625, 47.785634765625]\n",
      "Val Loss Meta Info:  [4270.104375, 3485.54, 144.686650390625]\n",
      "\n",
      "Epoch: 131, NLL Loss: 4111.4559375, Val Loss: 12746.7392578125, Time took: 0.3837001323699951\n",
      "Train loss Meta Info:  [1420.14671875, 464.173671875, 47.8832861328125]\n",
      "Val Loss Meta Info:  [4271.1, 8330.665, 144.97494140625]\n",
      "\n",
      "Epoch: 132, NLL Loss: 4035.9365625, Val Loss: 10897.9375, Time took: 0.34891724586486816\n",
      "Train loss Meta Info:  [1420.11078125, 534.749609375, 47.9772265625]\n",
      "Val Loss Meta Info:  [4269.3584375, 6483.3375, 145.241953125]\n",
      "\n",
      "Epoch: 133, NLL Loss: 4168.12921875, Val Loss: 19401.5, Time took: 0.41141653060913086\n",
      "Train loss Meta Info:  [1420.3575, 665.56484375, 48.064169921875]\n",
      "Val Loss Meta Info:  [4270.618125, 14985.38625, 145.49685546875]\n",
      "\n",
      "Epoch: 134, NLL Loss: 4351.05734375, Val Loss: 11013.93359375, Time took: 0.3574657440185547\n",
      "Train loss Meta Info:  [1420.0084375, 513.0871875, 48.1471923828125]\n",
      "Val Loss Meta Info:  [4270.9540625, 6597.21375, 145.76673828125]\n",
      "\n",
      "Epoch: 135, NLL Loss: 4038.5359375, Val Loss: 6526.72998046875, Time took: 0.390167236328125\n",
      "Train loss Meta Info:  [1420.7709375, 566.1470703125, 48.235107421875]\n",
      "Val Loss Meta Info:  [4271.6025, 2109.10703125, 146.0208984375]\n",
      "\n",
      "Epoch: 136, NLL Loss: 4075.85046875, Val Loss: 8001.462890625, Time took: 0.35149478912353516\n",
      "Train loss Meta Info:  [1420.0946875, 507.4746875, 48.3178759765625]\n",
      "Val Loss Meta Info:  [4269.9590625, 3585.2446875, 146.259638671875]\n",
      "\n",
      "Epoch: 137, NLL Loss: 4011.79390625, Val Loss: 11091.0849609375, Time took: 0.3510105609893799\n",
      "Train loss Meta Info:  [1420.4521875, 525.8491015625, 48.395576171875]\n",
      "Val Loss Meta Info:  [4269.6596875, 6674.94625, 146.480498046875]\n",
      "\n",
      "Epoch: 138, NLL Loss: 4062.83734375, Val Loss: 15690.3720703125, Time took: 0.33666491508483887\n",
      "Train loss Meta Info:  [1420.078125, 648.7116015625, 48.467412109375]\n",
      "Val Loss Meta Info:  [4269.6725, 11274.01375, 146.68685546875]\n",
      "\n",
      "Epoch: 139, NLL Loss: 4209.6309375, Val Loss: 9981.236328125, Time took: 0.2636401653289795\n",
      "Train loss Meta Info:  [1420.3075, 601.4123828125, 48.53453125]\n",
      "Val Loss Meta Info:  [4270.455, 5563.878125, 146.90333984375]\n",
      "\n",
      "Epoch: 140, NLL Loss: 4531.745, Val Loss: 6841.35986328125, Time took: 0.3153963088989258\n",
      "Train loss Meta Info:  [1420.1559375, 586.451796875, 48.604990234375]\n",
      "Val Loss Meta Info:  [4270.059375, 2424.139375, 147.161103515625]\n",
      "\n",
      "Epoch: 141, NLL Loss: 3915.34265625, Val Loss: 7601.4228515625, Time took: 0.3849353790283203\n",
      "Train loss Meta Info:  [1420.2021875, 498.414921875, 48.689033203125]\n",
      "Val Loss Meta Info:  [4269.493125, 3184.5428125, 147.387646484375]\n",
      "\n",
      "Epoch: 142, NLL Loss: 4305.67109375, Val Loss: 10174.375, Time took: 0.3053429126739502\n",
      "Train loss Meta Info:  [1420.1725, 701.1875, 48.7628076171875]\n",
      "Val Loss Meta Info:  [4269.7975, 5756.949375, 147.628671875]\n",
      "\n",
      "Epoch: 143, NLL Loss: 3899.009375, Val Loss: 13050.9423828125, Time took: 0.3008394241333008\n",
      "Train loss Meta Info:  [1420.1290625, 465.92875, 48.84138671875]\n",
      "Val Loss Meta Info:  [4269.404375, 8633.7, 147.83638671875]\n",
      "\n",
      "Epoch: 144, NLL Loss: 4009.9175, Val Loss: 6896.75537109375, Time took: 0.3081398010253906\n",
      "Train loss Meta Info:  [1420.5415625, 497.34265625, 48.90900390625]\n",
      "Val Loss Meta Info:  [4269.0940625, 2479.6359375, 148.025673828125]\n",
      "\n",
      "Epoch: 145, NLL Loss: 4682.09171875, Val Loss: 7493.2373046875, Time took: 0.3435533046722412\n",
      "Train loss Meta Info:  [1420.0415625, 820.931796875, 48.970556640625]\n",
      "Val Loss Meta Info:  [4269.5390625, 3075.425, 148.27341796875]\n",
      "\n",
      "Epoch: 146, NLL Loss: 4126.40921875, Val Loss: 12616.734375, Time took: 0.2830822467803955\n",
      "Train loss Meta Info:  [1419.65875, 709.67125, 49.0513916015625]\n",
      "Val Loss Meta Info:  [4268.480625, 8199.74125, 148.51208984375]\n",
      "\n",
      "Epoch: 147, NLL Loss: 4555.4090625, Val Loss: 7313.15234375, Time took: 0.34174346923828125\n",
      "Train loss Meta Info:  [1419.7275, 1078.884375, 49.1293017578125]\n",
      "Val Loss Meta Info:  [4269.4371875, 2894.939375, 148.7763671875]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148, NLL Loss: 3918.75765625, Val Loss: 6907.1650390625, Time took: 0.3245828151702881\n",
      "Train loss Meta Info:  [1420.0665625, 502.7624609375, 49.2157373046875]\n",
      "Val Loss Meta Info:  [4268.64875, 2489.513125, 149.003544921875]\n",
      "\n",
      "Epoch: 149, NLL Loss: 4088.2453125, Val Loss: 19309.091796875, Time took: 0.2555556297302246\n",
      "Train loss Meta Info:  [1419.86703125, 551.28046875, 49.289951171875]\n",
      "Val Loss Meta Info:  [4268.9565625, 14890.91625, 149.220966796875]\n",
      "\n",
      "Epoch: 150, NLL Loss: 4119.7321875, Val Loss: 8004.181640625, Time took: 0.27544665336608887\n",
      "Train loss Meta Info:  [1420.32765625, 580.3285546875, 49.3609375]\n",
      "Val Loss Meta Info:  [4268.7490625, 3586.0021875, 149.4303515625]\n",
      "\n",
      "Epoch: 151, NLL Loss: 3906.805, Val Loss: 8283.4521484375, Time took: 0.2930324077606201\n",
      "Train loss Meta Info:  [1420.14875, 493.9267578125, 49.4292724609375]\n",
      "Val Loss Meta Info:  [4268.2384375, 3865.606875, 149.605625]\n",
      "\n",
      "Epoch: 152, NLL Loss: 4089.300625, Val Loss: 11642.7822265625, Time took: 0.22782349586486816\n",
      "Train loss Meta Info:  [1419.75296875, 640.13515625, 49.4863671875]\n",
      "Val Loss Meta Info:  [4269.0509375, 7223.956875, 149.774580078125]\n",
      "\n",
      "Epoch: 153, NLL Loss: 3972.704375, Val Loss: 8132.35791015625, Time took: 0.2972397804260254\n",
      "Train loss Meta Info:  [1419.73921875, 495.6528125, 49.541396484375]\n",
      "Val Loss Meta Info:  [4268.6590625, 3713.7765625, 149.922958984375]\n",
      "\n",
      "Epoch: 154, NLL Loss: 4462.12734375, Val Loss: 7381.349609375, Time took: 0.3200821876525879\n",
      "Train loss Meta Info:  [1420.015625, 647.8819921875, 49.589638671875]\n",
      "Val Loss Meta Info:  [4268.219375, 2963.00875, 150.12158203125]\n",
      "\n",
      "Epoch: 155, NLL Loss: 3884.01359375, Val Loss: 6899.24853515625, Time took: 0.30474328994750977\n",
      "Train loss Meta Info:  [1419.98, 464.7796875, 49.65443359375]\n",
      "Val Loss Meta Info:  [4268.964375, 2480.00046875, 150.28375]\n",
      "\n",
      "Epoch: 156, NLL Loss: 4301.845625, Val Loss: 6927.01904296875, Time took: 0.30893397331237793\n",
      "Train loss Meta Info:  [1419.5196875, 624.7909375, 49.70720703125]\n",
      "Val Loss Meta Info:  [4269.0778125, 2507.4778125, 150.46419921875]\n",
      "\n",
      "Epoch: 157, NLL Loss: 3952.24625, Val Loss: 10223.529296875, Time took: 0.2934913635253906\n",
      "Train loss Meta Info:  [1419.8709375, 493.138125, 49.7660009765625]\n",
      "Val Loss Meta Info:  [4268.2475, 5804.663125, 150.620283203125]\n",
      "\n",
      "Epoch: 158, NLL Loss: 4173.8178125, Val Loss: 7824.6923828125, Time took: 0.3090991973876953\n",
      "Train loss Meta Info:  [1419.925625, 516.351640625, 49.8167529296875]\n",
      "Val Loss Meta Info:  [4269.008125, 3404.9003125, 150.783935546875]\n",
      "\n",
      "Epoch: 159, NLL Loss: 3889.57, Val Loss: 10109.8232421875, Time took: 0.32390356063842773\n",
      "Train loss Meta Info:  [1420.1409375, 487.1746875, 49.869990234375]\n",
      "Val Loss Meta Info:  [4269.0034375, 5689.905, 150.9144921875]\n",
      "\n",
      "Epoch: 160, NLL Loss: 3989.72265625, Val Loss: 9151.7626953125, Time took: 0.36569881439208984\n",
      "Train loss Meta Info:  [1419.5284375, 517.2244140625, 49.912314453125]\n",
      "Val Loss Meta Info:  [4267.7690625, 4732.966875, 151.02751953125]\n",
      "\n",
      "Epoch: 161, NLL Loss: 3995.77859375, Val Loss: 27192.666015625, Time took: 0.324321985244751\n",
      "Train loss Meta Info:  [1419.4053125, 530.179375, 49.948857421875]\n",
      "Val Loss Meta Info:  [4268.744375, 22772.7975, 151.12953125]\n",
      "\n",
      "Epoch: 162, NLL Loss: 3926.63125, Val Loss: 13496.96484375, Time took: 0.3082091808319092\n",
      "Train loss Meta Info:  [1419.619375, 490.119765625, 49.981787109375]\n",
      "Val Loss Meta Info:  [4268.01125, 9077.74125, 151.2122265625]\n",
      "\n",
      "Epoch: 163, NLL Loss: 4248.3925, Val Loss: 27840.00390625, Time took: 0.25379014015197754\n",
      "Train loss Meta Info:  [1419.730625, 514.0034375, 50.0083349609375]\n",
      "Val Loss Meta Info:  [4268.778125, 23419.9175, 151.31615234375]\n",
      "\n",
      "Epoch: 164, NLL Loss: 4007.603125, Val Loss: 7577.2353515625, Time took: 0.3124375343322754\n",
      "Train loss Meta Info:  [1419.56625, 570.1575, 50.041865234375]\n",
      "Val Loss Meta Info:  [4267.43125, 3158.39625, 151.4083203125]\n",
      "\n",
      "Epoch: 165, NLL Loss: 3989.8096875, Val Loss: 6617.22998046875, Time took: 0.31337738037109375\n",
      "Train loss Meta Info:  [1419.305625, 480.72359375, 50.07154296875]\n",
      "Val Loss Meta Info:  [4269.0665625, 2196.67421875, 151.48876953125]\n",
      "\n",
      "Epoch: 166, NLL Loss: 4600.05046875, Val Loss: 11419.4013671875, Time took: 0.3149864673614502\n",
      "Train loss Meta Info:  [1419.2003125, 955.796328125, 50.097333984375]\n",
      "Val Loss Meta Info:  [4268.31125, 6999.464375, 151.625732421875]\n",
      "\n",
      "Epoch: 167, NLL Loss: 3985.785625, Val Loss: 9014.919921875, Time took: 0.34631896018981934\n",
      "Train loss Meta Info:  [1419.48375, 503.3776171875, 50.14181640625]\n",
      "Val Loss Meta Info:  [4268.628125, 4594.545625, 151.746435546875]\n",
      "\n",
      "Epoch: 168, NLL Loss: 4062.91578125, Val Loss: 13914.5224609375, Time took: 0.30082058906555176\n",
      "Train loss Meta Info:  [1419.6909375, 527.835546875, 50.1809326171875]\n",
      "Val Loss Meta Info:  [4267.815625, 9494.84625, 151.86154296875]\n",
      "\n",
      "Epoch: 169, NLL Loss: 4009.0240625, Val Loss: 10369.78125, Time took: 0.3009359836578369\n",
      "Train loss Meta Info:  [1419.33234375, 515.633125, 50.218193359375]\n",
      "Val Loss Meta Info:  [4267.805625, 5950.0125, 151.963984375]\n",
      "\n",
      "Epoch: 170, NLL Loss: 4017.27640625, Val Loss: 23025.451171875, Time took: 0.3251914978027344\n",
      "Train loss Meta Info:  [1419.426875, 501.3401953125, 50.2512744140625]\n",
      "Val Loss Meta Info:  [4267.083125, 18606.31375, 152.05759765625]\n",
      "\n",
      "Epoch: 171, NLL Loss: 4246.2940625, Val Loss: 11117.3876953125, Time took: 0.24876618385314941\n",
      "Train loss Meta Info:  [1419.440625, 739.25609375, 50.28142578125]\n",
      "Val Loss Meta Info:  [4268.6253125, 6696.589375, 152.172275390625]\n",
      "\n",
      "Epoch: 172, NLL Loss: 4099.84078125, Val Loss: 8572.5078125, Time took: 0.2856621742248535\n",
      "Train loss Meta Info:  [1419.48921875, 627.0005078125, 50.318564453125]\n",
      "Val Loss Meta Info:  [4267.63375, 4152.58875, 152.285849609375]\n",
      "\n",
      "Epoch: 173, NLL Loss: 4016.71625, Val Loss: 7398.35546875, Time took: 0.3246645927429199\n",
      "Train loss Meta Info:  [1419.6821875, 498.155859375, 50.355341796875]\n",
      "Val Loss Meta Info:  [4268.2475, 2977.719375, 152.3879296875]\n",
      "\n",
      "Epoch: 174, NLL Loss: 4008.61515625, Val Loss: 8638.9560546875, Time took: 0.31098246574401855\n",
      "Train loss Meta Info:  [1419.684375, 504.1846875, 50.388330078125]\n",
      "Val Loss Meta Info:  [4268.2375, 4218.234375, 152.484052734375]\n",
      "\n",
      "Epoch: 175, NLL Loss: 4077.61859375, Val Loss: 10901.31640625, Time took: 0.31378817558288574\n",
      "Train loss Meta Info:  [1419.638125, 606.457421875, 50.4193359375]\n",
      "Val Loss Meta Info:  [4267.70875, 6481.02875, 152.578603515625]\n",
      "\n",
      "Epoch: 176, NLL Loss: 4146.80046875, Val Loss: 6502.3037109375, Time took: 0.3068881034851074\n",
      "Train loss Meta Info:  [1419.719375, 524.07953125, 50.4498291015625]\n",
      "Val Loss Meta Info:  [4267.735625, 2081.88671875, 152.6812890625]\n",
      "\n",
      "Epoch: 177, NLL Loss: 3979.51515625, Val Loss: 7932.32861328125, Time took: 0.27783799171447754\n",
      "Train loss Meta Info:  [1419.2446875, 464.223984375, 50.4830029296875]\n",
      "Val Loss Meta Info:  [4267.64, 3511.915625, 152.772734375]\n",
      "\n",
      "Epoch: 178, NLL Loss: 4026.4540625, Val Loss: 9210.0068359375, Time took: 0.23637914657592773\n",
      "Train loss Meta Info:  [1419.59875, 549.39640625, 50.512451171875]\n",
      "Val Loss Meta Info:  [4267.8634375, 4789.285, 152.857900390625]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f52368aa6460>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_mpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_mpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-b534c952b25b>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(model, data, val_data, lr, epoch, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hierarchichal_point_process/src/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch, data, optimizer, batch_size, val_data)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dmm/env-hrmtpp/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dmm/env-hrmtpp/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
