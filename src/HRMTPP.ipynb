{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define RMTPP Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMTPP(nn.Module):\n",
    "    def __init__(self, marker_type='real', marker_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.marker_dim = marker_dim\n",
    "        \n",
    "        # Dimensions for embedding inputs\n",
    "        self.marker_embed_dim = 64\n",
    "        self.time_embed_dim = 64\n",
    "        # Networks for embedding inputs\n",
    "        self.create_embedding_nets()\n",
    "        \n",
    "        # This is the layer that encodes the history\n",
    "        self.hidden_layer_dim = 128\n",
    "        # Create RNN layer Network\n",
    "        self.create_rnn()\n",
    "        \n",
    "        # Hidden shared layer size (bw mu and var)\n",
    "        # while generating marker from hidden state\n",
    "        self.marker_shared_dim = 64\n",
    "        # Create Network for Marker generation from hidden_seq\n",
    "        self.create_marker_generation_net()\n",
    "        self.create_time_likelihood_net()\n",
    "\n",
    "    ############ UTILITY METHODS #############\n",
    "        \n",
    "    def _one_hot_marker(self, marker_seq):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "            marker_seq: Tensor of shape TxBSx1\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    ############ NETWORKS #############    \n",
    "    \n",
    "    def create_rnn(self):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "            marker_embed_dim: dimension of embedded markers\n",
    "            time_embed_dim: dimension of embedded times,intervals\n",
    "            hidden_layer_dim: dimension of hidden state of recurrent layer\n",
    "        \"\"\"\n",
    "\n",
    "        ### Vanilla RNN\n",
    "#         self.rnn = nn.RNN(\n",
    "#             input_size=self.marker_embed_dim+self.time_embed_dim,\n",
    "#             hidden_size=self.hidden_layer_dim,\n",
    "#             nonlinearity='relu'\n",
    "#         )\n",
    "        ### GRU\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.marker_embed_dim+self.time_embed_dim,\n",
    "            hidden_size=self.hidden_layer_dim,\n",
    "        )\n",
    "    \n",
    "    def create_embedding_nets(self):\n",
    "        # marker_dim is passed. timeseries_dim is 2\n",
    "        self.marker_embedding_net = nn.Linear(self.marker_dim, self.marker_embed_dim)\n",
    "        \n",
    "        self.time_embedding_net = nn.Sequential(\n",
    "            nn.Linear(2, self.time_embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.time_embed_dim, self.time_embed_dim)\n",
    "        )\n",
    "        \n",
    "    def create_marker_generation_net(self):\n",
    "        \"\"\"\n",
    "            Generate network to create marker sufficient statistics using\n",
    "            rnn's hidden layer\n",
    "        \"\"\"\n",
    "        self.marker_gen_hidden = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim, self.marker_shared_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.generated_marker_mu = nn.Linear(self.marker_shared_dim, self.marker_dim)\n",
    "        self.generated_marker_var = nn.Sequential(\n",
    "            nn.Linear(self.marker_shared_dim, self.marker_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def create_time_likelihood_net(self):\n",
    "        self.h_influence = nn.Linear(self.hidden_layer_dim, 1, bias=False)\n",
    "        self.base_intensity = nn.Parameter(torch.zeros(1,1,1))\n",
    "        self.wt = nn.Parameter(torch.ones(1,1,1))\n",
    "    \n",
    "    \n",
    "    ############ METHODS #############\n",
    "    \n",
    "    def _embed_data(self, marker_seq, time_seq):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "            marker_seq: Tensor of shape TxBSx marker_dim\n",
    "            time_seq: Tensor of shape TxBSx 2\n",
    "            Output:\n",
    "            marker_seq_emb: Tensor of shape T x BS x marker_embed_dim\n",
    "            time_seq_emb: Tensor of shape T x BS x time_embed_dim\n",
    "        \"\"\"\n",
    "        marker_seq_emb = self.marker_embedding_net(marker_seq)\n",
    "        time_seq_emb = self.time_embedding_net(time_seq)\n",
    "        return marker_seq_emb, time_seq_emb\n",
    "    \n",
    "    \n",
    "    \n",
    "    def marker_log_likelihood(self, h_seq, marker_seq):\n",
    "        \"\"\"\n",
    "        Use the h_seq to generate the distribution for the markers,\n",
    "        and use that distribution to compute the log likelihood of the marker_seq\n",
    "            Input:  \n",
    "                    h_seq   : Tensor of shape T x BS x hidden_layer_dim (if real)\n",
    "                    marker_seq : Tensor of shape T x BS x marker_dim\n",
    "            Output:\n",
    "                    log_likelihood_marker_seq : T x BS x marker_dim\n",
    "        \"\"\"\n",
    "        marker_gen_shared = self.marker_gen_hidden(h_seq)\n",
    "        mu, var = self.generated_marker_mu(marker_gen_shared), self.generated_marker_var(marker_gen_shared)\n",
    "        \n",
    "        marker_gen_dist = Normal(mu, var.sqrt())\n",
    "        log_likelihood_marker_seq = marker_gen_dist.log_prob(marker_seq)\n",
    "        \n",
    "        return log_likelihood_marker_seq\n",
    "        \n",
    "        \n",
    "    def time_log_likelihood(self, h_seq, time_seq):\n",
    "        \"\"\"\n",
    "        Use the h_seq to compute the log likelihood of the time_seq\n",
    "        using the formula in the paper\n",
    "            Input:  \n",
    "                    h_seq   : Tensor of shape T x BS x hidden_layer_dim (if real)\n",
    "                    time_seq : Tensor of shape T x BS x 2 . Last dimension is [times, intervals]\n",
    "            Output:\n",
    "                    log_likelihood_time_seq : T x BS x 1\n",
    "        \"\"\"\n",
    "#         import pdb; pdb.set_trace()\n",
    "        past_influence = self.h_influence(h_seq)\n",
    "        current_influence = self.wt * time_seq[:,:,1:2]\n",
    "        base_intensity = self.base_intensity\n",
    "        \n",
    "        term1 = past_influence + current_influence + base_intensity\n",
    "        term2 = past_influence + base_intensity\n",
    "        \n",
    "        # After factorizing the formula in the paper\n",
    "        log_likelihood_time_seq = term1 + (term2.exp() - term1.exp())/self.wt\n",
    "        \n",
    "        return log_likelihood_time_seq\n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    def forward(self, marker_seq, time_seq, **kwargs):\n",
    "        # Transform markers and timesteps into the embedding spaces\n",
    "        marker_seq_emb, time_seq_emb = self._embed_data(marker_seq, time_seq)\n",
    "        T,BS,_ = marker_seq_emb.shape\n",
    "        \n",
    "        # Run RNN over the concatenated sequence [marker_seq_emb, time_seq_emb]\n",
    "        time_marker_combined = torch.cat([marker_seq_emb, time_seq_emb], dim=-1)\n",
    "        h_0 = torch.zeros(1, BS, self.hidden_layer_dim).to(device)\n",
    "        hidden_seq, _ = self.rnn(time_marker_combined, h_0)\n",
    "        hidden_combined = torch.cat([h_0, hidden_seq], dim=0)\n",
    "        \n",
    "        # compute the marker and time log likelihoods\n",
    "        # h_0 is used to generate marker_1 and so on...\n",
    "        marker_ll = self.marker_log_likelihood(hidden_combined[:-1], marker_seq)\n",
    "        # h_0 is used to generate timestamp_1 and so on...\n",
    "        time_ll = self.time_log_likelihood(hidden_combined[:-1], time_seq)\n",
    "        \n",
    "        likelihood_loss = marker_ll.sum() + time_ll.sum()\n",
    "        NLL = -likelihood_loss\n",
    "        \n",
    "        # NLL is used for optimization,\n",
    "        # the individual LL values are used for logging\n",
    "        return NLL, [-marker_ll.sum().item(), -time_ll.sum().item() ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRMTPP(RMTPP):\n",
    "    def __init__(self, latent_dim=20, **kwargs):\n",
    "        self.latent_dim = latent_dim\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.create_inference_net()\n",
    "        self.create_marker_generation_net()\n",
    "        self.create_time_likelihood_net()\n",
    "    \n",
    "    ## Utility Methods ##\n",
    "    def _reparameterize(self, mu, var):\n",
    "        epsilon = torch.randn_like(mu)\n",
    "        return mu + epsilon*var.sqrt()\n",
    "    \n",
    "    def create_inference_net(self):\n",
    "        self.inference_rnn = nn.GRU(\n",
    "            input_size = self.marker_embed_dim+self.time_embed_dim,\n",
    "            hidden_size = self.hidden_layer_dim\n",
    "        )\n",
    "        \n",
    "        self.inference_intermediate_net = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim, self.hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.posterior_mean_net = nn.Linear(self.hidden_layer_dim, self.latent_dim)\n",
    "        self.posterior_var_net = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim, self.latent_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "    def create_marker_generation_net(self):\n",
    "        \"\"\"\n",
    "            Generate network to create marker sufficient statistics using\n",
    "            rnn's hidden layer and latent variable\n",
    "        \"\"\"\n",
    "        self.marker_gen_hidden = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim+self.latent_dim, self.marker_shared_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.generated_marker_mu = nn.Linear(self.marker_shared_dim, self.marker_dim)\n",
    "        self.generated_marker_var = nn.Sequential(\n",
    "            nn.Linear(self.marker_shared_dim, self.marker_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def create_time_likelihood_net(self):\n",
    "        self.h_influence = nn.Linear(self.hidden_layer_dim+self.latent_dim, 1, bias=False)\n",
    "        self.base_intensity = nn.Parameter(torch.zeros(1,1,1))\n",
    "        self.wt = nn.Parameter(torch.randn(1,1,1))\n",
    "    \n",
    "        \n",
    "    def _inference(self, hidden_seq):\n",
    "        \"\"\"\n",
    "        Use the hidden_seq to compute the posterior\n",
    "        q(z | x) = NN(RNN(x(1...T))) = NN(h_T)\n",
    "        Also, compute a sampled value and return\n",
    "            Input:  \n",
    "                    hidden_seq   : Tensor of shape (T+1) x BS x hidden_layer_dim (first timestep is h_0)\n",
    "            Output:\n",
    "                    z_sampled: Tensor of shape 1 x BS x latent_dim\n",
    "                    z_mean: Tensor of shape 1 x BS x latent_dim\n",
    "                    z_var: Tensor of shape 1 x BS x latent_dim\n",
    "        \"\"\"\n",
    "        \n",
    "        intermediate_layer = self.inference_intermediate_net(hidden_seq[-1:])\n",
    "        z_mean = self.posterior_mean_net(intermediate_layer)\n",
    "        z_var = self.posterior_var_net(intermediate_layer)\n",
    "        z_sampled = self._reparameterize(z_mean, z_var)\n",
    "        \n",
    "        return z_sampled, z_mean, z_var\n",
    "    \n",
    "    def hz_combined(self, hidden_seq, z):\n",
    "        \"\"\"\n",
    "        Concatenate the z to the hidden_seq along the last dimension\n",
    "            Input:  \n",
    "                    hidden_seq   : Tensor of shape (T+1) x BS x hidden_layer_dim (first timestep is h_0)\n",
    "                    z: Tensor of shape 1 x BS x latent_dim\n",
    "            Output:\n",
    "                    hz = Tensor of shape (T+1) x BS x (hidden_layer_dim+latent_dim)\n",
    "        \"\"\"\n",
    "        # Extract timelength\n",
    "        T, _, _ = hidden_seq.shape\n",
    "        # Expand z on the time dimension, leaving everything else the same\n",
    "        z_broadcast = z.expand(T, -1, -1)\n",
    "        \n",
    "        hz = torch.cat([hidden_seq, z_broadcast], dim=-1)\n",
    "        \n",
    "        return hz\n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    def forward(self, marker_seq, time_seq, anneal=1.):\n",
    "        # Transform markers and timesteps into the embedding spaces\n",
    "        marker_seq_emb, time_seq_emb = self._embed_data(marker_seq, time_seq)\n",
    "        T,BS,_ = marker_seq_emb.shape\n",
    "        \n",
    "        # Run RNN over the concatenated sequence [marker_seq_emb, time_seq_emb]\n",
    "        time_marker_combined = torch.cat([marker_seq_emb, time_seq_emb], dim=-1)\n",
    "        h_0 = torch.zeros(1, BS, self.hidden_layer_dim).to(device)\n",
    "        # Run RNN\n",
    "        hidden_seq, _ = self.rnn(time_marker_combined, h_0)\n",
    "        # Append h_0 to h_1 .. h_T\n",
    "        hidden_seq = torch.cat([h_0, hidden_seq], dim=0)\n",
    "        \n",
    "        ## Inference\n",
    "        # Get the sampled value and (mean + var) latent variable\n",
    "        # using the hidden state sequence\n",
    "        posterior_sample, posterior_mean, posterior_var = self._inference(hidden_seq)\n",
    "        posterior_dist = Normal(posterior_mean, posterior_var.sqrt())\n",
    "\n",
    "        # Prior is just a Normal(0,1) dist\n",
    "        prior_dist = Normal(0,1)\n",
    "\n",
    "        ## Generative Part\n",
    "        \n",
    "        # Use the embedded markers and times to create another set of \n",
    "        # hidden vectors. Can reuse the h_0 and time_marker combined computed above\n",
    "\n",
    "        # Use an RNN to summarize the x1 ... xT sequence\n",
    "        hidden_seq, _ = self.rnn(time_marker_combined, h_0)\n",
    "        hidden_seq = torch.cat([h_0, hidden_seq], dim=0)\n",
    "        \n",
    "        # Combine hidden_seq and z to form the input for the generative part\n",
    "        hz_combined = self.hz_combined(hidden_seq, posterior_sample)\n",
    "        \n",
    "        # compute the marker and time log likelihoods\n",
    "        # z,h_0 is used to generate marker_1 and so on...\n",
    "        marker_ll = self.marker_log_likelihood(hz_combined[:-1], marker_seq)\n",
    "        # z,h_0 is used to generate timestamp_1 and so on...\n",
    "        time_ll = self.time_log_likelihood(hz_combined[:-1], time_seq)\n",
    "        \n",
    "        likelihood_loss = marker_ll.sum() + time_ll.sum()\n",
    "        NLL = -likelihood_loss\n",
    "        \n",
    "        KL = kl_divergence(posterior_dist, prior_dist).sum()\n",
    "        \n",
    "        loss = NLL + anneal*10*KL\n",
    "        \n",
    "        # NLL and KL are used for optimization,\n",
    "        # the individual LL values are used for logging\n",
    "        return loss, [-marker_ll.sum().item(), -time_ll.sum().item(), KL.item()]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import train\n",
    "# from hrmtpp import hrmtpp\n",
    "# from rmtpp import rmtpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, data = None, val_data=None, lr= 1e-2, l2_reg=1e-2, epoch = 200, batch_size = 32):\n",
    "    if data == None:\n",
    "        data, val_data = generate_mpp()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=l2_reg)\n",
    "\n",
    "    for epoch_number in range(epoch):\n",
    "        train(model, epoch_number, data, optimizer, batch_size, val_data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, data, val_data):\n",
    "    model = model().to(device)\n",
    "#     data, _ = generate_mpp(type='hawkes', num_sample=1000)\n",
    "#     val_data, _ = generate_mpp(type='hawkes', num_sample = 200)\n",
    "    print(\"Times: Data Shape: {}, Val Data Shape: {}\".format(data['t'].shape, val_data['t'].shape))\n",
    "    print(\"Markers: Data Shape: {}, Val Data Shape: {}\".format(data['x'].shape, val_data['x'].shape))\n",
    "    trainer(model, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.synthetic_data import test_val_split, generate_mpp\n",
    "from utils.mimic_data_tensors import mimic_data_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mimic_data_tensors()\n",
    "data, val_data = test_val_split(data, val_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data, _ = generate_mpp(type='hawkes', num_sample=1000)\n",
    "# val_data, _ = generate_mpp(type='hawkes', num_sample = 200)\n",
    "# data, _ = generate_mpp(type='autoregressive', time_step=50, num_sample=100, num_clusters=10, m=8)\n",
    "# data, val_data = test_val_split(data, val_ratio=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([37, 1268, 32]), torch.Size([37, 1268, 2]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x'].shape, data['t'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMTPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([37, 1268, 2]), Val Data Shape: torch.Size([37, 317, 2])\n",
      "Markers: Data Shape: torch.Size([37, 1268, 32]), Val Data Shape: torch.Size([37, 317, 32])\n",
      "Epoch: 0, NLL Loss: 4492099781.047318, Val Loss: 21996843008.0, Time took: 0.34491729736328125\n",
      "Train loss Meta Info:  [ 4.49209978e+09 -8.90796882e-01]\n",
      "Val Loss Meta Info:  [21996843118.7027, -224.17884290540542]\n",
      "\n",
      "Epoch: 1, NLL Loss: 2474084121.0347004, Val Loss: 15251885056.0, Time took: 0.29399776458740234\n",
      "Train loss Meta Info:  [ 2.47408412e+09 -2.61504056e+01]\n",
      "Val Loss Meta Info:  [15251885083.675676, -677.379856418919]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1740661559.7223976, Val Loss: 12580389888.0, Time took: 0.2978246212005615\n",
      "Train loss Meta Info:  [ 1.74066167e+09 -7.92468317e+01]\n",
      "Val Loss Meta Info:  [12580390635.243244, -1247.790962837838]\n",
      "\n",
      "Epoch: 3, NLL Loss: 1448588902.5615141, Val Loss: 11147462656.0, Time took: 0.2848541736602783\n",
      "Train loss Meta Info:  [ 1.44858903e+09 -1.46089554e+02]\n",
      "Val Loss Meta Info:  [11147463707.675676, -1724.8788006756756]\n",
      "\n",
      "Epoch: 4, NLL Loss: 1290583572.9968455, Val Loss: 10198201344.0, Time took: 0.26884889602661133\n",
      "Train loss Meta Info:  [ 1.29058381e+09 -2.02277071e+02]\n",
      "Val Loss Meta Info:  [10198203973.18919, -2410.2466216216217]\n",
      "\n",
      "Epoch: 5, NLL Loss: 1184881117.274448, Val Loss: 9461959680.0, Time took: 0.2638530731201172\n",
      "Train loss Meta Info:  [ 1.18488138e+09 -2.84245518e+02]\n",
      "Val Loss Meta Info:  [9461962807.35135, -3825.488175675676]\n",
      "\n",
      "Epoch: 6, NLL Loss: 1102145442.3217666, Val Loss: 8856421376.0, Time took: 0.26970887184143066\n",
      "Train loss Meta Info:  [ 1.1021459e+09 -4.5694547e+02]\n",
      "Val Loss Meta Info:  [8856427879.783783, -7429.716216216216]\n",
      "\n",
      "Epoch: 7, NLL Loss: 1033522630.6624606, Val Loss: 8374101504.0, Time took: 0.26842522621154785\n",
      "Train loss Meta Info:  [ 1.03352353e+09 -9.02250051e+02]\n",
      "Val Loss Meta Info:  [8374116573.405405, -15105.349662162162]\n",
      "\n",
      "Epoch: 8, NLL Loss: 978215171.2302839, Val Loss: 7861897216.0, Time took: 0.2554140090942383\n",
      "Train loss Meta Info:  [ 9.78217017e+08 -1.84891287e+03]\n",
      "Val Loss Meta Info:  [7861947419.675675, -50106.82432432433]\n",
      "\n",
      "Epoch: 9, NLL Loss: 919677495.7223974, Val Loss: 7460695552.0, Time took: 0.2557651996612549\n",
      "Train loss Meta Info:  [ 9.19683683e+08 -6.18662083e+03]\n",
      "Val Loss Meta Info:  [7460829903.567568, -134689.8108108108]\n",
      "\n",
      "Epoch: 10, NLL Loss: 873191865.7413249, Val Loss: 7063467520.0, Time took: 0.2687067985534668\n",
      "Train loss Meta Info:  [ 8.73208503e+08 -1.66414451e+04]\n",
      "Val Loss Meta Info:  [7063850011.675675, -382477.3243243243]\n",
      "\n",
      "Epoch: 11, NLL Loss: 827189335.2176657, Val Loss: 6663218176.0, Time took: 0.27161550521850586\n",
      "Train loss Meta Info:  [ 8.27236547e+08 -4.72064060e+04]\n",
      "Val Loss Meta Info:  [6664299160.216216, -1080761.945945946]\n",
      "\n",
      "Epoch: 12, NLL Loss: 780923387.9621451, Val Loss: 6313171968.0, Time took: 0.2629261016845703\n",
      "Train loss Meta Info:  [ 7.81055919e+08 -1.32527520e+05]\n",
      "Val Loss Meta Info:  [6315960264.648648, -2788253.8378378376]\n",
      "\n",
      "Epoch: 13, NLL Loss: 740163479.4195584, Val Loss: 5980958208.0, Time took: 0.23451709747314453\n",
      "Train loss Meta Info:  [ 7.40504446e+08 -3.40966422e+05]\n",
      "Val Loss Meta Info:  [5988075243.243243, -7117318.054054054]\n",
      "\n",
      "Epoch: 14, NLL Loss: 701393806.5362777, Val Loss: 5691544064.0, Time took: 0.23405981063842773\n",
      "Train loss Meta Info:  [ 7.02261900e+08 -8.68095083e+05]\n",
      "Val Loss Meta Info:  [5705315743.135135, -13771727.567567568]\n",
      "\n",
      "Epoch: 15, NLL Loss: 667289384.3785489, Val Loss: 5335222784.0, Time took: 0.2292003631591797\n",
      "Train loss Meta Info:  [ 6.68982910e+08 -1.69352386e+06]\n",
      "Val Loss Meta Info:  [5382719654.054054, -47496790.48648649]\n",
      "\n",
      "Epoch: 16, NLL Loss: 625726308.1388012, Val Loss: 4988880384.0, Time took: 0.22673702239990234\n",
      "Train loss Meta Info:  [ 6.31499329e+08 -5.77302137e+06]\n",
      "Val Loss Meta Info:  [5106268436.756757, -117388038.91891892]\n",
      "\n",
      "Epoch: 17, NLL Loss: 584869424.4542587, Val Loss: 4550013952.0, Time took: 0.22620558738708496\n",
      "Train loss Meta Info:  [ 5.99131605e+08 -1.42621802e+07]\n",
      "Val Loss Meta Info:  [4846704695.351352, -296690660.3243243]\n",
      "\n",
      "Epoch: 18, NLL Loss: 532667515.5583596, Val Loss: 3846258432.0, Time took: 0.23011040687561035\n",
      "Train loss Meta Info:  [ 5.68716891e+08 -3.60493789e+07]\n",
      "Val Loss Meta Info:  [4603530267.675675, -757272133.1891892]\n",
      "\n",
      "Epoch: 19, NLL Loss: 448186515.78548896, Val Loss: 2430042880.0, Time took: 0.22617173194885254\n",
      "Train loss Meta Info:  [ 5.40204078e+08 -9.20175645e+07]\n",
      "Val Loss Meta Info:  [4376207138.594595, -1946164362.3783784]\n",
      "\n",
      "Epoch: 20, NLL Loss: 277080986.64984226, Val Loss: -881071744.0, Time took: 0.2277514934539795\n",
      "Train loss Meta Info:  [ 5.13536062e+08 -2.36455076e+08]\n",
      "Val Loss Meta Info:  [4164111387.675676, -5045183128.216216]\n",
      "\n",
      "Epoch: 21, NLL Loss: -124291539.17981073, Val Loss: -9134625792.0, Time took: 0.2313075065612793\n",
      "Train loss Meta Info:  [ 4.88643616e+08 -6.12935155e+08]\n",
      "Val Loss Meta Info:  [3966564185.9459457, -13101190171.675676]\n",
      "\n",
      "Epoch: 22, NLL Loss: -1126358535.268139, Val Loss: -30358448128.0, Time took: 0.2319180965423584\n",
      "Train loss Meta Info:  [ 4.65450509e+08 -1.59180905e+09]\n",
      "Val Loss Meta Info:  [3787877182.2702703, -34146324812.10811]\n",
      "\n",
      "Epoch: 23, NLL Loss: -3704388137.993691, Val Loss: -86158950400.0, Time took: 0.23329544067382812\n",
      "Train loss Meta Info:  [ 4.44401147e+08 -4.14878930e+09]\n",
      "Val Loss Meta Info:  [3612109851.675676, -89771056930.59459]\n",
      "\n",
      "Epoch: 24, NLL Loss: -10482830093.728706, Val Loss: -234693607424.0, Time took: 0.23102021217346191\n",
      "Train loss Meta Info:  [ 4.23819456e+08 -1.09066496e+10]\n",
      "Val Loss Meta Info:  [3453657530.810811, -238147253220.3243]\n",
      "\n",
      "Epoch: 25, NLL Loss: -28526926799.545742, Val Loss: -633983926272.0, Time took: 0.2250957489013672\n",
      "Train loss Meta Info:  [ 4.05203345e+08 -2.89321302e+10]\n",
      "Val Loss Meta Info:  [3306565299.891892, -637290484929.7297]\n",
      "\n",
      "Epoch: 26, NLL Loss: -77031869985.91798, Val Loss: -1717120401408.0, Time took: 0.23325037956237793\n",
      "Train loss Meta Info:  [ 3.87919174e+08 -7.74197896e+10]\n",
      "Val Loss Meta Info:  [3169989825.7297297, -1720290384812.973]\n",
      "\n",
      "Epoch: 27, NLL Loss: -208603950083.2303, Val Loss: -4681545285632.0, Time took: 0.23225116729736328\n",
      "Train loss Meta Info:  [ 3.71868805e+08 -2.08975819e+11]\n",
      "Val Loss Meta Info:  [3043260028.5405407, -4684588664112.433]\n",
      "\n",
      "Epoch: 28, NLL Loss: -568686203797.4006, Val Loss: -12867205070848.0, Time took: 0.23374724388122559\n",
      "Train loss Meta Info:  [ 3.56974048e+08 -5.69043172e+11]\n",
      "Val Loss Meta Info:  [2925676931.4594593, -12870130682907.676]\n",
      "\n",
      "Epoch: 29, NLL Loss: -1562934680747.205, Val Loss: -35671892819968.0, Time took: 0.23284387588500977\n",
      "Train loss Meta Info:  [ 3.43153479e+08 -1.56327783e+12]\n",
      "Val Loss Meta Info:  [2816555506.1621623, -35674705724277.625]\n",
      "\n",
      "Epoch: 30, NLL Loss: -4332710302871.823, Val Loss: -99773038198784.0, Time took: 0.22992849349975586\n",
      "Train loss Meta Info:  [ 3.30326601e+08 -4.33304066e+12]\n",
      "Val Loss Meta Info:  [2715259433.5135136, -99775746812291.45]\n",
      "\n",
      "Epoch: 31, NLL Loss: -12117829558142.79, Val Loss: -281565540122624.0, Time took: 0.23449039459228516\n",
      "Train loss Meta Info:  [ 3.18419128e+08 -1.21181479e+13]\n",
      "Val Loss Meta Info:  [2621168335.5675673, -281568131068900.3]\n",
      "\n",
      "Epoch: 32, NLL Loss: -34195601994774.613, Val Loss: -801752685215744.0, Time took: 0.23455548286437988\n",
      "Train loss Meta Info:  [ 3.07358347e+08 -3.41959095e+13]\n",
      "Val Loss Meta Info:  [2533712979.027027, -801755242607588.4]\n",
      "\n",
      "Epoch: 33, NLL Loss: -97367450869579.11, Val Loss: -2303600877371392.0, Time took: 0.2365114688873291\n",
      "Train loss Meta Info:  [ 2.97077541e+08 -9.73677484e+13]\n",
      "Val Loss Meta Info:  [2452355791.5675673, -2303603387605656.0]\n",
      "\n",
      "Epoch: 34, NLL Loss: -279759924587781.66, Val Loss: -6678346117152768.0, Time took: 0.2264244556427002\n",
      "Train loss Meta Info:  [ 2.87513523e+08 -2.79760212e+14]\n",
      "Val Loss Meta Info:  [2385260211.891892, -6678348192086293.0]\n",
      "\n",
      "Epoch: 35, NLL Loss: -811522720501488.6, Val Loss: -1.953303022587085e+16, Time took: 0.24102234840393066\n",
      "Train loss Meta Info:  [ 2.79537254e+08 -8.11523004e+14]\n",
      "Val Loss Meta Info:  [2305974714.810811, -1.9533032083154004e+16]\n",
      "\n",
      "Epoch: 36, NLL Loss: -2372475714726450.0, Val Loss: -5.765451140510515e+16, Time took: 0.23641347885131836\n",
      "Train loss Meta Info:  [ 2.70305923e+08 -2.37247598e+15]\n",
      "Val Loss Meta Info:  [2244245559.3513513, -5.765451175334574e+16]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, NLL Loss: -7003981820580964.0, Val Loss: -1.716853047033856e+17, Time took: 0.22749114036560059\n",
      "Train loss Meta Info:  [ 2.63011042e+08 -7.00398202e+15]\n",
      "Val Loss Meta Info:  [2235944627.891892, -1.716853084179519e+17]\n",
      "\n",
      "Epoch: 38, NLL Loss: -2.089652756094268e+16, Val Loss: -1.7221635163973222e+17, Time took: 0.23256993293762207\n",
      "Train loss Meta Info:  [ 2.61542663e+08 -2.08965276e+16]\n",
      "Val Loss Meta Info:  [2242853140.756757, -1.7221634281763725e+17]\n",
      "\n",
      "Epoch: 39, NLL Loss: -2.0963144861193576e+16, Val Loss: -1.728920874343465e+17, Time took: 0.23165631294250488\n",
      "Train loss Meta Info:  [ 2.61758426e+08 -2.09631449e+16]\n",
      "Val Loss Meta Info:  [2232021545.5135136, -1.7289208186249702e+17]\n",
      "\n",
      "Epoch: 40, NLL Loss: -2.1048747583394296e+16, Val Loss: -1.7394139948436685e+17, Time took: 0.2338259220123291\n",
      "Train loss Meta Info:  [ 2.60086454e+08 -2.10487476e+16]\n",
      "Val Loss Meta Info:  [2204198856.6486487, -1.739414022702916e+17]\n",
      "\n",
      "Epoch: 41, NLL Loss: -2.1148271256565636e+16, Val Loss: -1.7598807165999514e+17, Time took: 0.23130559921264648\n",
      "Train loss Meta Info:  [ 2.56604245e+08 -2.11482713e+16]\n",
      "Val Loss Meta Info:  [2168836649.5135136, -1.759880688740704e+17]\n",
      "\n",
      "Epoch: 42, NLL Loss: -2.136384915974944e+16, Val Loss: -1.8854794760290304e+17, Time took: 0.2268996238708496\n",
      "Train loss Meta Info:  [ 2.52332158e+08 -2.13638492e+16]\n",
      "Val Loss Meta Info:  [2116840475.6756756, -1.8854793878080806e+17]\n",
      "\n",
      "Epoch: 43, NLL Loss: -2.27926575288673e+16, Val Loss: -1.908867978137436e+17, Time took: 0.23218154907226562\n",
      "Train loss Meta Info:  [ 2.46286360e+08 -2.27926575e+16]\n",
      "Val Loss Meta Info:  [2027136525.837838, -1.9088679317053574e+17]\n",
      "\n",
      "Epoch: 44, NLL Loss: -2.2970963218099876e+16, Val Loss: -2.1141265267975782e+17, Time took: 0.23231744766235352\n",
      "Train loss Meta Info:  [ 2.36175520e+08 -2.29709632e+16]\n",
      "Val Loss Meta Info:  [1959090009.945946, -2.11412654537041e+17]\n",
      "\n",
      "Epoch: 45, NLL Loss: -2.5347508473615252e+16, Val Loss: -2.512682483795886e+17, Time took: 0.2328810691833496\n",
      "Train loss Meta Info:  [ 2.28427161e+08 -2.53475085e+16]\n",
      "Val Loss Meta Info:  [1887165578.3783784, -2.5126824234341837e+17]\n",
      "\n",
      "Epoch: 46, NLL Loss: -3.003017238712338e+16, Val Loss: -2.7654813382606848e+17, Time took: 0.23103117942810059\n",
      "Train loss Meta Info:  [ 2.20272903e+08 -3.00301724e+16]\n",
      "Val Loss Meta Info:  [1819580249.945946, -2.765481245396527e+17]\n",
      "\n",
      "Epoch: 47, NLL Loss: -3.2936059680200764e+16, Val Loss: -2.782165052822651e+17, Time took: 0.22739791870117188\n",
      "Train loss Meta Info:  [ 2.12610994e+08 -3.29360597e+16]\n",
      "Val Loss Meta Info:  [1760161238.4864864, -2.782164997104156e+17]\n",
      "\n",
      "Epoch: 48, NLL Loss: -3.3139298833331584e+16, Val Loss: -2.802520964422697e+17, Time took: 0.23398470878601074\n",
      "Train loss Meta Info:  [ 2.05847727e+08 -3.31392988e+16]\n",
      "Val Loss Meta Info:  [1706787369.5135136, -2.8025208204832525e+17]\n",
      "\n",
      "Epoch: 49, NLL Loss: -3.3399966739360824e+16, Val Loss: -2.8951543036667494e+17, Time took: 0.24489593505859375\n",
      "Train loss Meta Info:  [ 1.99755177e+08 -3.33999667e+16]\n",
      "Val Loss Meta Info:  [1658532614.9189188, -2.8951543779580755e+17]\n",
      "\n",
      "Epoch: 50, NLL Loss: -3.4418401253330776e+16, Val Loss: -3.227511242537042e+17, Time took: 0.2374563217163086\n",
      "Train loss Meta Info:  [ 1.94231623e+08 -3.44184013e+16]\n",
      "Val Loss Meta Info:  [1616139679.1351352, -3.227511186818547e+17]\n",
      "\n",
      "Epoch: 51, NLL Loss: -3.789522185497086e+16, Val Loss: -3.283299775335629e+17, Time took: 0.2407701015472412\n",
      "Train loss Meta Info:  [ 1.89357373e+08 -3.78952219e+16]\n",
      "Val Loss Meta Info:  [1575564813.837838, -3.283299812481292e+17]\n",
      "\n",
      "Epoch: 52, NLL Loss: -3.837087455223327e+16, Val Loss: -3.5843010477634355e+17, Time took: 0.23141694068908691\n",
      "Train loss Meta Info:  [ 1.84692825e+08 -3.83708746e+16]\n",
      "Val Loss Meta Info:  [1538152724.7567568, -3.584300927040031e+17]\n",
      "\n",
      "Epoch: 53, NLL Loss: -4.166571164485372e+16, Val Loss: -5.422570415073526e+17, Time took: 0.22912907600402832\n",
      "Train loss Meta Info:  [ 1.80382776e+08 -4.16657116e+16]\n",
      "Val Loss Meta Info:  [1507021796.3243244, -5.4225702572044576e+17]\n",
      "\n",
      "Epoch: 54, NLL Loss: -6.379724759470387e+16, Val Loss: -5.5569022174049075e+17, Time took: 0.23255491256713867\n",
      "Train loss Meta Info:  [ 1.76765514e+08 -6.37972476e+16]\n",
      "Val Loss Meta Info:  [1474470109.4054055, -5.5569020502494234e+17]\n",
      "\n",
      "Epoch: 55, NLL Loss: -6.572076623035527e+16, Val Loss: -5.758994172577055e+17, Time took: 0.23461484909057617\n",
      "Train loss Meta Info:  [ 1.73007307e+08 -6.57207662e+16]\n",
      "Val Loss Meta Info:  [1444090188.108108, -5.758994070426481e+17]\n",
      "\n",
      "Epoch: 56, NLL Loss: -6.812222329879811e+16, Val Loss: -5.758789732133765e+17, Time took: 0.2329697608947754\n",
      "Train loss Meta Info:  [ 1.69493801e+08 -6.81222233e+16]\n",
      "Val Loss Meta Info:  [1415505864.6486487, -5.758789620696776e+17]\n",
      "\n",
      "Epoch: 57, NLL Loss: -6.827522005998826e+16, Val Loss: -5.767715017772237e+17, Time took: 0.23157548904418945\n",
      "Train loss Meta Info:  [ 1.66184717e+08 -6.82752201e+16]\n",
      "Val Loss Meta Info:  [1388669426.162162, -5.767714683461268e+17]\n",
      "\n",
      "Epoch: 58, NLL Loss: -6.846176363198248e+16, Val Loss: -5.783763077174395e+17, Time took: 0.23055577278137207\n",
      "Train loss Meta Info:  [ 1.63072447e+08 -6.84617636e+16]\n",
      "Val Loss Meta Info:  [1363245775.5675676, -5.783762798581921e+17]\n",
      "\n",
      "Epoch: 59, NLL Loss: -6.880067226625452e+16, Val Loss: -5.85148955747156e+17, Time took: 0.2336444854736328\n",
      "Train loss Meta Info:  [ 1.60119133e+08 -6.88006723e+16]\n",
      "Val Loss Meta Info:  [1339233916.5405405, -5.851489743199875e+17]\n",
      "\n",
      "Epoch: 60, NLL Loss: -6.930730444068385e+16, Val Loss: -5.875236259852452e+17, Time took: 0.23125410079956055\n",
      "Train loss Meta Info:  [ 1.57323751e+08 -6.93073044e+16]\n",
      "Val Loss Meta Info:  [1316407683.4594595, -5.875236222706789e+17]\n",
      "\n",
      "Epoch: 61, NLL Loss: -6.957954564417189e+16, Val Loss: -5.904685991607665e+17, Time took: 0.22967171669006348\n",
      "Train loss Meta Info:  [ 1.54668020e+08 -6.95795456e+16]\n",
      "Val Loss Meta Info:  [1294717592.2162163, -5.904685898743507e+17]\n",
      "\n",
      "Epoch: 62, NLL Loss: -7.022447706621651e+16, Val Loss: -5.978303792645407e+17, Time took: 0.2298142910003662\n",
      "Train loss Meta Info:  [ 1.52142752e+08 -7.02244771e+16]\n",
      "Val Loss Meta Info:  [1274180358.9189188, -5.978303848363901e+17]\n",
      "\n",
      "Epoch: 63, NLL Loss: -7.090505330252217e+16, Val Loss: -6.024023547712635e+17, Time took: 0.2272188663482666\n",
      "Train loss Meta Info:  [ 1.49748964e+08 -7.09050533e+16]\n",
      "Val Loss Meta Info:  [1254421919.1351352, -6.024023324838656e+17]\n",
      "\n",
      "Epoch: 64, NLL Loss: -7.145287467397908e+16, Val Loss: -6.091728037777244e+17, Time took: 0.22922515869140625\n",
      "Train loss Meta Info:  [ 1.47442515e+08 -7.14528747e+16]\n",
      "Val Loss Meta Info:  [1235590503.7837837, -6.091727684893445e+17]\n",
      "\n",
      "Epoch: 65, NLL Loss: -7.190889777194123e+16, Val Loss: -6.160688719876588e+17, Time took: 0.22881007194519043\n",
      "Train loss Meta Info:  [ 1.45236629e+08 -7.19088978e+16]\n",
      "Val Loss Meta Info:  [1217516737.7297297, -6.160688459856946e+17]\n",
      "\n",
      "Epoch: 66, NLL Loss: -7.258284864860101e+16, Val Loss: -6.227958215653458e+17, Time took: 0.229813814163208\n",
      "Train loss Meta Info:  [ 1.43130020e+08 -7.25828486e+16]\n",
      "Val Loss Meta Info:  [1200213019.6756756, -6.22795836423611e+17]\n",
      "\n",
      "Epoch: 67, NLL Loss: -7.348453316140534e+16, Val Loss: -6.339426704477389e+17, Time took: 0.23279142379760742\n",
      "Train loss Meta Info:  [ 1.41113377e+08 -7.34845332e+16]\n",
      "Val Loss Meta Info:  [1183654552.2162163, -6.339426258729431e+17]\n",
      "\n",
      "Epoch: 68, NLL Loss: -7.43195676942707e+16, Val Loss: -6.361267128573624e+17, Time took: 0.22856426239013672\n",
      "Train loss Meta Info:  [ 1.39174330e+08 -7.43195677e+16]\n",
      "Val Loss Meta Info:  [1167627789.837838, -6.36126671997133e+17]\n",
      "\n",
      "Epoch: 69, NLL Loss: -7.452061725410573e+16, Val Loss: -6.376990144850821e+17, Time took: 0.23351645469665527\n",
      "Train loss Meta Info:  [ 1.37298984e+08 -7.45206173e+16]\n",
      "Val Loss Meta Info:  [1152152880.4324324, -6.376990330579136e+17]\n",
      "\n",
      "Epoch: 70, NLL Loss: -7.462123969372123e+16, Val Loss: -6.376458256100884e+17, Time took: 0.2276144027709961\n",
      "Train loss Meta Info:  [ 1.35486506e+08 -7.46212397e+16]\n",
      "Val Loss Meta Info:  [1137207019.2432432, -6.376457810352927e+17]\n",
      "\n",
      "Epoch: 71, NLL Loss: -7.462111536999914e+16, Val Loss: -6.376052811188142e+17, Time took: 0.23363065719604492\n",
      "Train loss Meta Info:  [ 1.33736294e+08 -7.46211154e+16]\n",
      "Val Loss Meta Info:  [1122753452.9729729, -6.376052476877174e+17]\n",
      "\n",
      "Epoch: 72, NLL Loss: -7.45973066726783e+16, Val Loss: -6.375913310650368e+17, Time took: 0.23253893852233887\n",
      "Train loss Meta Info:  [ 1.32044542e+08 -7.45973067e+16]\n",
      "Val Loss Meta Info:  [1108789524.7567568, -6.375913403514525e+17]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, NLL Loss: -7.460797445012366e+16, Val Loss: -6.375831534473052e+17, Time took: 0.23341774940490723\n",
      "Train loss Meta Info:  [ 1.30404345e+08 -7.46079745e+16]\n",
      "Val Loss Meta Info:  [1095323869.4054055, -6.3758313858904e+17]\n",
      "\n",
      "Epoch: 74, NLL Loss: -7.460467548167898e+16, Val Loss: -6.375823288135844e+17, Time took: 0.2326946258544922\n",
      "Train loss Meta Info:  [ 1.28825379e+08 -7.46046755e+16]\n",
      "Val Loss Meta Info:  [1082122018.5945945, -6.375823065261865e+17]\n",
      "\n",
      "Epoch: 75, NLL Loss: -7.459490387558006e+16, Val Loss: -6.375823288135844e+17, Time took: 0.2324821949005127\n",
      "Train loss Meta Info:  [ 1.27274022e+08 -7.45949039e+16]\n",
      "Val Loss Meta Info:  [1069381576.6486486, -6.375823065261865e+17]\n",
      "\n",
      "Epoch: 76, NLL Loss: -7.459547509268165e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22575950622558594\n",
      "Train loss Meta Info:  [ 1.25779001e+08 -7.45954751e+16]\n",
      "Val Loss Meta Info:  [1057030365.4054054, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 77, NLL Loss: -7.459452906177794e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2371811866760254\n",
      "Train loss Meta Info:  [ 1.24328291e+08 -7.45945291e+16]\n",
      "Val Loss Meta Info:  [1045012701.4054054, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 78, NLL Loss: -7.45943777488607e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23430991172790527\n",
      "Train loss Meta Info:  [ 1.22918994e+08 -7.45943777e+16]\n",
      "Val Loss Meta Info:  [1033334784.0, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 79, NLL Loss: -7.455558311126538e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2338101863861084\n",
      "Train loss Meta Info:  [ 1.21549305e+08 -7.45555831e+16]\n",
      "Val Loss Meta Info:  [1021980339.8918918, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 80, NLL Loss: -7.45922860320436e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23015260696411133\n",
      "Train loss Meta Info:  [ 1.20217212e+08 -7.45922860e+16]\n",
      "Val Loss Meta Info:  [1010933649.2972972, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 81, NLL Loss: -7.460294882353323e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22971749305725098\n",
      "Train loss Meta Info:  [ 1.18921054e+08 -7.46029488e+16]\n",
      "Val Loss Meta Info:  [1000330433.7297298, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 82, NLL Loss: -7.46187382614119e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23126864433288574\n",
      "Train loss Meta Info:  [ 1.17676600e+08 -7.46187383e+16]\n",
      "Val Loss Meta Info:  [989704634.8108108, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 83, NLL Loss: -7.461822123948126e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23506617546081543\n",
      "Train loss Meta Info:  [ 1.16429484e+08 -7.46182212e+16]\n",
      "Val Loss Meta Info:  [979492421.1891892, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 84, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2328174114227295\n",
      "Train loss Meta Info:  [ 1.15230657e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [969535045.1891892, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 85, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23082733154296875\n",
      "Train loss Meta Info:  [ 1.14061554e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [959819554.5945946, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 86, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23367977142333984\n",
      "Train loss Meta Info:  [ 1.12920726e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [950335543.3513514, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 87, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2273404598236084\n",
      "Train loss Meta Info:  [ 1.11807017e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [941073269.6216216, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 88, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2329092025756836\n",
      "Train loss Meta Info:  [ 1.10719137e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [932023766.4864864, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 89, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23177766799926758\n",
      "Train loss Meta Info:  [ 1.09656223e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [923178399.1351352, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 90, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23238086700439453\n",
      "Train loss Meta Info:  [ 1.08617149e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [914528864.8648648, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 91, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2344043254852295\n",
      "Train loss Meta Info:  [ 1.07600948e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [906068134.054054, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 92, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23278212547302246\n",
      "Train loss Meta Info:  [ 1.06606936e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [897789177.081081, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 93, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23406624794006348\n",
      "Train loss Meta Info:  [ 1.05634156e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [889684853.6216216, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 94, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23234033584594727\n",
      "Train loss Meta Info:  [ 1.04681837e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [881748908.972973, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 95, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23250174522399902\n",
      "Train loss Meta Info:  [ 1.03749263e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [873976084.7567568, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 96, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23080062866210938\n",
      "Train loss Meta Info:  [ 1.02835763e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [866359738.8108108, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 97, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23270702362060547\n",
      "Train loss Meta Info:  [ 1.01940629e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [858894944.8648648, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 98, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23249578475952148\n",
      "Train loss Meta Info:  [ 1.01063291e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [851576832.0, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 99, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2317674160003662\n",
      "Train loss Meta Info:  [ 1.00203068e+08 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [844400307.8918918, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 100, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22974109649658203\n",
      "Train loss Meta Info:  [ 9.93595471e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [837361055.1351352, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 101, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23163557052612305\n",
      "Train loss Meta Info:  [ 9.85320531e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [830454479.5675676, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 102, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2340710163116455\n",
      "Train loss Meta Info:  [ 9.77201473e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [823676153.081081, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 103, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23439621925354004\n",
      "Train loss Meta Info:  [ 9.69232776e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [820172966.054054, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 104, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23329472541809082\n",
      "Train loss Meta Info:  [ 9.65087731e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [810521240.2162162, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 105, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23686790466308594\n",
      "Train loss Meta Info:  [ 9.53764629e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [804440451.4594594, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 106, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.24635624885559082\n",
      "Train loss Meta Info:  [ 9.46610630e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [797863327.1351352, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 107, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22710919380187988\n",
      "Train loss Meta Info:  [ 9.38877869e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [791690489.081081, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 108, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22221779823303223\n",
      "Train loss Meta Info:  [ 9.31618019e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [785629294.7027028, -6.375821876600646e+17]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21796965599060059\n",
      "Train loss Meta Info:  [ 9.24489214e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [779670555.6756756, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 110, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21327424049377441\n",
      "Train loss Meta Info:  [ 9.17481048e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [773811781.1891892, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 111, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21297311782836914\n",
      "Train loss Meta Info:  [ 9.10590253e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [768049594.8108108, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 112, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21341633796691895\n",
      "Train loss Meta Info:  [ 9.03813184e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [762382169.945946, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 113, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21349835395812988\n",
      "Train loss Meta Info:  [ 8.97147681e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [756806849.7297298, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 114, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21440601348876953\n",
      "Train loss Meta Info:  [ 8.90590247e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [751321088.0, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 115, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21747350692749023\n",
      "Train loss Meta Info:  [ 8.84138083e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [745923113.5135136, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 116, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21720170974731445\n",
      "Train loss Meta Info:  [ 8.77789439e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [740610656.8648648, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 117, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21483683586120605\n",
      "Train loss Meta Info:  [ 8.71541224e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [735381227.2432432, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 118, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21817350387573242\n",
      "Train loss Meta Info:  [ 8.65390467e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [730233551.5675676, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 119, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21199893951416016\n",
      "Train loss Meta Info:  [ 8.59335948e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [725165083.6756756, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 120, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21329092979431152\n",
      "Train loss Meta Info:  [ 8.53374627e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [720174218.3783784, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 121, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21452045440673828\n",
      "Train loss Meta Info:  [ 8.47504448e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [715258907.6756756, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 122, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21500134468078613\n",
      "Train loss Meta Info:  [ 8.41723409e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [710417712.4324324, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 123, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21381640434265137\n",
      "Train loss Meta Info:  [ 8.36029196e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [705648695.3513514, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 124, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21285200119018555\n",
      "Train loss Meta Info:  [ 8.30419775e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [700950306.5945946, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 125, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21387219429016113\n",
      "Train loss Meta Info:  [ 8.24893731e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [696320774.918919, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 126, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21270370483398438\n",
      "Train loss Meta Info:  [ 8.19448479e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [691758716.5405406, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 127, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21419763565063477\n",
      "Train loss Meta Info:  [ 8.14082458e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [687262747.6756756, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 128, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21445345878601074\n",
      "Train loss Meta Info:  [ 8.08794283e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [682831207.7837838, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 129, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21449542045593262\n",
      "Train loss Meta Info:  [ 8.03581774e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [678462491.6756756, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 130, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21561741828918457\n",
      "Train loss Meta Info:  [ 7.98443280e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [674155658.3783784, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 131, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21259808540344238\n",
      "Train loss Meta Info:  [ 7.93377380e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [669909213.4054054, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 132, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21287226676940918\n",
      "Train loss Meta Info:  [ 7.88382797e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [665721717.6216216, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 133, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21289515495300293\n",
      "Train loss Meta Info:  [ 7.83457456e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [661592064.0, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 134, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21361589431762695\n",
      "Train loss Meta Info:  [ 7.78599571e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [657518924.1081082, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 135, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2192976474761963\n",
      "Train loss Meta Info:  [ 7.73808774e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [653501190.918919, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 136, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2150101661682129\n",
      "Train loss Meta Info:  [ 7.69083143e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [649537702.054054, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 137, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2166731357574463\n",
      "Train loss Meta Info:  [ 7.64420802e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [645627295.1351352, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 138, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2145533561706543\n",
      "Train loss Meta Info:  [ 7.59821258e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [641768973.8378378, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 139, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2127549648284912\n",
      "Train loss Meta Info:  [ 7.55282825e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [637961520.4324324, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 140, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2130751609802246\n",
      "Train loss Meta Info:  [ 7.50804005e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [634204049.2972972, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 141, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21521449089050293\n",
      "Train loss Meta Info:  [ 7.46384240e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [630495564.1081082, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 142, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.233229398727417\n",
      "Train loss Meta Info:  [ 7.42022182e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [626834902.4864864, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 143, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21266722679138184\n",
      "Train loss Meta Info:  [ 7.37716235e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [623221234.1621622, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 144, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21138238906860352\n",
      "Train loss Meta Info:  [ 7.33465361e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [619653728.8648648, -6.375821876600646e+17]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21096372604370117\n",
      "Train loss Meta Info:  [ 7.29268959e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [616131390.2702702, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 146, NLL Loss: -7.461821993879717e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21141648292541504\n",
      "Train loss Meta Info:  [ 7.25125545e+07 -7.46182199e+16]\n",
      "Val Loss Meta Info:  [612653111.3513514, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 147, NLL Loss: -7.461822015557784e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21100783348083496\n",
      "Train loss Meta Info:  [ 7.21033864e+07 -7.46182202e+16]\n",
      "Val Loss Meta Info:  [609218449.2972972, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 148, NLL Loss: -7.461822080591989e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21153831481933594\n",
      "Train loss Meta Info:  [ 7.16993711e+07 -7.46182208e+16]\n",
      "Val Loss Meta Info:  [605826407.7837838, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 149, NLL Loss: -7.461822188982331e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21481800079345703\n",
      "Train loss Meta Info:  [ 7.13003730e+07 -7.46182219e+16]\n",
      "Val Loss Meta Info:  [602476045.8378378, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 150, NLL Loss: -7.461822514153357e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2129993438720703\n",
      "Train loss Meta Info:  [ 7.09062738e+07 -7.46182251e+16]\n",
      "Val Loss Meta Info:  [599166699.2432432, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 151, NLL Loss: -7.461823663090981e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21288037300109863\n",
      "Train loss Meta Info:  [ 7.05169420e+07 -7.46182366e+16]\n",
      "Val Loss Meta Info:  [595897537.7297298, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 152, NLL Loss: -7.461832160893782e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21306777000427246\n",
      "Train loss Meta Info:  [ 7.01324044e+07 -7.46183216e+16]\n",
      "Val Loss Meta Info:  [592667398.918919, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 153, NLL Loss: -7.461872286998336e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21419858932495117\n",
      "Train loss Meta Info:  [ 6.97524344e+07 -7.46187229e+16]\n",
      "Val Loss Meta Info:  [589495323.6756756, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 154, NLL Loss: -7.461871614978218e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2145545482635498\n",
      "Train loss Meta Info:  [ 6.93792627e+07 -7.46187161e+16]\n",
      "Val Loss Meta Info:  [586333931.2432432, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 155, NLL Loss: -7.461663895727086e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2132260799407959\n",
      "Train loss Meta Info:  [ 6.90073796e+07 -7.46166390e+16]\n",
      "Val Loss Meta Info:  [583213498.8108108, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 156, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21608996391296387\n",
      "Train loss Meta Info:  [ 6.86403205e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [580135188.7567568, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 157, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21356701850891113\n",
      "Train loss Meta Info:  [ 6.82782130e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [577092967.7837838, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 158, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21357297897338867\n",
      "Train loss Meta Info:  [ 6.79203161e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [574086227.027027, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 159, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.21338176727294922\n",
      "Train loss Meta Info:  [ 6.75666212e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [571114080.8648648, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 160, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2673201560974121\n",
      "Train loss Meta Info:  [ 6.72169952e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [568175975.7837838, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 161, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23867249488830566\n",
      "Train loss Meta Info:  [ 6.68713448e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [565271247.5675676, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 162, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2347853183746338\n",
      "Train loss Meta Info:  [ 6.65296309e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [562399287.3513514, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 163, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2372267246246338\n",
      "Train loss Meta Info:  [ 6.61918039e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [559559596.972973, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 164, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2388615608215332\n",
      "Train loss Meta Info:  [ 6.58577130e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [556751456.8648648, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 165, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23809146881103516\n",
      "Train loss Meta Info:  [ 6.55273637e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [553974147.4594594, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 166, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2438342571258545\n",
      "Train loss Meta Info:  [ 6.52006563e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [551905224.6486486, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 167, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2431330680847168\n",
      "Train loss Meta Info:  [ 6.49567115e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [548592114.1621622, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 168, NLL Loss: -7.461822058913922e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23569726943969727\n",
      "Train loss Meta Info:  [ 6.45673686e+07 -7.46182206e+16]\n",
      "Val Loss Meta Info:  [545849897.5135136, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 169, NLL Loss: -7.46048892274331e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23366618156433105\n",
      "Train loss Meta Info:  [ 6.42447715e+07 -7.46048892e+16]\n",
      "Val Loss Meta Info:  [543199785.5135136, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 170, NLL Loss: -7.457078745807872e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23296642303466797\n",
      "Train loss Meta Info:  [ 6.39329483e+07 -7.45707875e+16]\n",
      "Val Loss Meta Info:  [540578124.1081082, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 171, NLL Loss: -7.46048892274331e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23033523559570312\n",
      "Train loss Meta Info:  [ 6.36244616e+07 -7.46048892e+16]\n",
      "Val Loss Meta Info:  [537983806.2702702, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 172, NLL Loss: -7.461832421030603e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23364567756652832\n",
      "Train loss Meta Info:  [ 6.33192118e+07 -7.46183242e+16]\n",
      "Val Loss Meta Info:  [535417496.2162162, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 173, NLL Loss: -7.46048894442138e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22888946533203125\n",
      "Train loss Meta Info:  [ 6.30172745e+07 -7.46048894e+16]\n",
      "Val Loss Meta Info:  [532892533.6216216, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 174, NLL Loss: -7.46048894442138e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2302556037902832\n",
      "Train loss Meta Info:  [ 6.27201473e+07 -7.46048894e+16]\n",
      "Val Loss Meta Info:  [530367847.7837838, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 175, NLL Loss: -7.457145687683002e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2334442138671875\n",
      "Train loss Meta Info:  [ 6.24231257e+07 -7.45714569e+16]\n",
      "Val Loss Meta Info:  [527879859.8918919, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 176, NLL Loss: -7.46048892274331e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2288827896118164\n",
      "Train loss Meta Info:  [ 6.21303948e+07 -7.46048892e+16]\n",
      "Val Loss Meta Info:  [525417776.4324324, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 177, NLL Loss: -7.461869663952064e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2381277084350586\n",
      "Train loss Meta Info:  [ 6.18406719e+07 -7.46186966e+16]\n",
      "Val Loss Meta Info:  [523042151.7837838, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 178, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23394417762756348\n",
      "Train loss Meta Info:  [ 6.15611913e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [520571710.2702703, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 179, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23358798027038574\n",
      "Train loss Meta Info:  [ 6.12705368e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [518185513.5135135, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 180, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.24691176414489746\n",
      "Train loss Meta Info:  [ 6.09897718e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [515823117.8378378, -6.375821876600646e+17]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2409355640411377\n",
      "Train loss Meta Info:  [ 6.07118428e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [513483969.7297297, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 182, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.24295878410339355\n",
      "Train loss Meta Info:  [ 6.04366415e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [511187497.5135135, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 183, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2458193302154541\n",
      "Train loss Meta Info:  [ 6.01664368e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [508883829.6216216, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 184, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.24047136306762695\n",
      "Train loss Meta Info:  [ 5.98953937e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [506611435.2432432, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 185, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23808574676513672\n",
      "Train loss Meta Info:  [ 5.96280531e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [504364336.4324324, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 186, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23683571815490723\n",
      "Train loss Meta Info:  [ 5.93636806e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [502139267.4594595, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 187, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22766995429992676\n",
      "Train loss Meta Info:  [ 5.91018734e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [499935453.4054054, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 188, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22642850875854492\n",
      "Train loss Meta Info:  [ 5.88426019e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [497752894.2702703, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 189, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22729206085205078\n",
      "Train loss Meta Info:  [ 5.85858199e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [495591091.8918919, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 190, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22766900062561035\n",
      "Train loss Meta Info:  [ 5.83314658e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [493449880.2162162, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 191, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22663116455078125\n",
      "Train loss Meta Info:  [ 5.80795467e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [491328982.4864865, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 192, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22603464126586914\n",
      "Train loss Meta Info:  [ 5.78300207e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [489228011.2432432, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 193, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22852396965026855\n",
      "Train loss Meta Info:  [ 5.75828305e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [487146745.0810811, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 194, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.22704339027404785\n",
      "Train loss Meta Info:  [ 5.73379617e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [485084962.5945946, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 195, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2277214527130127\n",
      "Train loss Meta Info:  [ 5.70954146e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [483042387.027027, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 196, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23122811317443848\n",
      "Train loss Meta Info:  [ 5.68551073e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [481018686.2702703, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 197, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23250770568847656\n",
      "Train loss Meta Info:  [ 5.66169822e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [479013638.9189189, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 198, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.2313671112060547\n",
      "Train loss Meta Info:  [ 5.63811066e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [477027023.5675676, -6.375821876600646e+17]\n",
      "\n",
      "Epoch: 199, NLL Loss: -7.461821972201648e+16, Val Loss: -6.375821913746309e+17, Time took: 0.23040008544921875\n",
      "Train loss Meta Info:  [ 5.61473779e+07 -7.46182197e+16]\n",
      "Val Loss Meta Info:  [475058508.1081081, -6.375821876600646e+17]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=RMTPP, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRMTPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([37, 1268, 2]), Val Data Shape: torch.Size([37, 317, 2])\n",
      "Markers: Data Shape: torch.Size([37, 1268, 32]), Val Data Shape: torch.Size([37, 317, 32])\n",
      "Epoch: 0, NLL Loss: 4872830145.817035, Val Loss: 18511527936.0, Time took: 0.4079751968383789\n",
      "Train loss Meta Info:  [4.87283015e+09 1.26922887e+00 6.12307640e-01]\n",
      "Val Loss Meta Info:  [18511527050.37838, -50.07133195206926, 7.438031170819257]\n",
      "\n",
      "Epoch: 1, NLL Loss: 2090164325.7539432, Val Loss: 9887761408.0, Time took: 0.3835105895996094\n",
      "Train loss Meta Info:  [ 2.09016433e+09 -5.81910316e+00  8.67580469e-01]\n",
      "Val Loss Meta Info:  [9887759941.18919, -49.544618348817565, 107.32084037162163]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1135579965.3753943, Val Loss: 4026192640.0, Time took: 0.39615440368652344\n",
      "Train loss Meta Info:  [ 1.13557997e+09 -4.61438786e+00  1.25672726e+01]\n",
      "Val Loss Meta Info:  [4026184676.324324, -181.4596706081081, 777.5174725506756]\n",
      "\n",
      "Epoch: 3, NLL Loss: 451795458.01892745, Val Loss: 1908115840.0, Time took: 0.388547420501709\n",
      "Train loss Meta Info:  [ 4.51795485e+08 -2.10077096e+01  9.10440029e+01]\n",
      "Val Loss Meta Info:  [1908088389.1891892, -660.0625, 2809.380489864865]\n",
      "\n",
      "Epoch: 4, NLL Loss: 212697664.4037855, Val Loss: 993785280.0, Time took: 0.3867011070251465\n",
      "Train loss Meta Info:  [ 2.12697731e+08 -7.87643290e+01  3.28845900e+02]\n",
      "Val Loss Meta Info:  [993716390.054054, -2003.0508868243244, 7086.951013513513]\n",
      "\n",
      "Epoch: 5, NLL Loss: 109777586.47318612, Val Loss: 1316487040.0, Time took: 0.39125967025756836\n",
      "Train loss Meta Info:  [ 1.09777786e+08 -2.40481878e+02  8.29629163e+02]\n",
      "Val Loss Meta Info:  [1316360745.5135136, -17011.682432432433, 14338.52195945946]\n",
      "\n",
      "Epoch: 6, NLL Loss: 154302810.44794953, Val Loss: 715857984.0, Time took: 0.3797733783721924\n",
      "Train loss Meta Info:  [ 1.54304819e+08 -2.10604565e+03  1.67826366e+03]\n",
      "Val Loss Meta Info:  [715797476.3243244, -90073.66891891892, 15053.224662162162]\n",
      "\n",
      "Epoch: 7, NLL Loss: 80368067.83596215, Val Loss: 544470336.0, Time took: 0.3838777542114258\n",
      "Train loss Meta Info:  [ 8.03782739e+07 -1.03263860e+04  1.76158952e+03]\n",
      "Val Loss Meta Info:  [544756929.7297298, -434690.0, 14806.047297297297]\n",
      "\n",
      "Epoch: 8, NLL Loss: 60528445.37539432, Val Loss: 496576192.0, Time took: 0.37687182426452637\n",
      "Train loss Meta Info:  [ 6.05810056e+07 -5.26993990e+04  1.73252629e+03]\n",
      "Val Loss Meta Info:  [499318396.5405405, -2890526.4864864866, 14828.552364864865]\n",
      "\n",
      "Epoch: 9, NLL Loss: 55043827.6340694, Val Loss: 443778016.0, Time took: 0.38244128227233887\n",
      "Train loss Meta Info:  [ 5.53810072e+07 -3.37336399e+05  1.73513167e+03]\n",
      "Val Loss Meta Info:  [469121743.5675676, -25497634.594594594, 15386.871621621622]\n",
      "\n",
      "Epoch: 10, NLL Loss: 48612414.20820189, Val Loss: 99260904.0, Time took: 0.3840348720550537\n",
      "Train loss Meta Info:  [ 5.17109310e+07 -3.09869693e+06  1.80030309e+03]\n",
      "Val Loss Meta Info:  [427615536.4324324, -328521783.3513514, 16714.408783783783]\n",
      "\n",
      "Epoch: 11, NLL Loss: 8601574.958990537, Val Loss: -15477593088.0, Time took: 0.36601758003234863\n",
      "Train loss Meta Info:  [ 4.75217852e+07 -3.89204254e+07  1.95557461e+03]\n",
      "Val Loss Meta Info:  [374659542.4864865, -15852453445.18919, 20133.238175675677]\n",
      "\n",
      "Epoch: 12, NLL Loss: -1670956098.2208202, Val Loss: -7553130430464.0, Time took: 0.3861353397369385\n",
      "Train loss Meta Info:  [ 4.16172612e+07 -1.71257361e+09  2.35548188e+03]\n",
      "Val Loss Meta Info:  [306078886.0540541, -7553436827205.189, 28439.29054054054]\n",
      "\n",
      "Epoch: 13, NLL Loss: -967692248616.3785, Val Loss: -1.2489021867425792e+16, Time took: 0.3693065643310547\n",
      "Train loss Meta Info:  [ 3.37058302e+07 -9.67725954e+11  3.32720468e+03]\n",
      "Val Loss Meta Info:  [249093839.56756756, -1.248902198350599e+16, 39184.99324324324]\n",
      "\n",
      "Epoch: 14, NLL Loss: -1145842149615971.2, Val Loss: -4.237933978599817e+18, Time took: 0.37281155586242676\n",
      "Train loss Meta Info:  [ 2.75557571e+07 -1.14584216e+15  4.58417616e+03]\n",
      "Val Loss Meta Info:  [204815844.3243243, -4.23793384487543e+18, 55121.27702702703]\n",
      "\n",
      "Epoch: 15, NLL Loss: -6.10131143488655e+17, Val Loss: -6.682197255413301e+18, Time took: 0.37596964836120605\n",
      "Train loss Meta Info:  [ 2.26165733e+07 -6.10131143e+17  6.44801169e+03]\n",
      "Val Loss Meta Info:  [196615181.83783785, -6.682196928531466e+18, 56156.64864864865]\n",
      "\n",
      "Epoch: 16, NLL Loss: -7.843787696430275e+17, Val Loss: -8.652745293248332e+18, Time took: 0.3697011470794678\n",
      "Train loss Meta Info:  [ 2.16697577e+07 -7.84378770e+17  6.56901792e+03]\n",
      "Val Loss Meta Info:  [187890909.4054054, -8.65274523381527e+18, 57562.7027027027]\n",
      "\n",
      "Epoch: 17, NLL Loss: -1.1553820746244175e+18, Val Loss: -1.2339835491204465e+19, Time took: 0.36151885986328125\n",
      "Train loss Meta Info:  [ 2.07537141e+07 -1.15538207e+18  6.73181360e+03]\n",
      "Val Loss Meta Info:  [180711091.8918919, -1.2339835402054873e+19, 58673.05405405405]\n",
      "\n",
      "Epoch: 18, NLL Loss: -1.509486956783468e+18, Val Loss: -1.514953520140465e+19, Time took: 0.38352060317993164\n",
      "Train loss Meta Info:  [ 2.00249990e+07 -1.50948696e+18  6.86102206e+03]\n",
      "Val Loss Meta Info:  [174693237.6216216, -1.5149534785373223e+19, 59899.91891891892]\n",
      "\n",
      "Epoch: 19, NLL Loss: -1.8588739333997238e+18, Val Loss: -1.682795179583262e+19, Time took: 0.3810884952545166\n",
      "Train loss Meta Info:  [ 1.92636319e+07 -1.85887393e+18  7.00366419e+03]\n",
      "Val Loss Meta Info:  [168378464.86486486, -1.6827951052919357e+19, 61163.41891891892]\n",
      "\n",
      "Epoch: 20, NLL Loss: -2.0656704722913098e+18, Val Loss: -2.2923900446432035e+19, Time took: 0.3701298236846924\n",
      "Train loss Meta Info:  [ 1.86347704e+07 -2.06567047e+18  7.15107612e+03]\n",
      "Val Loss Meta Info:  [162344461.83783785, -2.292390026813285e+19, 62557.43243243243]\n",
      "\n",
      "Epoch: 21, NLL Loss: -2.730134033376415e+18, Val Loss: -2.42655399278071e+19, Time took: 0.37819623947143555\n",
      "Train loss Meta Info:  [ 1.79835228e+07 -2.73013403e+18  7.31315865e+03]\n",
      "Val Loss Meta Info:  [158155872.86486486, -2.426553933347649e+19, 63989.16216216216]\n",
      "\n",
      "Epoch: 22, NLL Loss: -2.812004574456751e+18, Val Loss: -2.3928504429521666e+19, Time took: 0.3756237030029297\n",
      "Train loss Meta Info:  [ 1.74932247e+07 -2.81200457e+18  7.48026327e+03]\n",
      "Val Loss Meta Info:  [153345203.8918919, -2.3928503478592692e+19, 65645.37837837837]\n",
      "\n",
      "Epoch: 23, NLL Loss: -3.0253821205334533e+18, Val Loss: -2.9636878529864925e+19, Time took: 0.38086509704589844\n",
      "Train loss Meta Info:  [ 1.69269230e+07 -3.02538212e+18  7.67386771e+03]\n",
      "Val Loss Meta Info:  [148943955.02702704, -2.963687686573922e+19, 67532.91216216216]\n",
      "\n",
      "Epoch: 24, NLL Loss: -3.3152948015030267e+18, Val Loss: -2.976637021329136e+19, Time took: 0.3762166500091553\n",
      "Train loss Meta Info:  [ 1.64599194e+07 -3.31529480e+18  7.89371221e+03]\n",
      "Val Loss Meta Info:  [143605012.75675675, -2.9766370569889726e+19, 69564.56756756757]\n",
      "\n",
      "Epoch: 25, NLL Loss: -3.892139377013799e+18, Val Loss: -3.4038276352410386e+19, Time took: 0.3808565139770508\n",
      "Train loss Meta Info:  [ 1.59084274e+07 -3.89213938e+18  8.13215252e+03]\n",
      "Val Loss Meta Info:  [139902284.1081081, -3.4038274450552435e+19, 71389.64864864865]\n",
      "\n",
      "Epoch: 26, NLL Loss: -4.2021019889594885e+18, Val Loss: -3.5616862788594434e+19, Time took: 0.4033942222595215\n",
      "Train loss Meta Info:  [ 1.55097766e+07 -4.20210199e+18  8.34540701e+03]\n",
      "Val Loss Meta Info:  [136768345.94594595, -3.5616862194263826e+19, 72774.1081081081]\n",
      "\n",
      "Epoch: 27, NLL Loss: -3.971995255537483e+18, Val Loss: -4.018527202935256e+19, Time took: 0.37728309631347656\n",
      "Train loss Meta Info:  [ 1.51807948e+07 -3.97199526e+18  8.50860077e+03]\n",
      "Val Loss Meta Info:  [134907239.7837838, -4.0185269533163995e+19, 74255.45945945945]\n",
      "\n",
      "Epoch: 28, NLL Loss: -4.228011363076643e+18, Val Loss: -3.5387933472575193e+19, Time took: 0.38370704650878906\n",
      "Train loss Meta Info:  [ 1.48632485e+07 -4.22801136e+18  8.68322963e+03]\n",
      "Val Loss Meta Info:  [131198325.62162162, -3.5387931749016424e+19, 75853.67567567568]\n",
      "\n",
      "Epoch: 29, NLL Loss: -4.3040015356101043e+18, Val Loss: -3.793872348320157e+19, Time took: 0.3955111503601074\n",
      "Train loss Meta Info:  [ 1.45438158e+07 -4.30400154e+18  8.86999177e+03]\n",
      "Val Loss Meta Info:  [128891142.91891892, -3.793872265113871e+19, 77489.05405405405]\n",
      "\n",
      "Epoch: 30, NLL Loss: -4.2934577809952645e+18, Val Loss: -3.296429318560809e+19, Time took: 0.3711888790130615\n",
      "Train loss Meta Info:  [ 1.42736106e+07 -4.29345778e+18  9.06093610e+03]\n",
      "Val Loss Meta Info:  [126870500.32432432, -3.296429146204932e+19, 79188.17567567568]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, NLL Loss: -4.671873479167338e+18, Val Loss: -3.6828847858822152e+19, Time took: 0.3783395290374756\n",
      "Train loss Meta Info:  [ 1.39612628e+07 -4.67187348e+18  9.25954356e+03]\n",
      "Val Loss Meta Info:  [123692751.56756757, -3.682884779938909e+19, 80645.01351351352]\n",
      "\n",
      "Epoch: 32, NLL Loss: -4.3515548828323026e+18, Val Loss: -3.716851118989797e+19, Time took: 0.4096670150756836\n",
      "Train loss Meta Info:  [ 1.37244808e+07 -4.35155488e+18  9.43002073e+03]\n",
      "Val Loss Meta Info:  [121741007.56756757, -3.716850821824492e+19, 82151.24324324324]\n",
      "\n",
      "Epoch: 33, NLL Loss: -5.050017178279948e+18, Val Loss: -3.913759137970992e+19, Time took: 0.376331090927124\n",
      "Train loss Meta Info:  [ 1.34971515e+07 -5.05001718e+18  9.60704150e+03]\n",
      "Val Loss Meta Info:  [119222105.94594595, -3.913758924011972e+19, 83332.80405405405]\n",
      "\n",
      "Epoch: 34, NLL Loss: -4.2734227714671693e+18, Val Loss: -3.2955470704306815e+19, Time took: 0.3898346424102783\n",
      "Train loss Meta Info:  [ 1.32321720e+07 -4.27342277e+18  9.74676974e+03]\n",
      "Val Loss Meta Info:  [117420391.78378378, -3.2955470644873753e+19, 84608.37837837837]\n",
      "\n",
      "Epoch: 35, NLL Loss: -4.576168102375864e+18, Val Loss: -3.970349242234018e+19, Time took: 0.38013768196105957\n",
      "Train loss Meta Info:  [ 1.30715626e+07 -4.57616810e+18  9.89609427e+03]\n",
      "Val Loss Meta Info:  [115970940.54054055, -3.97034908770806e+19, 85917.31081081081]\n",
      "\n",
      "Epoch: 36, NLL Loss: -4.974163161358311e+18, Val Loss: -3.6744216249808978e+19, Time took: 0.38054370880126953\n",
      "Train loss Meta Info:  [ 1.28732118e+07 -4.97416316e+18  1.00493961e+04]\n",
      "Val Loss Meta Info:  [113865568.86486487, -3.674421512058082e+19, 87257.91216216216]\n",
      "\n",
      "Epoch: 37, NLL Loss: -4.814571164366098e+18, Val Loss: -3.7290275505604395e+19, Time took: 0.3761296272277832\n",
      "Train loss Meta Info:  [ 1.27000564e+07 -4.81457116e+18  1.02071160e+04]\n",
      "Val Loss Meta Info:  [112402099.8918919, -3.729027657539949e+19, 88642.18918918919]\n",
      "\n",
      "Epoch: 38, NLL Loss: -4.819490414073678e+18, Val Loss: -4.01592267979138e+19, Time took: 0.37106752395629883\n",
      "Train loss Meta Info:  [ 1.24792133e+07 -4.81949041e+18  1.03689734e+04]\n",
      "Val Loss Meta Info:  [110866528.86486487, -4.015922549038646e+19, 90044.1418918919]\n",
      "\n",
      "Epoch: 39, NLL Loss: -4.999341904796073e+18, Val Loss: -4.139067982102292e+19, Time took: 0.36852407455444336\n",
      "Train loss Meta Info:  [ 1.23246263e+07 -4.99934190e+18  1.05332833e+04]\n",
      "Val Loss Meta Info:  [109211371.24324325, -4.139067851349558e+19, 91457.9054054054]\n",
      "\n",
      "Epoch: 40, NLL Loss: -4.638079465545512e+18, Val Loss: -3.913081838808282e+19, Time took: 0.3675856590270996\n",
      "Train loss Meta Info:  [ 1.21441152e+07 -4.63807947e+18  1.07000022e+04]\n",
      "Val Loss Meta Info:  [108388538.8108108, -3.913081862581506e+19, 92904.91891891892]\n",
      "\n",
      "Epoch: 41, NLL Loss: -5.349621471541889e+18, Val Loss: -4.5803442195753075e+19, Time took: 0.36751556396484375\n",
      "Train loss Meta Info:  [ 1.19884375e+07 -5.34962147e+18  1.08693455e+04]\n",
      "Val Loss Meta Info:  [106981389.83783785, -4.580344160142247e+19, 94002.52027027027]\n",
      "\n",
      "Epoch: 42, NLL Loss: -5.319685259219433e+18, Val Loss: -5.127345976738054e+19, Time took: 0.36774682998657227\n",
      "Train loss Meta Info:  [ 1.18388847e+07 -5.31968526e+18  1.09980344e+04]\n",
      "Val Loss Meta Info:  [105506013.4054054, -5.1273458935317684e+19, 95110.87162162163]\n",
      "\n",
      "Epoch: 43, NLL Loss: -5.07625339176681e+18, Val Loss: -4.741187377556147e+19, Time took: 0.36774396896362305\n",
      "Train loss Meta Info:  [ 1.16636068e+07 -5.07625339e+18  1.11276251e+04]\n",
      "Val Loss Meta Info:  [104474001.2972973, -4.741187330009698e+19, 96230.2027027027]\n",
      "\n",
      "Epoch: 44, NLL Loss: -5.627694302607877e+18, Val Loss: -4.563476831595921e+19, Time took: 0.3704073429107666\n",
      "Train loss Meta Info:  [ 1.15581876e+07 -5.62769430e+18  1.12582245e+04]\n",
      "Val Loss Meta Info:  [102989145.94594595, -4.563476581977065e+19, 97175.85135135135]\n",
      "\n",
      "Epoch: 45, NLL Loss: -5.511030284899083e+18, Val Loss: -3.467394360684629e+19, Time took: 0.367877721786499\n",
      "Train loss Meta Info:  [ 1.14087884e+07 -5.51103028e+18  1.13688189e+04]\n",
      "Val Loss Meta Info:  [102338656.86486487, -3.4673943844578537e+19, 98134.48648648648]\n",
      "\n",
      "Epoch: 46, NLL Loss: -3.9222013186643154e+18, Val Loss: -3.584925116819466e+19, Time took: 0.36887073516845703\n",
      "Train loss Meta Info:  [ 1.13350578e+07 -3.92220132e+18  1.14805683e+04]\n",
      "Val Loss Meta Info:  [100551320.21621622, -3.5849250217265684e+19, 99078.71621621621]\n",
      "\n",
      "Epoch: 47, NLL Loss: -4.10043708225243e+18, Val Loss: -3.932225215857164e+19, Time took: 0.3667640686035156\n",
      "Train loss Meta Info:  [ 1.11693429e+07 -4.10043708e+18  1.15912315e+04]\n",
      "Val Loss Meta Info:  [100378783.13513513, -3.932225203970552e+19, 100035.46621621621]\n",
      "\n",
      "Epoch: 48, NLL Loss: -4.5052954176811295e+18, Val Loss: -4.504553123854103e+19, Time took: 0.3685910701751709\n",
      "Train loss Meta Info:  [ 1.10572095e+07 -4.50529542e+18  1.17031710e+04]\n",
      "Val Loss Meta Info:  [99241029.1891892, -4.504553218947001e+19, 100973.0]\n",
      "\n",
      "Epoch: 49, NLL Loss: -4.3395213281152266e+18, Val Loss: -3.717549088971109e+19, Time took: 0.3768503665924072\n",
      "Train loss Meta Info:  [ 1.09870485e+07 -4.33952133e+18  1.18132390e+04]\n",
      "Val Loss Meta Info:  [98896245.62162162, -3.7175491840640066e+19, 101921.19594594595]\n",
      "\n",
      "Epoch: 50, NLL Loss: -4.575793984006163e+18, Val Loss: -3.994337507319533e+19, Time took: 0.3673269748687744\n",
      "Train loss Meta Info:  [ 1.08794808e+07 -4.57579398e+18  1.19235081e+04]\n",
      "Val Loss Meta Info:  [97214173.4054054, -3.99433760241243e+19, 102869.87162162163]\n",
      "\n",
      "Epoch: 51, NLL Loss: -4.391580401149741e+18, Val Loss: -4.4477457560934285e+19, Time took: 0.36865663528442383\n",
      "Train loss Meta Info:  [ 1.07493457e+07 -4.39158040e+18  1.20342534e+04]\n",
      "Val Loss Meta Info:  [96771182.7027027, -4.447745863072938e+19, 103824.46621621621]\n",
      "\n",
      "Epoch: 52, NLL Loss: -4.4478459663462523e+18, Val Loss: -3.6357572985901548e+19, Time took: 0.368375301361084\n",
      "Train loss Meta Info:  [ 1.06601107e+07 -4.44784597e+18  1.21459267e+04]\n",
      "Val Loss Meta Info:  [95768250.8108108, -3.635757120290972e+19, 104793.42567567568]\n",
      "\n",
      "Epoch: 53, NLL Loss: -4.66905299598471e+18, Val Loss: -4.289759569126202e+19, Time took: 0.3673219680786133\n",
      "Train loss Meta Info:  [ 1.05807839e+07 -4.66905300e+18  1.22593171e+04]\n",
      "Val Loss Meta Info:  [94346419.8918919, -4.289759283847509e+19, 105754.67567567568]\n",
      "\n",
      "Epoch: 54, NLL Loss: -4.937739223446063e+18, Val Loss: -4.4710224172534465e+19, Time took: 0.3679463863372803\n",
      "Train loss Meta Info:  [ 1.04454048e+07 -4.93773922e+18  1.23717997e+04]\n",
      "Val Loss Meta Info:  [93978464.86486487, -4.471022322160549e+19, 106722.1081081081]\n",
      "\n",
      "Epoch: 55, NLL Loss: -4.64478321915648e+18, Val Loss: -3.808946652736966e+19, Time took: 0.36853480339050293\n",
      "Train loss Meta Info:  [ 1.03457985e+07 -4.64478322e+18  1.24849762e+04]\n",
      "Val Loss Meta Info:  [92575875.45945945, -3.808946771603087e+19, 107695.31756756757]\n",
      "\n",
      "Epoch: 56, NLL Loss: -4.800424882448042e+18, Val Loss: -3.5235974368546783e+19, Time took: 0.3677361011505127\n",
      "Train loss Meta Info:  [ 1.02775599e+07 -4.80042488e+18  1.25988207e+04]\n",
      "Val Loss Meta Info:  [92242508.1081081, -3.5235973298751685e+19, 108673.9527027027]\n",
      "\n",
      "Epoch: 57, NLL Loss: -5.243340828895391e+18, Val Loss: -4.140357049534697e+19, Time took: 0.3705003261566162\n",
      "Train loss Meta Info:  [ 1.01623746e+07 -5.24334083e+18  1.27135342e+04]\n",
      "Val Loss Meta Info:  [91584290.5945946, -4.140356930668575e+19, 109668.55405405405]\n",
      "\n",
      "Epoch: 58, NLL Loss: -4.895961198054151e+18, Val Loss: -4.264644084719891e+19, Time took: 0.368056058883667\n",
      "Train loss Meta Info:  [ 1.01237425e+07 -4.89596120e+18  1.28296202e+04]\n",
      "Val Loss Meta Info:  [89913939.02702703, -4.264644108493115e+19, 110669.55405405405]\n",
      "\n",
      "Epoch: 59, NLL Loss: -5.308111605589971e+18, Val Loss: -4.135148443051596e+19, Time took: 0.36738038063049316\n",
      "Train loss Meta Info:  [ 9.96153078e+06 -5.30811161e+18  1.29466818e+04]\n",
      "Val Loss Meta Info:  [89461801.51351352, -4.135148502484657e+19, 111686.35135135135]\n",
      "\n",
      "Epoch: 60, NLL Loss: -4.950161967125972e+18, Val Loss: -5.215134503536899e+19, Time took: 0.37140583992004395\n",
      "Train loss Meta Info:  [ 9.92239162e+06 -4.95016197e+18  1.30655697e+04]\n",
      "Val Loss Meta Info:  [88996760.21621622, -5.215134515423511e+19, 112711.87837837837]\n",
      "\n",
      "Epoch: 61, NLL Loss: -5.293952982781152e+18, Val Loss: -4.383022784222069e+19, Time took: 0.38454580307006836\n",
      "Train loss Meta Info:  [ 9.78405644e+06 -5.29395298e+18  1.31853970e+04]\n",
      "Val Loss Meta Info:  [88022908.54054055, -4.383022594036274e+19, 113751.13513513513]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, NLL Loss: -5.397895963120762e+18, Val Loss: -5.043830152124747e+19, Time took: 0.35905933380126953\n",
      "Train loss Meta Info:  [ 9.79387322e+06 -5.39789596e+18  1.33066270e+04]\n",
      "Val Loss Meta Info:  [87163281.2972973, -5.043829985712176e+19, 114791.3918918919]\n",
      "\n",
      "Epoch: 63, NLL Loss: -5.051538482685387e+18, Val Loss: -5.508151273706645e+19, Time took: 0.3579444885253906\n",
      "Train loss Meta Info:  [ 9.64862013e+06 -5.05153848e+18  1.34287277e+04]\n",
      "Val Loss Meta Info:  [85892400.43243243, -5.5081511072940745e+19, 115845.25675675676]\n",
      "\n",
      "Epoch: 64, NLL Loss: -5.215434748599177e+18, Val Loss: -4.957073407037407e+19, Time took: 0.3403048515319824\n",
      "Train loss Meta Info:  [ 9.59150596e+06 -5.21543475e+18  1.35514299e+04]\n",
      "Val Loss Meta Info:  [85692685.83783785, -4.95707331194451e+19, 116900.1081081081]\n",
      "\n",
      "Epoch: 65, NLL Loss: -5.771758052963102e+18, Val Loss: -4.684281493553624e+19, Time took: 0.3378565311431885\n",
      "Train loss Meta Info:  [ 9.47954069e+06 -5.77175805e+18  1.36744366e+04]\n",
      "Val Loss Meta Info:  [85347888.43243243, -4.684281457893787e+19, 117960.6081081081]\n",
      "\n",
      "Epoch: 66, NLL Loss: -6.154151922944108e+18, Val Loss: -6.3761255438823195e+19, Time took: 0.3376584053039551\n",
      "Train loss Meta Info:  [ 9.37920877e+06 -6.15415192e+18  1.37996208e+04]\n",
      "Val Loss Meta Info:  [84032048.43243243, -6.37612560331538e+19, 118918.68918918919]\n",
      "\n",
      "Epoch: 67, NLL Loss: -6.223185416038812e+18, Val Loss: -5.122988392254852e+19, Time took: 0.33858418464660645\n",
      "Train loss Meta Info:  [ 9.32689060e+06 -6.22318542e+18  1.39116656e+04]\n",
      "Val Loss Meta Info:  [83351095.35135135, -5.122988356595016e+19, 119892.83783783784]\n",
      "\n",
      "Epoch: 68, NLL Loss: -6.568517870689333e+18, Val Loss: -5.021715894657614e+19, Time took: 0.33876657485961914\n",
      "Train loss Meta Info:  [ 9.21843540e+06 -6.56851787e+18  1.40255830e+04]\n",
      "Val Loss Meta Info:  [82778499.45945945, -5.0217155618324726e+19, 120820.67567567568]\n",
      "\n",
      "Epoch: 69, NLL Loss: -5.762533171217008e+18, Val Loss: -5.434895211994441e+19, Time took: 0.3387289047241211\n",
      "Train loss Meta Info:  [ 9.17898257e+06 -5.76253317e+18  1.41340579e+04]\n",
      "Val Loss Meta Info:  [81532554.37837838, -5.434894962375585e+19, 121757.37837837837]\n",
      "\n",
      "Epoch: 70, NLL Loss: -6.655522357597904e+18, Val Loss: -5.032300673195888e+19, Time took: 0.3381917476654053\n",
      "Train loss Meta Info:  [ 9.11972631e+06 -6.65552236e+18  1.42433662e+04]\n",
      "Val Loss Meta Info:  [82107198.27027027, -5.032300542443154e+19, 122710.24324324324]\n",
      "\n",
      "Epoch: 71, NLL Loss: -6.276527685044268e+18, Val Loss: -5.943020876826935e+19, Time took: 0.33862781524658203\n",
      "Train loss Meta Info:  [ 9.01307485e+06 -6.27652769e+18  1.43544460e+04]\n",
      "Val Loss Meta Info:  [80904351.13513513, -5.9430208173938745e+19, 123669.94594594595]\n",
      "\n",
      "Epoch: 72, NLL Loss: -6.178950710541916e+18, Val Loss: -5.908035296440405e+19, Time took: 0.33946824073791504\n",
      "Train loss Meta Info:  [ 8.96078344e+06 -6.17895071e+18  1.44666637e+04]\n",
      "Val Loss Meta Info:  [80655000.21621622, -5.9080349992751006e+19, 124630.63513513513]\n",
      "\n",
      "Epoch: 73, NLL Loss: -5.933669977868032e+18, Val Loss: -4.570754279157845e+19, Time took: 0.3384056091308594\n",
      "Train loss Meta Info:  [ 8.87114886e+06 -5.93366998e+18  1.45793848e+04]\n",
      "Val Loss Meta Info:  [79613052.54054055, -4.570754231611396e+19, 125601.04054054055]\n",
      "\n",
      "Epoch: 74, NLL Loss: -6.437699003889863e+18, Val Loss: -5.5312867575736566e+19, Time took: 0.33858656883239746\n",
      "Train loss Meta Info:  [ 8.82531632e+06 -6.43769900e+18  1.46925786e+04]\n",
      "Val Loss Meta Info:  [79007093.62162162, -5.53128682889333e+19, 126578.43243243243]\n",
      "\n",
      "Epoch: 75, NLL Loss: -7.043982333815586e+18, Val Loss: -6.0683898314538615e+19, Time took: 0.3385322093963623\n",
      "Train loss Meta Info:  [ 8.74865992e+06 -7.04398233e+18  1.48069310e+04]\n",
      "Val Loss Meta Info:  [77908694.48648648, -6.068389772020801e+19, 127570.1081081081]\n",
      "\n",
      "Epoch: 76, NLL Loss: -6.222148316436998e+18, Val Loss: -5.552829708798997e+19, Time took: 0.3382272720336914\n",
      "Train loss Meta Info:  [ 8.67575264e+06 -6.22214832e+18  1.49229545e+04]\n",
      "Val Loss Meta Info:  [77370298.8108108, -5.552829554273039e+19, 128563.22972972973]\n",
      "\n",
      "Epoch: 77, NLL Loss: -6.615937545739219e+18, Val Loss: -4.820534293881579e+19, Time took: 0.33820152282714844\n",
      "Train loss Meta Info:  [ 8.61022247e+06 -6.61593755e+18  1.50392326e+04]\n",
      "Val Loss Meta Info:  [76888202.37837838, -4.820533984829662e+19, 129572.9054054054]\n",
      "\n",
      "Epoch: 78, NLL Loss: -6.322541296300176e+18, Val Loss: -5.9485989192169685e+19, Time took: 0.3386211395263672\n",
      "Train loss Meta Info:  [ 8.53675938e+06 -6.32254130e+18  1.51568052e+04]\n",
      "Val Loss Meta Info:  [76446291.02702703, -5.948598966763418e+19, 130582.13513513513]\n",
      "\n",
      "Epoch: 79, NLL Loss: -6.325247128514806e+18, Val Loss: -7.001047491082296e+19, Time took: 0.34151530265808105\n",
      "Train loss Meta Info:  [ 8.47581150e+06 -6.32524713e+18  1.52748558e+04]\n",
      "Val Loss Meta Info:  [76176999.78378378, -7.001047217690215e+19, 131596.0945945946]\n",
      "\n",
      "Epoch: 80, NLL Loss: -5.988558527882182e+18, Val Loss: -6.064418835258986e+19, Time took: 0.34267425537109375\n",
      "Train loss Meta Info:  [ 8.42543289e+06 -5.98855853e+18  1.53933737e+04]\n",
      "Val Loss Meta Info:  [76125737.51351352, -6.064418692619639e+19, 132612.97297297296]\n",
      "\n",
      "Epoch: 81, NLL Loss: -6.505544157303834e+18, Val Loss: -5.943709610910574e+19, Time took: 0.33968615531921387\n",
      "Train loss Meta Info:  [ 8.32716834e+06 -6.50554416e+18  1.55119915e+04]\n",
      "Val Loss Meta Info:  [74689487.56756757, -5.943709289972045e+19, 133633.93243243243]\n",
      "\n",
      "Epoch: 82, NLL Loss: -7.297854400617565e+18, Val Loss: -5.427086040609325e+19, Time took: 0.33850884437561035\n",
      "Train loss Meta Info:  [ 8.28162903e+06 -7.29785440e+18  1.56316031e+04]\n",
      "Val Loss Meta Info:  [73539514.8108108, -5.427085933629815e+19, 134404.87837837837]\n",
      "\n",
      "Epoch: 83, NLL Loss: -6.4005556211815e+18, Val Loss: -5.984278951147602e+19, Time took: 0.3394961357116699\n",
      "Train loss Meta Info:  [ 8.20494115e+06 -6.40055562e+18  1.57221002e+04]\n",
      "Val Loss Meta Info:  [73428881.2972973, -5.984278963034214e+19, 135179.3918918919]\n",
      "\n",
      "Epoch: 84, NLL Loss: -6.860759605171284e+18, Val Loss: -6.87382915789745e+19, Time took: 0.33893442153930664\n",
      "Train loss Meta Info:  [ 8.15978179e+06 -6.86075961e+18  1.58127417e+04]\n",
      "Val Loss Meta Info:  [73266030.7027027, -6.873828896391982e+19, 135956.24324324325]\n",
      "\n",
      "Epoch: 85, NLL Loss: -6.26080429417005e+18, Val Loss: -4.942463976136822e+19, Time took: 0.3490867614746094\n",
      "Train loss Meta Info:  [ 8.12362350e+06 -6.26080429e+18  1.59037846e+04]\n",
      "Val Loss Meta Info:  [71593956.32432432, -4.942463999910046e+19, 136728.7837837838]\n",
      "\n",
      "Epoch: 86, NLL Loss: -6.587956320586804e+18, Val Loss: -6.6512347880728035e+19, Time took: 0.3510782718658447\n",
      "Train loss Meta Info:  [ 8.03298138e+06 -6.58795632e+18  1.59943140e+04]\n",
      "Val Loss Meta Info:  [71727325.4054054, -6.651234681093294e+19, 137505.45945945947]\n",
      "\n",
      "Epoch: 87, NLL Loss: -7.175645951583337e+18, Val Loss: -6.155823875703911e+19, Time took: 0.34824204444885254\n",
      "Train loss Meta Info:  [ 7.99337885e+06 -7.17564595e+18  1.60851856e+04]\n",
      "Val Loss Meta Info:  [71262263.35135135, -6.155823507218933e+19, 138292.2837837838]\n",
      "\n",
      "Epoch: 88, NLL Loss: -6.432978318351579e+18, Val Loss: -6.310670297266861e+19, Time took: 0.348116397857666\n",
      "Train loss Meta Info:  [ 7.92330534e+06 -6.43297832e+18  1.61772482e+04]\n",
      "Val Loss Meta Info:  [71142759.78378378, -6.310670118967678e+19, 139077.8918918919]\n",
      "\n",
      "Epoch: 89, NLL Loss: -6.603253822395561e+18, Val Loss: -5.899687364357679e+19, Time took: 0.3483607769012451\n",
      "Train loss Meta Info:  [ 7.89754366e+06 -6.60325382e+18  1.62692324e+04]\n",
      "Val Loss Meta Info:  [70425212.54054055, -5.899687364357679e+19, 139862.64864864864]\n",
      "\n",
      "Epoch: 90, NLL Loss: -7.006287419425975e+18, Val Loss: -6.225055285053804e+19, Time took: 0.353283166885376\n",
      "Train loss Meta Info:  [ 7.80986845e+06 -7.00628742e+18  1.63612093e+04]\n",
      "Val Loss Meta Info:  [71182432.86486487, -6.22505532071364e+19, 140648.98648648648]\n",
      "\n",
      "Epoch: 91, NLL Loss: -7.057429388771214e+18, Val Loss: -4.893355828598486e+19, Time took: 0.35413694381713867\n",
      "Train loss Meta Info:  [ 7.76823738e+06 -7.05742939e+18  1.64531596e+04]\n",
      "Val Loss Meta Info:  [69989299.8918919, -4.8933557453922e+19, 141444.43243243243]\n",
      "\n",
      "Epoch: 92, NLL Loss: -7.217860961743227e+18, Val Loss: -6.0622193721987826e+19, Time took: 0.3575596809387207\n",
      "Train loss Meta Info:  [ 7.67723764e+06 -7.21786096e+18  1.65458946e+04]\n",
      "Val Loss Meta Info:  [69024159.13513513, -6.062219384085395e+19, 142250.64864864864]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, NLL Loss: -6.725872989315882e+18, Val Loss: -6.28100767257272e+19, Time took: 0.40389180183410645\n",
      "Train loss Meta Info:  [ 7.64813799e+06 -6.72587299e+18  1.66400908e+04]\n",
      "Val Loss Meta Info:  [68656003.45945945, -6.281007601253047e+19, 143052.02702702704]\n",
      "\n",
      "Epoch: 94, NLL Loss: -7.073936311748634e+18, Val Loss: -6.057273329092395e+19, Time took: 0.3958902359008789\n",
      "Train loss Meta Info:  [ 7.58647401e+06 -7.07393631e+18  1.67339219e+04]\n",
      "Val Loss Meta Info:  [68330876.54054055, -6.05727303192709e+19, 143856.16216216216]\n",
      "\n",
      "Epoch: 95, NLL Loss: -6.877540774790296e+18, Val Loss: -6.1137965830484525e+19, Time took: 0.3834645748138428\n",
      "Train loss Meta Info:  [ 7.51150638e+06 -6.87754077e+18  1.68281278e+04]\n",
      "Val Loss Meta Info:  [67841024.0, -6.113796630594902e+19, 144663.7027027027]\n",
      "\n",
      "Epoch: 96, NLL Loss: -7.645281691992802e+18, Val Loss: -5.853234317498096e+19, Time took: 0.3840293884277344\n",
      "Train loss Meta Info:  [ 7.50225627e+06 -7.64528169e+18  1.69227127e+04]\n",
      "Val Loss Meta Info:  [67531388.54054055, -5.853234103539076e+19, 145143.1891891892]\n",
      "\n",
      "Epoch: 97, NLL Loss: -7.48014232933182e+18, Val Loss: -6.1503751358813045e+19, Time took: 0.38828444480895996\n",
      "Train loss Meta Info:  [ 7.43656849e+06 -7.48014233e+18  1.69788977e+04]\n",
      "Val Loss Meta Info:  [66762959.567567565, -6.150375064561631e+19, 145621.35135135136]\n",
      "\n",
      "Epoch: 98, NLL Loss: -7.04000259424875e+18, Val Loss: -6.312913300987524e+19, Time took: 0.39911818504333496\n",
      "Train loss Meta Info:  [ 7.36077435e+06 -7.04000259e+18  1.70349161e+04]\n",
      "Val Loss Meta Info:  [65940673.72972973, -6.31291317023479e+19, 146100.1081081081]\n",
      "\n",
      "Epoch: 99, NLL Loss: -7.0429504300132e+18, Val Loss: -6.473644748586982e+19, Time took: 0.3864119052886963\n",
      "Train loss Meta Info:  [ 7.33651004e+06 -7.04295043e+18  1.70909850e+04]\n",
      "Val Loss Meta Info:  [65359705.94594595, -6.473644510854738e+19, 146575.5945945946]\n",
      "\n",
      "Epoch: 100, NLL Loss: -7.624487117633897e+18, Val Loss: -6.281429445233135e+19, Time took: 0.3856945037841797\n",
      "Train loss Meta Info:  [ 7.28913219e+06 -7.62448712e+18  1.71466466e+04]\n",
      "Val Loss Meta Info:  [65440851.027027026, -6.281429433346522e+19, 147058.9189189189]\n",
      "\n",
      "Epoch: 101, NLL Loss: -7.318788415249214e+18, Val Loss: -6.46451044578807e+19, Time took: 0.3854093551635742\n",
      "Train loss Meta Info:  [ 7.24809953e+06 -7.31878842e+18  1.72032115e+04]\n",
      "Val Loss Meta Info:  [64918777.08108108, -6.464510267488887e+19, 147540.56756756757]\n",
      "\n",
      "Epoch: 102, NLL Loss: -7.74459774010422e+18, Val Loss: -7.059885436917147e+19, Time took: 0.3957362174987793\n",
      "Train loss Meta Info:  [ 7.16439929e+06 -7.74459774e+18  1.72595789e+04]\n",
      "Val Loss Meta Info:  [64703695.567567565, -7.0598853774840865e+19, 148029.27027027027]\n",
      "\n",
      "Epoch: 103, NLL Loss: -7.730767604198304e+18, Val Loss: -6.039790214601454e+19, Time took: 0.3612997531890869\n",
      "Train loss Meta Info:  [ 7.15526991e+06 -7.73076760e+18  1.73168663e+04]\n",
      "Val Loss Meta Info:  [64565026.5945946, -6.039790012529047e+19, 148523.37837837837]\n",
      "\n",
      "Epoch: 104, NLL Loss: -7.515793810032437e+18, Val Loss: -6.362455095911855e+19, Time took: 0.3465151786804199\n",
      "Train loss Meta Info:  [ 7.10346062e+06 -7.51579381e+18  1.73747831e+04]\n",
      "Val Loss Meta Info:  [63015313.2972973, -6.362455048365406e+19, 149024.35135135136]\n",
      "\n",
      "Epoch: 105, NLL Loss: -7.736499306286537e+18, Val Loss: -6.885655504965809e+19, Time took: 0.34394288063049316\n",
      "Train loss Meta Info:  [ 7.05441304e+06 -7.73649931e+18  1.74335092e+04]\n",
      "Val Loss Meta Info:  [63559596.972972974, -6.8856554098729116e+19, 149516.48648648648]\n",
      "\n",
      "Epoch: 106, NLL Loss: -7.529644292106203e+18, Val Loss: -5.84031593548103e+19, Time took: 0.34382081031799316\n",
      "Train loss Meta Info:  [ 7.00650174e+06 -7.52964429e+18  1.74928658e+04]\n",
      "Val Loss Meta Info:  [62401833.51351351, -5.840315923594418e+19, 150024.54054054053]\n",
      "\n",
      "Epoch: 107, NLL Loss: -7.311505673382721e+18, Val Loss: -5.804302531624855e+19, Time took: 0.3569951057434082\n",
      "Train loss Meta Info:  [ 6.92824825e+06 -7.31150567e+18  1.75522861e+04]\n",
      "Val Loss Meta Info:  [62852441.94594595, -5.80430234143906e+19, 150531.4054054054]\n",
      "\n",
      "Epoch: 108, NLL Loss: -7.452588470822007e+18, Val Loss: -6.902394909791722e+19, Time took: 0.34112095832824707\n",
      "Train loss Meta Info:  [ 6.90886230e+06 -7.45258847e+18  1.76115521e+04]\n",
      "Val Loss Meta Info:  [62011800.216216214, -6.902394802812212e+19, 151037.17567567568]\n",
      "\n",
      "Epoch: 109, NLL Loss: -6.935341754213386e+18, Val Loss: -6.695229326932679e+19, Time took: 0.34510374069213867\n",
      "Train loss Meta Info:  [ 6.86315960e+06 -6.93534175e+18  1.76706339e+04]\n",
      "Val Loss Meta Info:  [61836343.35135135, -6.695229219953169e+19, 151535.14864864864]\n",
      "\n",
      "Epoch: 110, NLL Loss: -7.584278039838966e+18, Val Loss: -5.4627660725399585e+19, Time took: 0.34407591819763184\n",
      "Train loss Meta Info:  [ 6.82559634e+06 -7.58427804e+18  1.77288116e+04]\n",
      "Val Loss Meta Info:  [60842800.432432435, -5.462765929900612e+19, 152033.35135135136]\n",
      "\n",
      "Epoch: 111, NLL Loss: -8.000620361469364e+18, Val Loss: -7.531571087381889e+19, Time took: 0.3483712673187256\n",
      "Train loss Meta Info:  [ 6.76730338e+06 -8.00062036e+18  1.77870779e+04]\n",
      "Val Loss Meta Info:  [60592999.783783786, -7.53157049305128e+19, 152473.5]\n",
      "\n",
      "Epoch: 112, NLL Loss: -7.490602743046368e+18, Val Loss: -5.9569609250485305e+19, Time took: 0.35019850730895996\n",
      "Train loss Meta Info:  [ 6.75914574e+06 -7.49060274e+18  1.78385573e+04]\n",
      "Val Loss Meta Info:  [60848716.10810811, -5.956960675429674e+19, 152914.64864864864]\n",
      "\n",
      "Epoch: 113, NLL Loss: -7.821964220247891e+18, Val Loss: -6.584518621522611e+19, Time took: 0.34749817848205566\n",
      "Train loss Meta Info:  [ 6.74053103e+06 -7.82196422e+18  1.78901542e+04]\n",
      "Val Loss Meta Info:  [60000975.567567565, -6.584518264924246e+19, 153353.5]\n",
      "\n",
      "Epoch: 114, NLL Loss: -7.502035596754639e+18, Val Loss: -6.621836046169329e+19, Time took: 0.3496685028076172\n",
      "Train loss Meta Info:  [ 6.65328124e+06 -7.50203560e+18  1.79417915e+04]\n",
      "Val Loss Meta Info:  [59346715.675675675, -6.621835760890636e+19, 153793.48648648648]\n",
      "\n",
      "Epoch: 115, NLL Loss: -7.585407560850349e+18, Val Loss: -6.8490149396771504e+19, Time took: 0.3431856632232666\n",
      "Train loss Meta Info:  [ 6.60528433e+06 -7.58540756e+18  1.79929860e+04]\n",
      "Val Loss Meta Info:  [59514354.16216216, -6.849014975336987e+19, 154228.6081081081]\n",
      "\n",
      "Epoch: 116, NLL Loss: -7.810586175633444e+18, Val Loss: -6.515774515726149e+19, Time took: 0.3700544834136963\n",
      "Train loss Meta Info:  [ 6.54821616e+06 -7.81058618e+18  1.80439424e+04]\n",
      "Val Loss Meta Info:  [59054183.783783786, -6.5157744681797e+19, 154667.67567567568]\n",
      "\n",
      "Epoch: 117, NLL Loss: -7.257246432490643e+18, Val Loss: -6.916760688915592e+19, Time took: 0.35015296936035156\n",
      "Train loss Meta Info:  [ 6.54516737e+06 -7.25724643e+18  1.80955424e+04]\n",
      "Val Loss Meta Info:  [58535998.27027027, -6.9167606770289795e+19, 155109.16216216216]\n",
      "\n",
      "Epoch: 118, NLL Loss: -7.615104107385878e+18, Val Loss: -7.131778983820211e+19, Time took: 0.34513211250305176\n",
      "Train loss Meta Info:  [ 6.47522514e+06 -7.61510411e+18  1.81470320e+04]\n",
      "Val Loss Meta Info:  [58193926.91891892, -7.13177865099507e+19, 155553.72972972973]\n",
      "\n",
      "Epoch: 119, NLL Loss: -7.208371496571296e+18, Val Loss: -6.182056903728693e+19, Time took: 0.3472442626953125\n",
      "Train loss Meta Info:  [ 6.47284603e+06 -7.20837150e+18  1.81990168e+04]\n",
      "Val Loss Meta Info:  [58400947.89189189, -6.182056594676776e+19, 155980.2162162162]\n",
      "\n",
      "Epoch: 120, NLL Loss: -7.010183783407611e+18, Val Loss: -7.834540197001612e+19, Time took: 0.35247206687927246\n",
      "Train loss Meta Info:  [ 6.43406818e+06 -7.01018378e+18  1.82500489e+04]\n",
      "Val Loss Meta Info:  [57342758.05405405, -7.834540268321286e+19, 156413.83783783784]\n",
      "\n",
      "Epoch: 121, NLL Loss: -7.440389254040686e+18, Val Loss: -6.9634041711891055e+19, Time took: 0.38170433044433594\n",
      "Train loss Meta Info:  [ 6.39094227e+06 -7.44038925e+18  1.83007103e+04]\n",
      "Val Loss Meta Info:  [57520003.45945946, -6.963404123642656e+19, 156850.2162162162]\n",
      "\n",
      "Epoch: 122, NLL Loss: -7.675357223190819e+18, Val Loss: -4.476617612024873e+19, Time took: 0.3925299644470215\n",
      "Train loss Meta Info:  [ 6.33621320e+06 -7.67535722e+18  1.83517438e+04]\n",
      "Val Loss Meta Info:  [56854784.0, -4.476617588251649e+19, 157272.85135135136]\n",
      "\n",
      "Epoch: 123, NLL Loss: -6.707703046330225e+18, Val Loss: -6.16902065406513e+19, Time took: 0.3654487133026123\n",
      "Train loss Meta Info:  [ 6.35584224e+06 -6.70770305e+18  1.84025389e+04]\n",
      "Val Loss Meta Info:  [56493440.0, -6.169020499539172e+19, 157695.51351351352]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124, NLL Loss: -6.843215332860704e+18, Val Loss: -6.454226053826504e+19, Time took: 0.34308815002441406\n",
      "Train loss Meta Info:  [ 6.27607477e+06 -6.84321533e+18  1.84527571e+04]\n",
      "Val Loss Meta Info:  [56130127.567567565, -6.454225780434424e+19, 158137.32432432432]\n",
      "\n",
      "Epoch: 125, NLL Loss: -7.527424964304692e+18, Val Loss: -6.009210597209748e+19, Time took: 0.34441256523132324\n",
      "Train loss Meta Info:  [ 6.22448277e+06 -7.52742496e+18  1.85023671e+04]\n",
      "Val Loss Meta Info:  [56212120.216216214, -6.009210418910565e+19, 158566.05405405405]\n",
      "\n",
      "Epoch: 126, NLL Loss: -6.389590920100787e+18, Val Loss: -5.961607461187512e+19, Time took: 0.3758084774017334\n",
      "Train loss Meta Info:  [ 6.20890902e+06 -6.38959092e+18  1.85525044e+04]\n",
      "Val Loss Meta Info:  [55979741.4054054, -5.961607294774941e+19, 158988.87837837837]\n",
      "\n",
      "Epoch: 127, NLL Loss: -6.983811792374438e+18, Val Loss: -5.916100873937119e+19, Time took: 0.3736100196838379\n",
      "Train loss Meta Info:  [ 6.13320439e+06 -6.98381179e+18  1.86019779e+04]\n",
      "Val Loss Meta Info:  [54739369.51351351, -5.9161007788442214e+19, 159396.1891891892]\n",
      "\n",
      "Epoch: 128, NLL Loss: -6.414699502903826e+18, Val Loss: -5.168296627607595e+19, Time took: 0.36003828048706055\n",
      "Train loss Meta Info:  [ 6.11060937e+06 -6.41469950e+18  1.86510258e+04]\n",
      "Val Loss Meta Info:  [54713503.13513514, -5.168296698927268e+19, 159806.63513513515]\n",
      "\n",
      "Epoch: 129, NLL Loss: -6.297519956449735e+18, Val Loss: -5.621863645860541e+19, Time took: 0.34876298904418945\n",
      "Train loss Meta Info:  [ 6.09862464e+06 -6.29751996e+18  1.86990633e+04]\n",
      "Val Loss Meta Info:  [55230879.13513514, -5.621863574540868e+19, 160210.2162162162]\n",
      "\n",
      "Epoch: 130, NLL Loss: -6.887616886645746e+18, Val Loss: -5.227866848186545e+19, Time took: 0.3442401885986328\n",
      "Train loss Meta Info:  [ 6.05443009e+06 -6.88761689e+18  1.87463029e+04]\n",
      "Val Loss Meta Info:  [54169077.62162162, -5.227866693660587e+19, 160617.83783783784]\n",
      "\n",
      "Epoch: 131, NLL Loss: -6.624876769508531e+18, Val Loss: -5.7548935577051595e+19, Time took: 0.3515317440032959\n",
      "Train loss Meta Info:  [ 6.03362244e+06 -6.62487677e+18  1.87940206e+04]\n",
      "Val Loss Meta Info:  [53879244.10810811, -5.754893593364996e+19, 161020.94594594595]\n",
      "\n",
      "Epoch: 132, NLL Loss: -6.256069443314771e+18, Val Loss: -5.612498005815145e+19, Time took: 0.34786534309387207\n",
      "Train loss Meta Info:  [ 5.95638655e+06 -6.25606944e+18  1.88412053e+04]\n",
      "Val Loss Meta Info:  [54241324.972972974, -5.612497684876616e+19, 161419.2837837838]\n",
      "\n",
      "Epoch: 133, NLL Loss: -7.007808279864573e+18, Val Loss: -5.6730481111567696e+19, Time took: 0.3462972640991211\n",
      "Train loss Meta Info:  [ 5.93638551e+06 -7.00780828e+18  1.88878260e+04]\n",
      "Val Loss Meta Info:  [54066016.86486486, -5.67304789719775e+19, 161316.8108108108]\n",
      "\n",
      "Epoch: 134, NLL Loss: -6.370647462013763e+18, Val Loss: -5.987987383965765e+19, Time took: 0.34204816818237305\n",
      "Train loss Meta Info:  [ 5.94077800e+06 -6.37064746e+18  1.88761480e+04]\n",
      "Val Loss Meta Info:  [52859039.13513514, -5.987987205666582e+19, 161733.24324324325]\n",
      "\n",
      "Epoch: 135, NLL Loss: -6.169712821954799e+18, Val Loss: -5.3390868473825985e+19, Time took: 0.34508657455444336\n",
      "Train loss Meta Info:  [ 5.85602892e+06 -6.16971282e+18  1.89248457e+04]\n",
      "Val Loss Meta Info:  [52625899.24324324, -5.3390865858771304e+19, 162152.8108108108]\n",
      "\n",
      "Epoch: 136, NLL Loss: -6.052243857679745e+18, Val Loss: -6.066415108570376e+19, Time took: 0.34406280517578125\n",
      "Train loss Meta Info:  [ 5.87305073e+06 -6.05224386e+18  1.89739311e+04]\n",
      "Val Loss Meta Info:  [52626546.16216216, -6.066414882724744e+19, 162320.16216216216]\n",
      "\n",
      "Epoch: 137, NLL Loss: -6.182349977339105e+18, Val Loss: -5.902548733417803e+19, Time took: 0.3405625820159912\n",
      "Train loss Meta Info:  [ 5.82214655e+06 -6.18234998e+18  1.89933960e+04]\n",
      "Val Loss Meta Info:  [51571030.48648649, -5.902548519458783e+19, 162735.7027027027]\n",
      "\n",
      "Epoch: 138, NLL Loss: -6.187641285132767e+18, Val Loss: -4.621962933709885e+19, Time took: 0.3408670425415039\n",
      "Train loss Meta Info:  [ 5.77584340e+06 -6.18764129e+18  1.90420650e+04]\n",
      "Val Loss Meta Info:  [52032975.567567565, -4.621962898050048e+19, 163156.05405405405]\n",
      "\n",
      "Epoch: 139, NLL Loss: -6.063444194160913e+18, Val Loss: -4.915405434781906e+19, Time took: 0.34173107147216797\n",
      "Train loss Meta Info:  [ 5.75011231e+06 -6.06344419e+18  1.90913746e+04]\n",
      "Val Loss Meta Info:  [52009651.89189189, -4.915405125729989e+19, 163553.13513513515]\n",
      "\n",
      "Epoch: 140, NLL Loss: -5.531720138579547e+18, Val Loss: -4.622224617477295e+19, Time took: 0.3410763740539551\n",
      "Train loss Meta Info:  [ 5.73024518e+06 -5.53172014e+18  1.91380224e+04]\n",
      "Val Loss Meta Info:  [51280729.94594595, -4.622224593704071e+19, 163027.2837837838]\n",
      "\n",
      "Epoch: 141, NLL Loss: -5.533941478105803e+18, Val Loss: -4.226207357236098e+19, Time took: 0.351027250289917\n",
      "Train loss Meta Info:  [ 5.72895778e+06 -5.53394148e+18  1.90708115e+04]\n",
      "Val Loss Meta Info:  [51004042.37837838, -4.226207178936915e+19, 163421.2972972973]\n",
      "\n",
      "Epoch: 142, NLL Loss: -5.296793447940083e+18, Val Loss: -4.374564900976565e+19, Time took: 0.34127283096313477\n",
      "Train loss Meta Info:  [ 5.65817354e+06 -5.29679345e+18  1.91169450e+04]\n",
      "Val Loss Meta Info:  [50780512.86486486, -4.374564651357708e+19, 163816.04054054053]\n",
      "\n",
      "Epoch: 143, NLL Loss: -5.143616803005722e+18, Val Loss: -4.227464318928971e+19, Time took: 0.3448202610015869\n",
      "Train loss Meta Info:  [ 5.62193002e+06 -5.14361680e+18  1.91632580e+04]\n",
      "Val Loss Meta Info:  [50848083.027027026, -4.227464307042359e+19, 164214.22972972973]\n",
      "\n",
      "Epoch: 144, NLL Loss: -5.088130482857611e+18, Val Loss: -5.091830431746936e+19, Time took: 0.34781837463378906\n",
      "Train loss Meta Info:  [ 5.59753971e+06 -5.08813048e+18  1.92099420e+04]\n",
      "Val Loss Meta Info:  [50416076.10810811, -5.091830217787916e+19, 164613.22972972973]\n",
      "\n",
      "Epoch: 145, NLL Loss: -5.922460987501969e+18, Val Loss: -4.042749883899812e+19, Time took: 0.34595274925231934\n",
      "Train loss Meta Info:  [ 5.54699127e+06 -5.92246099e+18  1.92568637e+04]\n",
      "Val Loss Meta Info:  [49594845.4054054, -4.042749776920302e+19, 165006.48648648648]\n",
      "\n",
      "Epoch: 146, NLL Loss: -5.712956441651935e+18, Val Loss: -5.669696799715308e+19, Time took: 0.34152793884277344\n",
      "Train loss Meta Info:  [ 5.52973963e+06 -5.71295644e+18  1.93030427e+04]\n",
      "Val Loss Meta Info:  [49367330.5945946, -5.669696443116943e+19, 165403.56756756757]\n",
      "\n",
      "Epoch: 147, NLL Loss: -5.341799684561529e+18, Val Loss: -5.7525230106356744e+19, Time took: 0.34473252296447754\n",
      "Train loss Meta Info:  [ 5.51609347e+06 -5.34179968e+18  1.93497619e+04]\n",
      "Val Loss Meta Info:  [49683774.27027027, -5.752522737243594e+19, 165799.7837837838]\n",
      "\n",
      "Epoch: 148, NLL Loss: -5.268517886646555e+18, Val Loss: -5.561804362509556e+19, Time took: 0.3433573246002197\n",
      "Train loss Meta Info:  [ 5.47056100e+06 -5.26851789e+18  1.93963854e+04]\n",
      "Val Loss Meta Info:  [48976913.2972973, -5.5618040415710265e+19, 166193.75675675675]\n",
      "\n",
      "Epoch: 149, NLL Loss: -5.262066347822732e+18, Val Loss: -4.448927071386311e+19, Time took: 0.3550689220428467\n",
      "Train loss Meta Info:  [ 5.42518372e+06 -5.26206635e+18  1.94427576e+04]\n",
      "Val Loss Meta Info:  [49163232.86486486, -4.448926916860353e+19, 166583.01351351352]\n",
      "\n",
      "Epoch: 150, NLL Loss: -5.473969514707915e+18, Val Loss: -5.522680660160728e+19, Time took: 0.35253405570983887\n",
      "Train loss Meta Info:  [ 5.43940806e+06 -5.47396951e+18  1.94884910e+04]\n",
      "Val Loss Meta Info:  [47919598.7027027, -5.522680541294607e+19, 166967.66216216216]\n",
      "\n",
      "Epoch: 151, NLL Loss: -5.602247593965614e+18, Val Loss: -5.381997707582138e+19, Time took: 0.3481297492980957\n",
      "Train loss Meta Info:  [ 5.35099685e+06 -5.60224759e+18  1.95336841e+04]\n",
      "Val Loss Meta Info:  [48624314.81081081, -5.38199744607667e+19, 167353.7027027027]\n",
      "\n",
      "Epoch: 152, NLL Loss: -5.760754986904109e+18, Val Loss: -5.369943981509155e+19, Time took: 0.3629167079925537\n",
      "Train loss Meta Info:  [ 5.36774824e+06 -5.76075499e+18  1.95790837e+04]\n",
      "Val Loss Meta Info:  [48058437.18918919, -5.369943850756421e+19, 167736.32432432432]\n",
      "\n",
      "Epoch: 153, NLL Loss: -6.058560832929084e+18, Val Loss: -4.888823201864142e+19, Time took: 0.34020280838012695\n",
      "Train loss Meta Info:  [ 5.30437531e+06 -6.05856083e+18  1.96240690e+04]\n",
      "Val Loss Meta Info:  [47776321.72972973, -4.888823237523979e+19, 168115.9189189189]\n",
      "\n",
      "Epoch: 154, NLL Loss: -6.304069344871448e+18, Val Loss: -5.123626108998962e+19, Time took: 0.3422279357910156\n",
      "Train loss Meta Info:  [ 5.29710076e+06 -6.30406934e+18  1.96686649e+04]\n",
      "Val Loss Meta Info:  [47664920.216216214, -5.123625859380106e+19, 168500.44594594595]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155, NLL Loss: -6.276064516638191e+18, Val Loss: -5.0471031783383106e+19, Time took: 0.3631882667541504\n",
      "Train loss Meta Info:  [ 5.26511097e+06 -6.27606452e+18  1.97138219e+04]\n",
      "Val Loss Meta Info:  [46667820.972972974, -5.047103083245413e+19, 168885.45945945947]\n",
      "\n",
      "Epoch: 156, NLL Loss: -5.525419871051063e+18, Val Loss: -4.833004075154512e+19, Time took: 0.3408629894256592\n",
      "Train loss Meta Info:  [ 5.24307035e+06 -5.52541987e+18  1.97590275e+04]\n",
      "Val Loss Meta Info:  [46992307.89189189, -4.833004087041125e+19, 169270.47297297296]\n",
      "\n",
      "Epoch: 157, NLL Loss: -5.532309129962941e+18, Val Loss: -4.758200780679702e+19, Time took: 0.363619327545166\n",
      "Train loss Meta Info:  [ 5.22704442e+06 -5.53230913e+18  1.98042472e+04]\n",
      "Val Loss Meta Info:  [46226871.35135135, -4.758200590493907e+19, 169652.82432432432]\n",
      "\n",
      "Epoch: 158, NLL Loss: -6.108472965567992e+18, Val Loss: -5.700311161674452e+19, Time took: 0.34709692001342773\n",
      "Train loss Meta Info:  [ 5.16830116e+06 -6.10847297e+18  1.98491925e+04]\n",
      "Val Loss Meta Info:  [46335716.324324325, -5.700311030921718e+19, 170027.47297297296]\n",
      "\n",
      "Epoch: 159, NLL Loss: -6.711383285172938e+18, Val Loss: -5.269860715688519e+19, Time took: 0.34714317321777344\n",
      "Train loss Meta Info:  [ 5.12823763e+06 -6.71138329e+18  1.98943970e+04]\n",
      "Val Loss Meta Info:  [46281437.4054054, -5.269860477956275e+19, 170426.6891891892]\n",
      "\n",
      "Epoch: 160, NLL Loss: -5.759547539306791e+18, Val Loss: -4.839836000604861e+19, Time took: 0.3493328094482422\n",
      "Train loss Meta Info:  [ 5.10395874e+06 -5.75954754e+18  1.99401241e+04]\n",
      "Val Loss Meta Info:  [45785987.45945946, -4.8398359411718005e+19, 170818.45945945947]\n",
      "\n",
      "Epoch: 161, NLL Loss: -6.767209049186829e+18, Val Loss: -5.24286022854755e+19, Time took: 0.3520631790161133\n",
      "Train loss Meta Info:  [ 5.07715181e+06 -6.76720905e+18  1.99858328e+04]\n",
      "Val Loss Meta Info:  [46128408.216216214, -5.2428601810011005e+19, 171217.2972972973]\n",
      "\n",
      "Epoch: 162, NLL Loss: -6.050289415062782e+18, Val Loss: -5.056887512411564e+19, Time took: 0.34659242630004883\n",
      "Train loss Meta Info:  [ 5.05774042e+06 -6.05028942e+18  2.00324045e+04]\n",
      "Val Loss Meta Info:  [45197889.72972973, -5.05688738165883e+19, 171611.0945945946]\n",
      "\n",
      "Epoch: 163, NLL Loss: -6.463658251438234e+18, Val Loss: -5.48502634515126e+19, Time took: 0.34822678565979004\n",
      "Train loss Meta Info:  [ 5.01895479e+06 -6.46365825e+18  2.00786972e+04]\n",
      "Val Loss Meta Info:  [45660800.0, -5.4850264164709335e+19, 172009.8108108108]\n",
      "\n",
      "Epoch: 164, NLL Loss: -5.652774995275273e+18, Val Loss: -5.653225675726573e+19, Time took: 0.3448216915130615\n",
      "Train loss Meta Info:  [ 4.99546599e+06 -5.65277500e+18  2.01253216e+04]\n",
      "Val Loss Meta Info:  [44990519.35135135, -5.653225592520287e+19, 172404.13513513515]\n",
      "\n",
      "Epoch: 165, NLL Loss: -6.062593009141941e+18, Val Loss: -6.487732131366699e+19, Time took: 0.34482288360595703\n",
      "Train loss Meta Info:  [ 4.96754285e+06 -6.06259301e+18  2.01713856e+04]\n",
      "Val Loss Meta Info:  [44815923.89189189, -6.487731953067516e+19, 172793.0]\n",
      "\n",
      "Epoch: 166, NLL Loss: -6.201417929971417e+18, Val Loss: -5.017274747290701e+19, Time took: 0.3432135581970215\n",
      "Train loss Meta Info:  [ 4.96773179e+06 -6.20141793e+18  2.02169543e+04]\n",
      "Val Loss Meta Info:  [44010087.783783786, -5.017274723517477e+19, 173181.48648648648]\n",
      "\n",
      "Epoch: 167, NLL Loss: -6.404131139345773e+18, Val Loss: -6.824488793503328e+19, Time took: 0.3502633571624756\n",
      "Train loss Meta Info:  [ 4.91465036e+06 -6.40413114e+18  2.02624671e+04]\n",
      "Val Loss Meta Info:  [44465318.05405405, -6.824488615204145e+19, 173571.43243243243]\n",
      "\n",
      "Epoch: 168, NLL Loss: -6.24257530012615e+18, Val Loss: -5.345168026293502e+19, Time took: 0.3468451499938965\n",
      "Train loss Meta Info:  [ 4.90458928e+06 -6.24257530e+18  2.03081133e+04]\n",
      "Val Loss Meta Info:  [43335624.64864865, -5.345167966860441e+19, 173958.97297297296]\n",
      "\n",
      "Epoch: 169, NLL Loss: -6.500288574966846e+18, Val Loss: -5.380725792531127e+19, Time took: 0.3446686267852783\n",
      "Train loss Meta Info:  [ 4.85453601e+06 -6.50028857e+18  2.03534857e+04]\n",
      "Val Loss Meta Info:  [43894763.24324324, -5.3807258638508e+19, 174346.2837837838]\n",
      "\n",
      "Epoch: 170, NLL Loss: -6.349394269908892e+18, Val Loss: -5.029806541019441e+19, Time took: 0.3424370288848877\n",
      "Train loss Meta Info:  [ 4.83239179e+06 -6.34939427e+18  2.03988137e+04]\n",
      "Val Loss Meta Info:  [43027552.86486486, -5.029806445926543e+19, 174731.32432432432]\n",
      "\n",
      "Epoch: 171, NLL Loss: -6.747651206894243e+18, Val Loss: -5.232473801906926e+19, Time took: 0.34509992599487305\n",
      "Train loss Meta Info:  [ 4.81319352e+06 -6.74765121e+18  2.04439018e+04]\n",
      "Val Loss Meta Info:  [43222638.7027027, -5.232473754360477e+19, 175099.9054054054]\n",
      "\n",
      "Epoch: 172, NLL Loss: -5.722181059792719e+18, Val Loss: -6.390703748652676e+19, Time took: 0.36429476737976074\n",
      "Train loss Meta Info:  [ 4.80870770e+06 -5.72218106e+18  2.04884703e+04]\n",
      "Val Loss Meta Info:  [43158759.783783786, -6.390703724879452e+19, 175499.75675675675]\n",
      "\n",
      "Epoch: 173, NLL Loss: -6.548673211943989e+18, Val Loss: -6.410941359673521e+19, Time took: 0.34386515617370605\n",
      "Train loss Meta Info:  [ 4.74346471e+06 -6.54867321e+18  2.05338885e+04]\n",
      "Val Loss Meta Info:  [43221569.72972973, -6.410941014961767e+19, 175887.2972972973]\n",
      "\n",
      "Epoch: 174, NLL Loss: -6.610098778272671e+18, Val Loss: -6.642845514352873e+19, Time took: 0.3644852638244629\n",
      "Train loss Meta Info:  [ 4.76279769e+06 -6.61009878e+18  2.05792840e+04]\n",
      "Val Loss Meta Info:  [42556076.972972974, -6.6428452053009555e+19, 176273.5810810811]\n",
      "\n",
      "Epoch: 175, NLL Loss: -6.834607911871633e+18, Val Loss: -5.551861258957252e+19, Time took: 0.35959863662719727\n",
      "Train loss Meta Info:  [ 4.71299259e+06 -6.83460791e+18  2.06245073e+04]\n",
      "Val Loss Meta Info:  [42017757.4054054, -5.551861128204518e+19, 176664.0810810811]\n",
      "\n",
      "Epoch: 176, NLL Loss: -6.939996316440401e+18, Val Loss: -5.593985748440606e+19, Time took: 0.3499443531036377\n",
      "Train loss Meta Info:  [ 4.69241291e+06 -6.93999632e+18  2.06702121e+04]\n",
      "Val Loss Meta Info:  [41760235.24324324, -5.593985760327219e+19, 177055.36486486485]\n",
      "\n",
      "Epoch: 177, NLL Loss: -6.817250570411739e+18, Val Loss: -5.3696941724673245e+19, Time took: 0.36215806007385254\n",
      "Train loss Meta Info:  [ 4.67263293e+06 -6.81725057e+18  2.07160010e+04]\n",
      "Val Loss Meta Info:  [41743190.48648649, -5.369693946621693e+19, 177448.4054054054]\n",
      "\n",
      "Epoch: 178, NLL Loss: -6.571455106745472e+18, Val Loss: -5.627235859673855e+19, Time took: 0.3516240119934082\n",
      "Train loss Meta Info:  [ 4.62935207e+06 -6.57145511e+18  2.07619978e+04]\n",
      "Val Loss Meta Info:  [43646716.54054054, -5.6272359428801405e+19, 177844.51351351352]\n",
      "\n",
      "Epoch: 179, NLL Loss: -7.343328821082986e+18, Val Loss: -7.35483778735643e+19, Time took: 0.34448695182800293\n",
      "Train loss Meta Info:  [ 4.61551830e+06 -7.34332882e+18  2.08083499e+04]\n",
      "Val Loss Meta Info:  [41373045.62162162, -7.3548376803769205e+19, 178247.5]\n",
      "\n",
      "Epoch: 180, NLL Loss: -6.773541903187688e+18, Val Loss: -6.784864153656885e+19, Time took: 0.35297393798828125\n",
      "Train loss Meta Info:  [ 4.58864476e+06 -6.77354190e+18  2.08555150e+04]\n",
      "Val Loss Meta Info:  [41471571.027027026, -6.784863785171907e+19, 178651.2972972973]\n",
      "\n",
      "Epoch: 181, NLL Loss: -6.410167378406971e+18, Val Loss: -5.4407362575658385e+19, Time took: 0.34082818031311035\n",
      "Train loss Meta Info:  [ 4.57983348e+06 -6.41016738e+18  2.09028350e+04]\n",
      "Val Loss Meta Info:  [41022522.81081081, -5.440736328885512e+19, 179050.05405405405]\n",
      "\n",
      "Epoch: 182, NLL Loss: -6.78664439131642e+18, Val Loss: -4.722409917976989e+19, Time took: 0.3441181182861328\n",
      "Train loss Meta Info:  [ 4.52353791e+06 -6.78664439e+18  2.09501174e+04]\n",
      "Val Loss Meta Info:  [45223783.783783786, -4.722409906090376e+19, 179443.25675675675]\n",
      "\n",
      "Epoch: 183, NLL Loss: -6.904652060793228e+18, Val Loss: -5.282736436654427e+19, Time took: 0.35088586807250977\n",
      "Train loss Meta Info:  [ 4.52171540e+06 -6.90465206e+18  2.09966516e+04]\n",
      "Val Loss Meta Info:  [40614787.45945946, -5.282736436654427e+19, 179854.67567567568]\n",
      "\n",
      "Epoch: 184, NLL Loss: -6.825420073608771e+18, Val Loss: -6.833010448423243e+19, Time took: 0.3472890853881836\n",
      "Train loss Meta Info:  [ 4.49005002e+06 -6.82542007e+18  2.10448294e+04]\n",
      "Val Loss Meta Info:  [40105793.72972973, -6.8330104603098554e+19, 180264.05405405405]\n",
      "\n",
      "Epoch: 185, NLL Loss: -6.822230421593011e+18, Val Loss: -5.668541432896841e+19, Time took: 0.34009599685668945\n",
      "Train loss Meta Info:  [ 4.49078567e+06 -6.82223042e+18  2.10927501e+04]\n",
      "Val Loss Meta Info:  [40287498.37837838, -5.668541254597658e+19, 180676.9054054054]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 186, NLL Loss: -7.996690110331252e+18, Val Loss: -6.1917545962856776e+19, Time took: 0.35157155990600586\n",
      "Train loss Meta Info:  [ 4.43737343e+06 -7.99669011e+18  2.11410809e+04]\n",
      "Val Loss Meta Info:  [876889226.3783784, -6.1917545487392285e+19, 181100.17567567568]\n",
      "\n",
      "Epoch: 187, NLL Loss: -7.143634353833354e+18, Val Loss: -7.021790437647267e+19, Time took: 0.3415226936340332\n",
      "Train loss Meta Info:  [ 4.42290901e+06 -7.14363435e+18  2.11906504e+04]\n",
      "Val Loss Meta Info:  [39455439.567567565, -7.02179040198743e+19, 181522.86486486485]\n",
      "\n",
      "Epoch: 188, NLL Loss: -6.70129573423437e+18, Val Loss: -7.46581853282228e+19, Time took: 0.35215020179748535\n",
      "Train loss Meta Info:  [ 4.39962093e+06 -6.70129573e+18  2.12401497e+04]\n",
      "Val Loss Meta Info:  [39577641.51351351, -7.465818699234851e+19, 181946.05405405405]\n",
      "\n",
      "Epoch: 189, NLL Loss: -7.328231270839902e+18, Val Loss: -4.6988764109007225e+19, Time took: 0.38112974166870117\n",
      "Train loss Meta Info:  [ 4.36606045e+06 -7.32823127e+18  2.12897361e+04]\n",
      "Val Loss Meta Info:  [39614699.24324324, -4.698876315807825e+19, 182374.05405405405]\n",
      "\n",
      "Epoch: 190, NLL Loss: -6.938274765647561e+18, Val Loss: -6.065886903184392e+19, Time took: 0.3489868640899658\n",
      "Train loss Meta Info:  [ 4.35432012e+06 -6.93827477e+18  2.13398025e+04]\n",
      "Val Loss Meta Info:  [40988526.7027027, -6.065886926957616e+19, 182801.0810810811]\n",
      "\n",
      "Epoch: 191, NLL Loss: -7.143251203513247e+18, Val Loss: -6.471578546336065e+19, Time took: 0.3579223155975342\n",
      "Train loss Meta Info:  [ 4.34117097e+06 -7.14325120e+18  2.13897457e+04]\n",
      "Val Loss Meta Info:  [39178717.4054054, -6.471578332377045e+19, 183230.0810810811]\n",
      "\n",
      "Epoch: 192, NLL Loss: -7.134108552750342e+18, Val Loss: -6.290595413966927e+19, Time took: 0.34162473678588867\n",
      "Train loss Meta Info:  [ 4.32349373e+06 -7.13410855e+18  2.14399236e+04]\n",
      "Val Loss Meta Info:  [92857593.08108108, -6.290595247554356e+19, 183659.8918918919]\n",
      "\n",
      "Epoch: 193, NLL Loss: -7.035951209533071e+18, Val Loss: -5.928499846661223e+19, Time took: 0.3553586006164551\n",
      "Train loss Meta Info:  [ 4.27231653e+06 -7.03595121e+18  2.14901904e+04]\n",
      "Val Loss Meta Info:  [39019772.54054054, -5.928499751568326e+19, 184089.54054054053]\n",
      "\n",
      "Epoch: 194, NLL Loss: -7.015089256269179e+18, Val Loss: -6.160965631880043e+19, Time took: 0.36395263671875\n",
      "Train loss Meta Info:  [ 4.25867511e+06 -7.01508926e+18  2.15404605e+04]\n",
      "Val Loss Meta Info:  [60436120.216216214, -6.160965370374575e+19, 184518.82432432432]\n",
      "\n",
      "Epoch: 195, NLL Loss: -6.724852482974723e+18, Val Loss: -4.945285762778346e+19, Time took: 0.34998321533203125\n",
      "Train loss Meta Info:  [ 4.23326146e+06 -6.72485248e+18  2.15906806e+04]\n",
      "Val Loss Meta Info:  [37979613.4054054, -4.945285596365776e+19, 184947.2027027027]\n",
      "\n",
      "Epoch: 196, NLL Loss: -7.169636693913156e+18, Val Loss: -7.004632778598148e+19, Time took: 0.37540555000305176\n",
      "Train loss Meta Info:  [ 4.21849123e+06 -7.16963669e+18  2.16408523e+04]\n",
      "Val Loss Meta Info:  [37940151.35135135, -7.0046326002989646e+19, 185374.6891891892]\n",
      "\n",
      "Epoch: 197, NLL Loss: -7.272077186410673e+18, Val Loss: -6.299317180003097e+19, Time took: 0.39420104026794434\n",
      "Train loss Meta Info:  [ 4.19965180e+06 -7.27207719e+18  2.16907904e+04]\n",
      "Val Loss Meta Info:  [124621491.8918919, -6.2993171681164845e+19, 185803.47297297296]\n",
      "\n",
      "Epoch: 198, NLL Loss: -7.407574506402748e+18, Val Loss: -6.361454540330579e+19, Time took: 0.3730034828186035\n",
      "Train loss Meta Info:  [ 4.17516473e+06 -7.40757451e+18  2.17409306e+04]\n",
      "Val Loss Meta Info:  [4287970743489.7295, -6.361454671083313e+19, 186233.0810810811]\n",
      "\n",
      "Epoch: 199, NLL Loss: -6.885558004298107e+18, Val Loss: -6.421839718928037e+19, Time took: 0.37467288970947266\n",
      "Train loss Meta Info:  [ 4.1496030e+06 -6.8855580e+18  2.1791146e+04]\n",
      "Val Loss Meta Info:  [204897059255268.3, -6.4218599618286e+19, 186662.7027027027]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=HRMTPP, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rmtpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([50, 8000, 2]), Val Data Shape: torch.Size([50, 2000, 2])\n",
      "Markers: Data Shape: torch.Size([50, 8000, 20]), Val Data Shape: torch.Size([50, 2000, 20])\n",
      "Epoch: 0, NLL Loss: 1519.8495, Val Loss: 57723.35546875, Time took: 0.44893574714660645\n",
      "Train loss Meta Info:  [1444.00798437   75.84150208]\n",
      "Val Loss Meta Info:  [57307.535, 415.824921875]\n",
      "\n",
      "Epoch: 1, NLL Loss: 1442.43723046875, Val Loss: 59497.359375, Time took: 0.42549681663513184\n",
      "Train loss Meta Info:  [1432.83265625    9.6045724 ]\n",
      "Val Loss Meta Info:  [57215.04, 2282.32]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1487.3058203125, Val Loss: 59576.58203125, Time took: 0.42228198051452637\n",
      "Train loss Meta Info:  [1430.13851953   57.16730798]\n",
      "Val Loss Meta Info:  [57271.32, 2305.2621875]\n",
      "\n",
      "Epoch: 3, NLL Loss: 1488.50864453125, Val Loss: 59348.046875, Time took: 0.4171335697174072\n",
      "Train loss Meta Info:  [1431.61246484   56.89618091]\n",
      "Val Loss Meta Info:  [56879.19, 2468.86203125]\n",
      "\n",
      "Epoch: 4, NLL Loss: 1480.43335546875, Val Loss: 59564.28515625, Time took: 0.4159080982208252\n",
      "Train loss Meta Info:  [1421.85295703   58.58037756]\n",
      "Val Loss Meta Info:  [56916.98, 2647.31]\n",
      "\n",
      "Epoch: 5, NLL Loss: 1481.60885546875, Val Loss: 59742.1171875, Time took: 0.41136717796325684\n",
      "Train loss Meta Info:  [1422.78140625   58.82745068]\n",
      "Val Loss Meta Info:  [56889.51, 2852.613125]\n",
      "\n",
      "Epoch: 6, NLL Loss: 1479.91617578125, Val Loss: 60133.5390625, Time took: 0.41780638694763184\n",
      "Train loss Meta Info:  [1422.07905469   57.83714075]\n",
      "Val Loss Meta Info:  [56896.97, 3236.573125]\n",
      "\n",
      "Epoch: 7, NLL Loss: 1479.26191796875, Val Loss: 60737.58203125, Time took: 0.4157226085662842\n",
      "Train loss Meta Info:  [1422.22219922   57.03973633]\n",
      "Val Loss Meta Info:  [56875.405, 3862.1784375]\n",
      "\n",
      "Epoch: 8, NLL Loss: 1478.38769140625, Val Loss: 61934.41015625, Time took: 0.41791605949401855\n",
      "Train loss Meta Info:  [1421.68260547   56.70510657]\n",
      "Val Loss Meta Info:  [56864.97, 5069.4425]\n",
      "\n",
      "Epoch: 9, NLL Loss: 1478.0093046875, Val Loss: 62906.5625, Time took: 0.41391491889953613\n",
      "Train loss Meta Info:  [1421.38740625   56.62190698]\n",
      "Val Loss Meta Info:  [56923.68, 5982.88375]\n",
      "\n",
      "Epoch: 10, NLL Loss: 1477.17690625, Val Loss: 65664.5078125, Time took: 0.41918110847473145\n",
      "Train loss Meta Info:  [1422.80213672   54.37478772]\n",
      "Val Loss Meta Info:  [56880.24, 8784.268125]\n",
      "\n",
      "Epoch: 11, NLL Loss: 1476.39378125, Val Loss: 67668.171875, Time took: 0.42072272300720215\n",
      "Train loss Meta Info:  [1421.72912109   54.66466077]\n",
      "Val Loss Meta Info:  [56861.62, 10806.5525]\n",
      "\n",
      "Epoch: 12, NLL Loss: 1474.58971875, Val Loss: 69975.296875, Time took: 0.40937376022338867\n",
      "Train loss Meta Info:  [1421.26007422   53.32964392]\n",
      "Val Loss Meta Info:  [56862.615, 13112.6875]\n",
      "\n",
      "Epoch: 13, NLL Loss: 1473.085625, Val Loss: 73534.3671875, Time took: 0.41402673721313477\n",
      "Train loss Meta Info:  [1421.29323438   51.79238611]\n",
      "Val Loss Meta Info:  [56865.0, 16669.365]\n",
      "\n",
      "Epoch: 14, NLL Loss: 1470.9181328125, Val Loss: 77775.3203125, Time took: 0.41307711601257324\n",
      "Train loss Meta Info:  [1421.36450391   49.55364441]\n",
      "Val Loss Meta Info:  [56829.76, 20945.5575]\n",
      "\n",
      "Epoch: 15, NLL Loss: 1469.53771484375, Val Loss: 83804.6171875, Time took: 0.4177722930908203\n",
      "Train loss Meta Info:  [1420.45978906   49.07794348]\n",
      "Val Loss Meta Info:  [56828.14, 26976.48]\n",
      "\n",
      "Epoch: 16, NLL Loss: 1468.60696875, Val Loss: 87890.796875, Time took: 0.410656213760376\n",
      "Train loss Meta Info:  [1420.45132422   48.15566235]\n",
      "Val Loss Meta Info:  [56839.775, 31051.03]\n",
      "\n",
      "Epoch: 17, NLL Loss: 1467.72583203125, Val Loss: 97549.234375, Time took: 0.4115133285522461\n",
      "Train loss Meta Info:  [1420.76839844   46.95741418]\n",
      "Val Loss Meta Info:  [56834.74, 40714.5075]\n",
      "\n",
      "Epoch: 18, NLL Loss: 1468.094109375, Val Loss: 95868.9375, Time took: 0.41054439544677734\n",
      "Train loss Meta Info:  [1420.65401953   47.44012769]\n",
      "Val Loss Meta Info:  [56827.185, 39041.765]\n",
      "\n",
      "Epoch: 19, NLL Loss: 1468.12868359375, Val Loss: 102150.640625, Time took: 0.4064624309539795\n",
      "Train loss Meta Info:  [1420.49937109   47.62932825]\n",
      "Val Loss Meta Info:  [56849.505, 45301.13]\n",
      "\n",
      "Epoch: 20, NLL Loss: 1467.70885546875, Val Loss: 115432.2578125, Time took: 0.4130516052246094\n",
      "Train loss Meta Info:  [1421.04031641   46.66853375]\n",
      "Val Loss Meta Info:  [56811.905, 58620.34]\n",
      "\n",
      "Epoch: 21, NLL Loss: 1467.08380078125, Val Loss: 126133.796875, Time took: 0.4158010482788086\n",
      "Train loss Meta Info:  [1420.13324609   46.95055969]\n",
      "Val Loss Meta Info:  [56810.53, 69323.27]\n",
      "\n",
      "Epoch: 22, NLL Loss: 1466.93016015625, Val Loss: 123684.2734375, Time took: 0.4168221950531006\n",
      "Train loss Meta Info:  [1420.13342969   46.79675861]\n",
      "Val Loss Meta Info:  [56805.04, 66879.245]\n",
      "\n",
      "Epoch: 23, NLL Loss: 1466.6190234375, Val Loss: 129910.5, Time took: 0.4105854034423828\n",
      "Train loss Meta Info:  [1419.99033594   46.62866858]\n",
      "Val Loss Meta Info:  [56803.015, 73107.485]\n",
      "\n",
      "Epoch: 24, NLL Loss: 1466.28729296875, Val Loss: 144573.734375, Time took: 0.41371870040893555\n",
      "Train loss Meta Info:  [1419.92149609   46.36580481]\n",
      "Val Loss Meta Info:  [56794.92, 87778.82]\n",
      "\n",
      "Epoch: 25, NLL Loss: 1465.97241015625, Val Loss: 135559.75, Time took: 0.411074161529541\n",
      "Train loss Meta Info:  [1419.69135938   46.28105267]\n",
      "Val Loss Meta Info:  [56781.405, 78778.365]\n",
      "\n",
      "Epoch: 26, NLL Loss: 1465.90295703125, Val Loss: 134271.03125, Time took: 0.40786147117614746\n",
      "Train loss Meta Info:  [1419.35854688   46.54440948]\n",
      "Val Loss Meta Info:  [56783.83, 77487.18]\n",
      "\n",
      "Epoch: 27, NLL Loss: 1465.31003515625, Val Loss: 142199.453125, Time took: 0.4116325378417969\n",
      "Train loss Meta Info:  [1419.39345703   45.9165838 ]\n",
      "Val Loss Meta Info:  [56795.13, 85404.34]\n",
      "\n",
      "Epoch: 28, NLL Loss: 1465.54011328125, Val Loss: 137232.953125, Time took: 0.41339707374572754\n",
      "Train loss Meta Info:  [1419.61499609   45.92509882]\n",
      "Val Loss Meta Info:  [56780.365, 80452.625]\n",
      "\n",
      "Epoch: 29, NLL Loss: 1464.482015625, Val Loss: 155662.78125, Time took: 0.41359734535217285\n",
      "Train loss Meta Info:  [1419.283375    45.1986618]\n",
      "Val Loss Meta Info:  [56772.075, 98890.7]\n",
      "\n",
      "Epoch: 30, NLL Loss: 1464.53901171875, Val Loss: 166663.0625, Time took: 0.41095924377441406\n",
      "Train loss Meta Info:  [1419.09032813   45.44868091]\n",
      "Val Loss Meta Info:  [56770.65, 109892.43]\n",
      "\n",
      "Epoch: 31, NLL Loss: 1464.01630859375, Val Loss: 151916.203125, Time took: 0.41404271125793457\n",
      "Train loss Meta Info:  [1419.05391797   44.96238672]\n",
      "Val Loss Meta Info:  [56772.205, 95144.0]\n",
      "\n",
      "Epoch: 32, NLL Loss: 1464.2857578125, Val Loss: 173861.921875, Time took: 0.41362428665161133\n",
      "Train loss Meta Info:  [1419.08619141   45.19958759]\n",
      "Val Loss Meta Info:  [56770.07, 117091.87]\n",
      "\n",
      "Epoch: 33, NLL Loss: 1464.55262109375, Val Loss: 160405.25, Time took: 0.41100430488586426\n",
      "Train loss Meta Info:  [1419.02883203   45.52377893]\n",
      "Val Loss Meta Info:  [56765.78, 103639.49]\n",
      "\n",
      "Epoch: 34, NLL Loss: 1463.5560859375, Val Loss: 141968.140625, Time took: 0.41534900665283203\n",
      "Train loss Meta Info:  [1418.92661719   44.62946014]\n",
      "Val Loss Meta Info:  [56767.49, 85200.63]\n",
      "\n",
      "Epoch: 35, NLL Loss: 1464.1100859375, Val Loss: 150839.109375, Time took: 0.4128696918487549\n",
      "Train loss Meta Info:  [1418.97338281   45.13672784]\n",
      "Val Loss Meta Info:  [56764.98, 94074.12]\n",
      "\n",
      "Epoch: 36, NLL Loss: 1464.508609375, Val Loss: 134626.5625, Time took: 0.4153413772583008\n",
      "Train loss Meta Info:  [1418.92513672   45.58346729]\n",
      "Val Loss Meta Info:  [56770.335, 77856.235]\n",
      "\n",
      "Epoch: 37, NLL Loss: 1464.483265625, Val Loss: 142205.578125, Time took: 0.4109935760498047\n",
      "Train loss Meta Info:  [1419.04737891   45.43586652]\n",
      "Val Loss Meta Info:  [56765.605, 85439.96]\n",
      "\n",
      "Epoch: 38, NLL Loss: 1463.1928046875, Val Loss: 156036.21875, Time took: 0.4120304584503174\n",
      "Train loss Meta Info:  [1418.92818359   44.26465967]\n",
      "Val Loss Meta Info:  [56762.745, 99273.49]\n",
      "\n",
      "Epoch: 39, NLL Loss: 1464.5405390625, Val Loss: 141728.84375, Time took: 0.4113929271697998\n",
      "Train loss Meta Info:  [1418.86103516   45.6794845 ]\n",
      "Val Loss Meta Info:  [56762.36, 84966.48]\n",
      "\n",
      "Epoch: 40, NLL Loss: 1463.449, Val Loss: 140939.140625, Time took: 0.4087858200073242\n",
      "Train loss Meta Info:  [1418.84727344   44.60170605]\n",
      "Val Loss Meta Info:  [56761.405, 84177.74]\n",
      "\n",
      "Epoch: 41, NLL Loss: 1463.52671875, Val Loss: 151999.3125, Time took: 0.41461992263793945\n",
      "Train loss Meta Info:  [1418.82574219   44.70098914]\n",
      "Val Loss Meta Info:  [56761.46, 95237.84]\n",
      "\n",
      "Epoch: 42, NLL Loss: 1463.41023828125, Val Loss: 147042.609375, Time took: 0.4134507179260254\n",
      "Train loss Meta Info:  [1418.82355469   44.58671643]\n",
      "Val Loss Meta Info:  [56759.88, 90282.75]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, NLL Loss: 1462.82735546875, Val Loss: 134957.5625, Time took: 0.41729021072387695\n",
      "Train loss Meta Info:  [1418.78383594   44.04353467]\n",
      "Val Loss Meta Info:  [56759.12, 78198.45]\n",
      "\n",
      "Epoch: 44, NLL Loss: 1463.2329609375, Val Loss: 135050.203125, Time took: 0.4096224308013916\n",
      "Train loss Meta Info:  [1418.770875     44.46210297]\n",
      "Val Loss Meta Info:  [56758.64, 78291.57]\n",
      "\n",
      "Epoch: 45, NLL Loss: 1462.3774765625, Val Loss: 144228.609375, Time took: 0.41159939765930176\n",
      "Train loss Meta Info:  [1418.76211719   43.61536249]\n",
      "Val Loss Meta Info:  [56759.435, 87469.14]\n",
      "\n",
      "Epoch: 46, NLL Loss: 1463.23995703125, Val Loss: 124219.4296875, Time took: 0.4104886054992676\n",
      "Train loss Meta Info:  [1418.77313281   44.4668443 ]\n",
      "Val Loss Meta Info:  [56758.155, 67461.28]\n",
      "\n",
      "Epoch: 47, NLL Loss: 1462.88539453125, Val Loss: 125056.6953125, Time took: 0.41052818298339844\n",
      "Train loss Meta Info:  [1418.75455469   44.13084631]\n",
      "Val Loss Meta Info:  [56759.415, 68297.29]\n",
      "\n",
      "Epoch: 48, NLL Loss: 1462.38334765625, Val Loss: 134212.859375, Time took: 0.41336536407470703\n",
      "Train loss Meta Info:  [1418.78344531   43.59989941]\n",
      "Val Loss Meta Info:  [56761.93, 77450.91]\n",
      "\n",
      "Epoch: 49, NLL Loss: 1464.11140625, Val Loss: 119353.609375, Time took: 0.41258883476257324\n",
      "Train loss Meta Info:  [1418.836625     45.27480298]\n",
      "Val Loss Meta Info:  [56758.485, 62595.125]\n",
      "\n",
      "Epoch: 50, NLL Loss: 1463.99696484375, Val Loss: 126157.1640625, Time took: 0.4142439365386963\n",
      "Train loss Meta Info:  [1418.75895703   45.23800238]\n",
      "Val Loss Meta Info:  [56757.865, 69399.29]\n",
      "\n",
      "Epoch: 51, NLL Loss: 1463.3198828125, Val Loss: 143352.328125, Time took: 0.4094240665435791\n",
      "Train loss Meta Info:  [1418.73759766   44.58227136]\n",
      "Val Loss Meta Info:  [56759.58, 86592.74]\n",
      "\n",
      "Epoch: 52, NLL Loss: 1463.309734375, Val Loss: 153145.5, Time took: 0.4115746021270752\n",
      "Train loss Meta Info:  [1418.77887891   44.53083722]\n",
      "Val Loss Meta Info:  [56762.51, 96382.99]\n",
      "\n",
      "Epoch: 53, NLL Loss: 1463.30923828125, Val Loss: 150166.828125, Time took: 0.4122774600982666\n",
      "Train loss Meta Info:  [1418.84695313   44.4622962 ]\n",
      "Val Loss Meta Info:  [56762.115, 93404.71]\n",
      "\n",
      "Epoch: 54, NLL Loss: 1462.7750859375, Val Loss: 148156.8125, Time took: 0.40891098976135254\n",
      "Train loss Meta Info:  [1418.83548828   43.93955792]\n",
      "Val Loss Meta Info:  [56761.875, 91394.98]\n",
      "\n",
      "Epoch: 55, NLL Loss: 1463.1830078125, Val Loss: 159528.96875, Time took: 0.4150266647338867\n",
      "Train loss Meta Info:  [1418.82477344   44.3582276 ]\n",
      "Val Loss Meta Info:  [56761.5, 102767.48]\n",
      "\n",
      "Epoch: 56, NLL Loss: 1462.79983984375, Val Loss: 158896.0, Time took: 0.4147505760192871\n",
      "Train loss Meta Info:  [1418.80526172   43.99456079]\n",
      "Val Loss Meta Info:  [56761.995, 102133.97]\n",
      "\n",
      "Epoch: 57, NLL Loss: 1462.9637890625, Val Loss: 158213.0, Time took: 0.4138326644897461\n",
      "Train loss Meta Info:  [1418.80678516   44.15698981]\n",
      "Val Loss Meta Info:  [56761.945, 101451.04]\n",
      "\n",
      "Epoch: 58, NLL Loss: 1462.5771484375, Val Loss: 154319.953125, Time took: 0.4276309013366699\n",
      "Train loss Meta Info:  [1418.79493359   43.78222748]\n",
      "Val Loss Meta Info:  [56760.34, 97559.62]\n",
      "\n",
      "Epoch: 59, NLL Loss: 1462.46811328125, Val Loss: 152349.09375, Time took: 0.43019890785217285\n",
      "Train loss Meta Info:  [1418.75513672   43.71297876]\n",
      "Val Loss Meta Info:  [56758.455, 95590.65]\n",
      "\n",
      "Epoch: 60, NLL Loss: 1462.4941796875, Val Loss: 158800.140625, Time took: 0.4205772876739502\n",
      "Train loss Meta Info:  [1418.71333203   43.78082788]\n",
      "Val Loss Meta Info:  [56757.3, 102042.83]\n",
      "\n",
      "Epoch: 61, NLL Loss: 1462.42883984375, Val Loss: 160137.078125, Time took: 0.42511558532714844\n",
      "Train loss Meta Info:  [1418.69491406   43.73393237]\n",
      "Val Loss Meta Info:  [56756.65, 103380.44]\n",
      "\n",
      "Epoch: 62, NLL Loss: 1462.3636796875, Val Loss: 141308.3125, Time took: 0.4199671745300293\n",
      "Train loss Meta Info:  [1418.67544141   43.68824084]\n",
      "Val Loss Meta Info:  [56756.36, 84551.97]\n",
      "\n",
      "Epoch: 63, NLL Loss: 1462.11799609375, Val Loss: 132207.359375, Time took: 0.41559314727783203\n",
      "Train loss Meta Info:  [1418.66173047   43.4562608 ]\n",
      "Val Loss Meta Info:  [56756.83, 75450.555]\n",
      "\n",
      "Epoch: 64, NLL Loss: 1461.999109375, Val Loss: 127707.59375, Time took: 0.42535400390625\n",
      "Train loss Meta Info:  [1418.66557812   43.33354309]\n",
      "Val Loss Meta Info:  [56757.09, 70950.505]\n",
      "\n",
      "Epoch: 65, NLL Loss: 1461.89847265625, Val Loss: 123755.109375, Time took: 0.4171762466430664\n",
      "Train loss Meta Info:  [1418.66974219   43.22874091]\n",
      "Val Loss Meta Info:  [56757.235, 66997.875]\n",
      "\n",
      "Epoch: 66, NLL Loss: 1462.01243359375, Val Loss: 115746.1796875, Time took: 0.41430091857910156\n",
      "Train loss Meta Info:  [1418.67453906   43.33788812]\n",
      "Val Loss Meta Info:  [56756.17, 58990.01]\n",
      "\n",
      "Epoch: 67, NLL Loss: 1461.74604296875, Val Loss: 110779.859375, Time took: 0.4111299514770508\n",
      "Train loss Meta Info:  [1418.65090234   43.09514337]\n",
      "Val Loss Meta Info:  [56755.765, 54024.11]\n",
      "\n",
      "Epoch: 68, NLL Loss: 1461.5637578125, Val Loss: 107827.015625, Time took: 0.4104502201080322\n",
      "Train loss Meta Info:  [1418.64543359   42.91832507]\n",
      "Val Loss Meta Info:  [56756.405, 51070.63]\n",
      "\n",
      "Epoch: 69, NLL Loss: 1461.74089453125, Val Loss: 102242.7890625, Time took: 0.41467761993408203\n",
      "Train loss Meta Info:  [1418.66280078   43.07809375]\n",
      "Val Loss Meta Info:  [56756.03, 45486.75]\n",
      "\n",
      "Epoch: 70, NLL Loss: 1461.72973046875, Val Loss: 100354.5546875, Time took: 0.41362714767456055\n",
      "Train loss Meta Info:  [1418.65865234   43.07108215]\n",
      "Val Loss Meta Info:  [56759.285, 43595.28]\n",
      "\n",
      "Epoch: 71, NLL Loss: 1461.562375, Val Loss: 100627.03125, Time took: 0.4139740467071533\n",
      "Train loss Meta Info:  [1418.74103906   42.82136334]\n",
      "Val Loss Meta Info:  [56757.68, 43869.36]\n",
      "\n",
      "Epoch: 72, NLL Loss: 1461.5593515625, Val Loss: 95327.5, Time took: 0.4106905460357666\n",
      "Train loss Meta Info:  [1418.70083594   42.85852167]\n",
      "Val Loss Meta Info:  [56757.26, 38570.245]\n",
      "\n",
      "Epoch: 73, NLL Loss: 1462.011796875, Val Loss: 102670.796875, Time took: 0.41571807861328125\n",
      "Train loss Meta Info:  [1418.68388281   43.32792822]\n",
      "Val Loss Meta Info:  [56756.31, 45914.515]\n",
      "\n",
      "Epoch: 74, NLL Loss: 1462.16974609375, Val Loss: 96343.046875, Time took: 0.41077160835266113\n",
      "Train loss Meta Info:  [1418.65829297   43.51145398]\n",
      "Val Loss Meta Info:  [56756.705, 39586.335]\n",
      "\n",
      "Epoch: 75, NLL Loss: 1461.974328125, Val Loss: 98592.359375, Time took: 0.40742945671081543\n",
      "Train loss Meta Info:  [1418.66939844   43.30492786]\n",
      "Val Loss Meta Info:  [56757.71, 41834.645]\n",
      "\n",
      "Epoch: 76, NLL Loss: 1461.494875, Val Loss: 100069.75, Time took: 0.4139120578765869\n",
      "Train loss Meta Info:  [1418.69767187   42.79719208]\n",
      "Val Loss Meta Info:  [56755.95, 43313.79]\n",
      "\n",
      "Epoch: 77, NLL Loss: 1461.48314453125, Val Loss: 96228.3359375, Time took: 0.41384077072143555\n",
      "Train loss Meta Info:  [1418.65676953   42.8263783 ]\n",
      "Val Loss Meta Info:  [56754.89, 39473.455]\n",
      "\n",
      "Epoch: 78, NLL Loss: 1461.85259375, Val Loss: 106752.046875, Time took: 0.41396594047546387\n",
      "Train loss Meta Info:  [1418.62785938   43.22473938]\n",
      "Val Loss Meta Info:  [56755.52, 49996.53]\n",
      "\n",
      "Epoch: 79, NLL Loss: 1461.41130859375, Val Loss: 108293.234375, Time took: 0.41033482551574707\n",
      "Train loss Meta Info:  [1418.64885156   42.76245575]\n",
      "Val Loss Meta Info:  [56755.24, 51538.0]\n",
      "\n",
      "Epoch: 80, NLL Loss: 1461.68148828125, Val Loss: 96159.1796875, Time took: 0.412111759185791\n",
      "Train loss Meta Info:  [1418.64159766   43.03988416]\n",
      "Val Loss Meta Info:  [56754.99, 39404.1825]\n",
      "\n",
      "Epoch: 81, NLL Loss: 1461.8464765625, Val Loss: 103234.8359375, Time took: 0.41029930114746094\n",
      "Train loss Meta Info:  [1418.62319531   43.22325751]\n",
      "Val Loss Meta Info:  [56754.81, 46480.045]\n",
      "\n",
      "Epoch: 82, NLL Loss: 1461.23337109375, Val Loss: 103898.0, Time took: 0.4089655876159668\n",
      "Train loss Meta Info:  [1418.611375     42.62198376]\n",
      "Val Loss Meta Info:  [56754.34, 47143.665]\n",
      "\n",
      "Epoch: 83, NLL Loss: 1461.7104609375, Val Loss: 92082.28125, Time took: 0.4158146381378174\n",
      "Train loss Meta Info:  [1418.59892969   43.11154736]\n",
      "Val Loss Meta Info:  [56754.92, 35327.3625]\n",
      "\n",
      "Epoch: 84, NLL Loss: 1462.2248203125, Val Loss: 97346.296875, Time took: 0.41734862327575684\n",
      "Train loss Meta Info:  [1418.61948047   43.60531305]\n",
      "Val Loss Meta Info:  [56754.85, 40591.44]\n",
      "\n",
      "Epoch: 85, NLL Loss: 1461.1971015625, Val Loss: 102520.2109375, Time took: 0.4201853275299072\n",
      "Train loss Meta Info:  [1418.62458594   42.57249274]\n",
      "Val Loss Meta Info:  [56753.99, 45766.24]\n",
      "\n",
      "Epoch: 86, NLL Loss: 1462.28691015625, Val Loss: 95832.0859375, Time took: 0.41391992568969727\n",
      "Train loss Meta Info:  [1418.60534375   43.68157996]\n",
      "Val Loss Meta Info:  [56754.76, 39077.3225]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, NLL Loss: 1461.8253203125, Val Loss: 97263.9140625, Time took: 0.4161362648010254\n",
      "Train loss Meta Info:  [1418.61060547   43.21470374]\n",
      "Val Loss Meta Info:  [56755.32, 40508.6]\n",
      "\n",
      "Epoch: 88, NLL Loss: 1461.902234375, Val Loss: 110024.8984375, Time took: 0.41614675521850586\n",
      "Train loss Meta Info:  [1418.61696484   43.28526318]\n",
      "Val Loss Meta Info:  [56754.54, 53270.365]\n",
      "\n",
      "Epoch: 89, NLL Loss: 1461.44580859375, Val Loss: 106974.078125, Time took: 0.4220263957977295\n",
      "Train loss Meta Info:  [1418.60521484   42.84059485]\n",
      "Val Loss Meta Info:  [56754.555, 50219.525]\n",
      "\n",
      "Epoch: 90, NLL Loss: 1461.7337265625, Val Loss: 101962.234375, Time took: 0.4188528060913086\n",
      "Train loss Meta Info:  [1418.61328125   43.12045563]\n",
      "Val Loss Meta Info:  [56754.65, 45207.595]\n",
      "\n",
      "Epoch: 91, NLL Loss: 1461.4495625, Val Loss: 98897.9296875, Time took: 0.42453598976135254\n",
      "Train loss Meta Info:  [1418.61021094   42.83934485]\n",
      "Val Loss Meta Info:  [56754.57, 42143.365]\n",
      "\n",
      "Epoch: 92, NLL Loss: 1461.61555859375, Val Loss: 103998.6796875, Time took: 0.42008209228515625\n",
      "Train loss Meta Info:  [1418.6009375    43.01460156]\n",
      "Val Loss Meta Info:  [56754.82, 47243.85]\n",
      "\n",
      "Epoch: 93, NLL Loss: 1461.36631640625, Val Loss: 108871.2265625, Time took: 0.43023037910461426\n",
      "Train loss Meta Info:  [1418.60101172   42.76530377]\n",
      "Val Loss Meta Info:  [56753.82, 52117.41]\n",
      "\n",
      "Epoch: 94, NLL Loss: 1461.37237109375, Val Loss: 99839.6171875, Time took: 0.41692471504211426\n",
      "Train loss Meta Info:  [1418.58055078   42.79181989]\n",
      "Val Loss Meta Info:  [56753.775, 43085.845]\n",
      "\n",
      "Epoch: 95, NLL Loss: 1461.32421484375, Val Loss: 97310.03125, Time took: 0.42940521240234375\n",
      "Train loss Meta Info:  [1418.57949219   42.74471667]\n",
      "Val Loss Meta Info:  [56754.19, 40555.84]\n",
      "\n",
      "Epoch: 96, NLL Loss: 1461.2460859375, Val Loss: 98238.9296875, Time took: 0.4239473342895508\n",
      "Train loss Meta Info:  [1418.57993359   42.66615125]\n",
      "Val Loss Meta Info:  [56754.375, 41484.5525]\n",
      "\n",
      "Epoch: 97, NLL Loss: 1461.14065234375, Val Loss: 98339.3984375, Time took: 0.4329984188079834\n",
      "Train loss Meta Info:  [1418.57615625   42.56451373]\n",
      "Val Loss Meta Info:  [56753.635, 41585.7625]\n",
      "\n",
      "Epoch: 98, NLL Loss: 1461.01428125, Val Loss: 93158.78125, Time took: 0.42795610427856445\n",
      "Train loss Meta Info:  [1418.56547266   42.44880945]\n",
      "Val Loss Meta Info:  [56753.22, 36405.5525]\n",
      "\n",
      "Epoch: 99, NLL Loss: 1461.05263671875, Val Loss: 95253.7890625, Time took: 0.4286930561065674\n",
      "Train loss Meta Info:  [1418.56476953   42.48785706]\n",
      "Val Loss Meta Info:  [56753.39, 38500.4]\n",
      "\n",
      "Epoch: 100, NLL Loss: 1460.92266015625, Val Loss: 93657.1171875, Time took: 0.44003963470458984\n",
      "Train loss Meta Info:  [1418.57230859   42.35033057]\n",
      "Val Loss Meta Info:  [56753.805, 36903.3125]\n",
      "\n",
      "Epoch: 101, NLL Loss: 1460.75131640625, Val Loss: 87756.8984375, Time took: 0.4273860454559326\n",
      "Train loss Meta Info:  [1418.56989844   42.18140503]\n",
      "Val Loss Meta Info:  [56754.455, 31002.4525]\n",
      "\n",
      "Epoch: 102, NLL Loss: 1460.99183984375, Val Loss: 91880.4140625, Time took: 0.44605517387390137\n",
      "Train loss Meta Info:  [1418.57377344   42.41806213]\n",
      "Val Loss Meta Info:  [56754.485, 35125.9425]\n",
      "\n",
      "Epoch: 103, NLL Loss: 1460.8642578125, Val Loss: 87323.125, Time took: 0.4460570812225342\n",
      "Train loss Meta Info:  [1418.57425391   42.2900094 ]\n",
      "Val Loss Meta Info:  [56753.85, 30569.2875]\n",
      "\n",
      "Epoch: 104, NLL Loss: 1460.98487109375, Val Loss: 92347.234375, Time took: 0.4377419948577881\n",
      "Train loss Meta Info:  [1418.56658984   42.41829333]\n",
      "Val Loss Meta Info:  [56753.81, 35593.4225]\n",
      "\n",
      "Epoch: 105, NLL Loss: 1460.97765625, Val Loss: 84838.9765625, Time took: 0.4239010810852051\n",
      "Train loss Meta Info:  [1418.56644922   42.41116663]\n",
      "Val Loss Meta Info:  [56753.94, 28085.0275]\n",
      "\n",
      "Epoch: 106, NLL Loss: 1461.3325625, Val Loss: 91237.1875, Time took: 0.4275214672088623\n",
      "Train loss Meta Info:  [1418.56026953   42.77228625]\n",
      "Val Loss Meta Info:  [56754.385, 34482.8]\n",
      "\n",
      "Epoch: 107, NLL Loss: 1461.2303984375, Val Loss: 88017.8671875, Time took: 0.42418551445007324\n",
      "Train loss Meta Info:  [1418.56966797   42.66071942]\n",
      "Val Loss Meta Info:  [56753.965, 31263.91]\n",
      "\n",
      "Epoch: 108, NLL Loss: 1461.05091015625, Val Loss: 90447.890625, Time took: 0.4251394271850586\n",
      "Train loss Meta Info:  [1418.55964453   42.49126294]\n",
      "Val Loss Meta Info:  [56753.94, 33693.9525]\n",
      "\n",
      "Epoch: 109, NLL Loss: 1460.7375, Val Loss: 93462.765625, Time took: 0.4289224147796631\n",
      "Train loss Meta Info:  [1418.55895313   42.17853601]\n",
      "Val Loss Meta Info:  [56753.87, 36708.8925]\n",
      "\n",
      "Epoch: 110, NLL Loss: 1461.27018359375, Val Loss: 89197.140625, Time took: 0.42760705947875977\n",
      "Train loss Meta Info:  [1418.55128125   42.71889044]\n",
      "Val Loss Meta Info:  [56754.545, 32442.5925]\n",
      "\n",
      "Epoch: 111, NLL Loss: 1461.1540078125, Val Loss: 90440.875, Time took: 0.41991472244262695\n",
      "Train loss Meta Info:  [1418.55646484   42.59754242]\n",
      "Val Loss Meta Info:  [56754.43, 33686.445]\n",
      "\n",
      "Epoch: 112, NLL Loss: 1460.9895859375, Val Loss: 101895.1875, Time took: 0.41359853744506836\n",
      "Train loss Meta Info:  [1418.5525       42.43708234]\n",
      "Val Loss Meta Info:  [56753.79, 45141.4]\n",
      "\n",
      "Epoch: 113, NLL Loss: 1461.088609375, Val Loss: 100658.5, Time took: 0.4171109199523926\n",
      "Train loss Meta Info:  [1418.54580859   42.54279938]\n",
      "Val Loss Meta Info:  [56753.775, 43904.725]\n",
      "\n",
      "Epoch: 114, NLL Loss: 1460.8086796875, Val Loss: 92740.9296875, Time took: 0.4119584560394287\n",
      "Train loss Meta Info:  [1418.55162109   42.25705762]\n",
      "Val Loss Meta Info:  [56753.715, 35987.215]\n",
      "\n",
      "Epoch: 115, NLL Loss: 1460.92574609375, Val Loss: 91958.4609375, Time took: 0.41407251358032227\n",
      "Train loss Meta Info:  [1418.5443125    42.38141235]\n",
      "Val Loss Meta Info:  [56753.845, 35204.6125]\n",
      "\n",
      "Epoch: 116, NLL Loss: 1460.68559375, Val Loss: 91248.6484375, Time took: 0.41764068603515625\n",
      "Train loss Meta Info:  [1418.54183984   42.14373798]\n",
      "Val Loss Meta Info:  [56754.405, 34494.25]\n",
      "\n",
      "Epoch: 117, NLL Loss: 1460.91372265625, Val Loss: 86829.4609375, Time took: 0.42107677459716797\n",
      "Train loss Meta Info:  [1418.55053125   42.36318103]\n",
      "Val Loss Meta Info:  [56753.845, 30075.6125]\n",
      "\n",
      "Epoch: 118, NLL Loss: 1460.9054453125, Val Loss: 90411.234375, Time took: 0.4199864864349365\n",
      "Train loss Meta Info:  [1418.53259766   42.37284021]\n",
      "Val Loss Meta Info:  [56753.74, 33657.49]\n",
      "\n",
      "Epoch: 119, NLL Loss: 1460.60848828125, Val Loss: 90818.734375, Time took: 0.43132638931274414\n",
      "Train loss Meta Info:  [1418.53520703   42.0733186 ]\n",
      "Val Loss Meta Info:  [56753.71, 34065.035]\n",
      "\n",
      "Epoch: 120, NLL Loss: 1460.8446328125, Val Loss: 85791.5078125, Time took: 0.4389057159423828\n",
      "Train loss Meta Info:  [1418.53474219   42.30986975]\n",
      "Val Loss Meta Info:  [56753.895, 29037.6175]\n",
      "\n",
      "Epoch: 121, NLL Loss: 1461.1591328125, Val Loss: 88136.78125, Time took: 0.44814157485961914\n",
      "Train loss Meta Info:  [1418.52692578   42.6322074 ]\n",
      "Val Loss Meta Info:  [56753.99, 31382.79]\n",
      "\n",
      "Epoch: 122, NLL Loss: 1460.49093359375, Val Loss: 91024.9609375, Time took: 0.4365503787994385\n",
      "Train loss Meta Info:  [1418.52714844   41.96376123]\n",
      "Val Loss Meta Info:  [56753.77, 34271.195]\n",
      "\n",
      "Epoch: 123, NLL Loss: 1460.781390625, Val Loss: 86676.1796875, Time took: 0.44056224822998047\n",
      "Train loss Meta Info:  [1418.5253125    42.25610712]\n",
      "Val Loss Meta Info:  [56754.17, 29922.005]\n",
      "\n",
      "Epoch: 124, NLL Loss: 1461.28101171875, Val Loss: 88940.6015625, Time took: 0.4226713180541992\n",
      "Train loss Meta Info:  [1418.52779687   42.75320996]\n",
      "Val Loss Meta Info:  [56754.105, 32186.4975]\n",
      "\n",
      "Epoch: 125, NLL Loss: 1460.4314609375, Val Loss: 99669.234375, Time took: 0.42603445053100586\n",
      "Train loss Meta Info:  [1418.52210547   41.90936285]\n",
      "Val Loss Meta Info:  [56754.475, 42914.76]\n",
      "\n",
      "Epoch: 126, NLL Loss: 1461.56483203125, Val Loss: 87134.65625, Time took: 0.42374539375305176\n",
      "Train loss Meta Info:  [1418.52801563   43.03681763]\n",
      "Val Loss Meta Info:  [56754.31, 30380.3575]\n",
      "\n",
      "Epoch: 127, NLL Loss: 1461.34137890625, Val Loss: 93483.21875, Time took: 0.42602086067199707\n",
      "Train loss Meta Info:  [1418.52375391   42.81763031]\n",
      "Val Loss Meta Info:  [56754.03, 36729.1825]\n",
      "\n",
      "Epoch: 128, NLL Loss: 1461.0631484375, Val Loss: 98524.1796875, Time took: 0.424854040145874\n",
      "Train loss Meta Info:  [1418.51965625   42.54349188]\n",
      "Val Loss Meta Info:  [56754.31, 41769.865]\n",
      "\n",
      "Epoch: 129, NLL Loss: 1461.3811484375, Val Loss: 96600.5390625, Time took: 0.4276161193847656\n",
      "Train loss Meta Info:  [1418.52406641   42.85708081]\n",
      "Val Loss Meta Info:  [56754.31, 39846.225]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, NLL Loss: 1460.6780625, Val Loss: 93300.9140625, Time took: 0.42639994621276855\n",
      "Train loss Meta Info:  [1418.51830469   42.15975555]\n",
      "Val Loss Meta Info:  [56754.23, 36546.685]\n",
      "\n",
      "Epoch: 131, NLL Loss: 1461.11359765625, Val Loss: 95401.4609375, Time took: 0.41133594512939453\n",
      "Train loss Meta Info:  [1418.51592578   42.59768646]\n",
      "Val Loss Meta Info:  [56754.4, 38647.065]\n",
      "\n",
      "Epoch: 132, NLL Loss: 1460.64925, Val Loss: 99029.0390625, Time took: 0.41181230545043945\n",
      "Train loss Meta Info:  [1418.51773047   42.13153912]\n",
      "Val Loss Meta Info:  [56754.72, 42274.31]\n",
      "\n",
      "Epoch: 133, NLL Loss: 1460.97366796875, Val Loss: 97087.125, Time took: 0.41220974922180176\n",
      "Train loss Meta Info:  [1418.524        42.44965088]\n",
      "Val Loss Meta Info:  [56754.545, 40332.585]\n",
      "\n",
      "Epoch: 134, NLL Loss: 1460.47495703125, Val Loss: 87549.6015625, Time took: 0.4136812686920166\n",
      "Train loss Meta Info:  [1418.52108203   41.95388385]\n",
      "Val Loss Meta Info:  [56754.425, 30795.17]\n",
      "\n",
      "Epoch: 135, NLL Loss: 1460.8127421875, Val Loss: 92859.6953125, Time took: 0.40969395637512207\n",
      "Train loss Meta Info:  [1418.51798828   42.29474689]\n",
      "Val Loss Meta Info:  [56754.635, 36105.06]\n",
      "\n",
      "Epoch: 136, NLL Loss: 1460.39928125, Val Loss: 97242.8203125, Time took: 0.41201066970825195\n",
      "Train loss Meta Info:  [1418.51533594   41.88396484]\n",
      "Val Loss Meta Info:  [56754.9, 40487.9125]\n",
      "\n",
      "Epoch: 137, NLL Loss: 1460.6278828125, Val Loss: 85986.9765625, Time took: 0.4090137481689453\n",
      "Train loss Meta Info:  [1418.51252344   42.11535406]\n",
      "Val Loss Meta Info:  [56754.87, 29232.12]\n",
      "\n",
      "Epoch: 138, NLL Loss: 1460.63127734375, Val Loss: 87680.9765625, Time took: 0.4061434268951416\n",
      "Train loss Meta Info:  [1418.50797656   42.12330084]\n",
      "Val Loss Meta Info:  [56754.96, 30926.03]\n",
      "\n",
      "Epoch: 139, NLL Loss: 1460.37812890625, Val Loss: 97234.1015625, Time took: 0.4146456718444824\n",
      "Train loss Meta Info:  [1418.50685937   41.87127612]\n",
      "Val Loss Meta Info:  [56755.01, 40479.085]\n",
      "\n",
      "Epoch: 140, NLL Loss: 1460.640515625, Val Loss: 89006.7109375, Time took: 0.4127364158630371\n",
      "Train loss Meta Info:  [1418.50769531   42.13281122]\n",
      "Val Loss Meta Info:  [56755.21, 32251.495]\n",
      "\n",
      "Epoch: 141, NLL Loss: 1460.27454296875, Val Loss: 84875.296875, Time took: 0.41510534286499023\n",
      "Train loss Meta Info:  [1418.5079375    41.76661365]\n",
      "Val Loss Meta Info:  [56755.49, 28119.805]\n",
      "\n",
      "Epoch: 142, NLL Loss: 1460.48176953125, Val Loss: 93127.1171875, Time took: 0.41129541397094727\n",
      "Train loss Meta Info:  [1418.50958203   41.97220367]\n",
      "Val Loss Meta Info:  [56755.45, 36371.665]\n",
      "\n",
      "Epoch: 143, NLL Loss: 1460.523546875, Val Loss: 91808.75, Time took: 0.4140763282775879\n",
      "Train loss Meta Info:  [1418.50869922   42.0148808 ]\n",
      "Val Loss Meta Info:  [56755.32, 35053.435]\n",
      "\n",
      "Epoch: 144, NLL Loss: 1460.2463125, Val Loss: 90679.015625, Time took: 0.41826891899108887\n",
      "Train loss Meta Info:  [1418.50182422   41.74447211]\n",
      "Val Loss Meta Info:  [56755.245, 33923.79]\n",
      "\n",
      "Epoch: 145, NLL Loss: 1460.4093515625, Val Loss: 95623.9609375, Time took: 0.41095709800720215\n",
      "Train loss Meta Info:  [1418.49723438   41.91212628]\n",
      "Val Loss Meta Info:  [56755.22, 38868.7375]\n",
      "\n",
      "Epoch: 146, NLL Loss: 1460.25841015625, Val Loss: 95916.3046875, Time took: 0.43090128898620605\n",
      "Train loss Meta Info:  [1418.49451563   41.76388666]\n",
      "Val Loss Meta Info:  [56755.11, 39161.1925]\n",
      "\n",
      "Epoch: 147, NLL Loss: 1460.14496484375, Val Loss: 86759.8359375, Time took: 0.41976380348205566\n",
      "Train loss Meta Info:  [1418.49227734   41.65270575]\n",
      "Val Loss Meta Info:  [56755.03, 30004.805]\n",
      "\n",
      "Epoch: 148, NLL Loss: 1460.41650390625, Val Loss: 93430.859375, Time took: 0.41935300827026367\n",
      "Train loss Meta Info:  [1418.49017969   41.92631873]\n",
      "Val Loss Meta Info:  [56755.36, 36675.4975]\n",
      "\n",
      "Epoch: 149, NLL Loss: 1460.33362109375, Val Loss: 88768.234375, Time took: 0.4139225482940674\n",
      "Train loss Meta Info:  [1418.4930625    41.84056567]\n",
      "Val Loss Meta Info:  [56755.51, 32012.73]\n",
      "\n",
      "Epoch: 150, NLL Loss: 1460.11978125, Val Loss: 88074.28125, Time took: 0.41544532775878906\n",
      "Train loss Meta Info:  [1418.48861719   41.63116077]\n",
      "Val Loss Meta Info:  [56755.565, 31318.7125]\n",
      "\n",
      "Epoch: 151, NLL Loss: 1460.1677265625, Val Loss: 96595.4296875, Time took: 0.415851354598999\n",
      "Train loss Meta Info:  [1418.48657031   41.68110919]\n",
      "Val Loss Meta Info:  [56755.55, 39839.8725]\n",
      "\n",
      "Epoch: 152, NLL Loss: 1460.21728515625, Val Loss: 88487.234375, Time took: 0.4101722240447998\n",
      "Train loss Meta Info:  [1418.48744922   41.72981635]\n",
      "Val Loss Meta Info:  [56755.37, 31731.8675]\n",
      "\n",
      "Epoch: 153, NLL Loss: 1460.068625, Val Loss: 91302.8203125, Time took: 0.4148104190826416\n",
      "Train loss Meta Info:  [1418.48359375   41.58503491]\n",
      "Val Loss Meta Info:  [56755.395, 34547.4275]\n",
      "\n",
      "Epoch: 154, NLL Loss: 1460.0128359375, Val Loss: 93065.875, Time took: 0.4151725769042969\n",
      "Train loss Meta Info:  [1418.48170703   41.5311156 ]\n",
      "Val Loss Meta Info:  [56755.59, 36310.295]\n",
      "\n",
      "Epoch: 155, NLL Loss: 1460.09842578125, Val Loss: 90076.9375, Time took: 0.4192826747894287\n",
      "Train loss Meta Info:  [1418.48078906   41.61765546]\n",
      "Val Loss Meta Info:  [56755.55, 33321.3975]\n",
      "\n",
      "Epoch: 156, NLL Loss: 1460.1372109375, Val Loss: 92531.6796875, Time took: 0.42438459396362305\n",
      "Train loss Meta Info:  [1418.47665625   41.66055231]\n",
      "Val Loss Meta Info:  [56755.73, 35775.9425]\n",
      "\n",
      "Epoch: 157, NLL Loss: 1460.10028515625, Val Loss: 91516.4375, Time took: 0.41454195976257324\n",
      "Train loss Meta Info:  [1418.47711328   41.62314581]\n",
      "Val Loss Meta Info:  [56755.73, 34760.7075]\n",
      "\n",
      "Epoch: 158, NLL Loss: 1459.9784453125, Val Loss: 90464.90625, Time took: 0.41573309898376465\n",
      "Train loss Meta Info:  [1418.47461719   41.50381604]\n",
      "Val Loss Meta Info:  [56755.635, 33709.2775]\n",
      "\n",
      "Epoch: 159, NLL Loss: 1460.00598828125, Val Loss: 92723.578125, Time took: 0.40987157821655273\n",
      "Train loss Meta Info:  [1418.47189453   41.53409119]\n",
      "Val Loss Meta Info:  [56755.555, 35968.0275]\n",
      "\n",
      "Epoch: 160, NLL Loss: 1460.154984375, Val Loss: 83575.515625, Time took: 0.4246797561645508\n",
      "Train loss Meta Info:  [1418.47298828   41.6820061 ]\n",
      "Val Loss Meta Info:  [56755.46, 26820.0575]\n",
      "\n",
      "Epoch: 161, NLL Loss: 1460.4231171875, Val Loss: 94641.359375, Time took: 0.41554808616638184\n",
      "Train loss Meta Info:  [1418.46786719   41.95525311]\n",
      "Val Loss Meta Info:  [56755.76, 37885.6]\n",
      "\n",
      "Epoch: 162, NLL Loss: 1460.5749453125, Val Loss: 87083.78125, Time took: 0.41562891006469727\n",
      "Train loss Meta Info:  [1418.46914453   42.1058374 ]\n",
      "Val Loss Meta Info:  [56755.91, 30327.8725]\n",
      "\n",
      "Epoch: 163, NLL Loss: 1460.0918125, Val Loss: 92720.9609375, Time took: 0.4161381721496582\n",
      "Train loss Meta Info:  [1418.46432422   41.62745856]\n",
      "Val Loss Meta Info:  [56756.09, 35964.8725]\n",
      "\n",
      "Epoch: 164, NLL Loss: 1460.031234375, Val Loss: 93237.515625, Time took: 0.4311213493347168\n",
      "Train loss Meta Info:  [1418.46359766   41.56764465]\n",
      "Val Loss Meta Info:  [56756.02, 36481.505]\n",
      "\n",
      "Epoch: 165, NLL Loss: 1460.03530859375, Val Loss: 90988.71875, Time took: 0.42060303688049316\n",
      "Train loss Meta Info:  [1418.46147266   41.5738241 ]\n",
      "Val Loss Meta Info:  [56755.9, 34232.8225]\n",
      "\n",
      "Epoch: 166, NLL Loss: 1460.04634765625, Val Loss: 93743.96875, Time took: 0.4158318042755127\n",
      "Train loss Meta Info:  [1418.46230078   41.58405792]\n",
      "Val Loss Meta Info:  [56755.99, 36987.9625]\n",
      "\n",
      "Epoch: 167, NLL Loss: 1460.0964453125, Val Loss: 92570.4140625, Time took: 0.41722846031188965\n",
      "Train loss Meta Info:  [1418.46148438   41.63494183]\n",
      "Val Loss Meta Info:  [56756.15, 35814.2775]\n",
      "\n",
      "Epoch: 168, NLL Loss: 1459.91612109375, Val Loss: 95593.296875, Time took: 0.41686105728149414\n",
      "Train loss Meta Info:  [1418.45689844   41.45923145]\n",
      "Val Loss Meta Info:  [56756.575, 38836.72]\n",
      "\n",
      "Epoch: 169, NLL Loss: 1459.9411796875, Val Loss: 92686.15625, Time took: 0.4208683967590332\n",
      "Train loss Meta Info:  [1418.45778125   41.48338446]\n",
      "Val Loss Meta Info:  [56756.565, 35929.5975]\n",
      "\n",
      "Epoch: 170, NLL Loss: 1460.1424296875, Val Loss: 84138.015625, Time took: 0.4145958423614502\n",
      "Train loss Meta Info:  [1418.45616016   41.68628052]\n",
      "Val Loss Meta Info:  [56756.41, 27381.6225]\n",
      "\n",
      "Epoch: 171, NLL Loss: 1460.20059765625, Val Loss: 91831.4140625, Time took: 0.41847753524780273\n",
      "Train loss Meta Info:  [1418.45287891   41.7476925 ]\n",
      "Val Loss Meta Info:  [56756.575, 35074.845]\n",
      "\n",
      "Epoch: 172, NLL Loss: 1460.0968046875, Val Loss: 90442.21875, Time took: 0.41732192039489746\n",
      "Train loss Meta Info:  [1418.45333203   41.64346973]\n",
      "Val Loss Meta Info:  [56756.495, 33685.7375]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173, NLL Loss: 1459.9007578125, Val Loss: 87331.2265625, Time took: 0.42354869842529297\n",
      "Train loss Meta Info:  [1418.44944141   41.45131122]\n",
      "Val Loss Meta Info:  [56756.355, 30574.875]\n",
      "\n",
      "Epoch: 174, NLL Loss: 1460.0692265625, Val Loss: 102931.359375, Time took: 0.4225592613220215\n",
      "Train loss Meta Info:  [1418.44421875   41.62498981]\n",
      "Val Loss Meta Info:  [56756.73, 46174.61]\n",
      "\n",
      "Epoch: 175, NLL Loss: 1460.17372265625, Val Loss: 88596.546875, Time took: 0.42085766792297363\n",
      "Train loss Meta Info:  [1418.44694922   41.72678265]\n",
      "Val Loss Meta Info:  [56756.83, 31839.7225]\n",
      "\n",
      "Epoch: 176, NLL Loss: 1460.03976171875, Val Loss: 92093.109375, Time took: 0.41774749755859375\n",
      "Train loss Meta Info:  [1418.44430469   41.59547321]\n",
      "Val Loss Meta Info:  [56756.75, 35336.35]\n",
      "\n",
      "Epoch: 177, NLL Loss: 1460.0770546875, Val Loss: 91416.609375, Time took: 0.4291188716888428\n",
      "Train loss Meta Info:  [1418.44056641   41.63649988]\n",
      "Val Loss Meta Info:  [56756.66, 34659.9475]\n",
      "\n",
      "Epoch: 178, NLL Loss: 1459.87686328125, Val Loss: 88110.796875, Time took: 0.41982531547546387\n",
      "Train loss Meta Info:  [1418.43685547   41.43997607]\n",
      "Val Loss Meta Info:  [56756.82, 31353.975]\n",
      "\n",
      "Epoch: 179, NLL Loss: 1459.89571484375, Val Loss: 93770.359375, Time took: 0.4225020408630371\n",
      "Train loss Meta Info:  [1418.43626953   41.45944446]\n",
      "Val Loss Meta Info:  [56756.955, 37013.405]\n",
      "\n",
      "Epoch: 180, NLL Loss: 1460.0265078125, Val Loss: 88201.6171875, Time took: 0.41698598861694336\n",
      "Train loss Meta Info:  [1418.43511328   41.59140137]\n",
      "Val Loss Meta Info:  [56756.84, 31444.785]\n",
      "\n",
      "Epoch: 181, NLL Loss: 1459.85509375, Val Loss: 93233.140625, Time took: 0.43335652351379395\n",
      "Train loss Meta Info:  [1418.43295313   41.42212506]\n",
      "Val Loss Meta Info:  [56757.145, 36476.005]\n",
      "\n",
      "Epoch: 182, NLL Loss: 1459.8398515625, Val Loss: 92869.4140625, Time took: 0.44271016120910645\n",
      "Train loss Meta Info:  [1418.43116797   41.40866608]\n",
      "Val Loss Meta Info:  [56757.275, 36112.135]\n",
      "\n",
      "Epoch: 183, NLL Loss: 1459.7564453125, Val Loss: 90093.5390625, Time took: 0.44548559188842773\n",
      "Train loss Meta Info:  [1418.42737109   41.32905115]\n",
      "Val Loss Meta Info:  [56756.995, 33336.5475]\n",
      "\n",
      "Epoch: 184, NLL Loss: 1459.7034296875, Val Loss: 94446.359375, Time took: 0.4232761859893799\n",
      "Train loss Meta Info:  [1418.42494141   41.27848242]\n",
      "Val Loss Meta Info:  [56757.13, 37689.23]\n",
      "\n",
      "Epoch: 185, NLL Loss: 1459.80601171875, Val Loss: 83859.3125, Time took: 0.4251229763031006\n",
      "Train loss Meta Info:  [1418.42497266   41.38104865]\n",
      "Val Loss Meta Info:  [56757.43, 27101.875]\n",
      "\n",
      "Epoch: 186, NLL Loss: 1459.83037109375, Val Loss: 94120.828125, Time took: 0.42349767684936523\n",
      "Train loss Meta Info:  [1418.41846094   41.41191284]\n",
      "Val Loss Meta Info:  [56757.875, 37362.95]\n",
      "\n",
      "Epoch: 187, NLL Loss: 1459.95621875, Val Loss: 88199.7109375, Time took: 0.43034958839416504\n",
      "Train loss Meta Info:  [1418.42007812   41.5361546 ]\n",
      "Val Loss Meta Info:  [56757.45, 31442.2675]\n",
      "\n",
      "Epoch: 188, NLL Loss: 1460.0700234375, Val Loss: 93150.359375, Time took: 0.4200165271759033\n",
      "Train loss Meta Info:  [1418.41812109   41.65190411]\n",
      "Val Loss Meta Info:  [56757.74, 36392.62]\n",
      "\n",
      "Epoch: 189, NLL Loss: 1460.05569140625, Val Loss: 90748.3203125, Time took: 0.4254319667816162\n",
      "Train loss Meta Info:  [1418.41405859   41.64164764]\n",
      "Val Loss Meta Info:  [56757.63, 33990.6925]\n",
      "\n",
      "Epoch: 190, NLL Loss: 1459.7743515625, Val Loss: 89821.6015625, Time took: 0.4114243984222412\n",
      "Train loss Meta Info:  [1418.40931641   41.3650307 ]\n",
      "Val Loss Meta Info:  [56757.73, 33063.8725]\n",
      "\n",
      "Epoch: 191, NLL Loss: 1459.88161328125, Val Loss: 91398.4609375, Time took: 0.40863728523254395\n",
      "Train loss Meta Info:  [1418.40786328   41.47373499]\n",
      "Val Loss Meta Info:  [56758.07, 34640.3825]\n",
      "\n",
      "Epoch: 192, NLL Loss: 1459.88907421875, Val Loss: 90409.65625, Time took: 0.40871739387512207\n",
      "Train loss Meta Info:  [1418.4086875    41.48040649]\n",
      "Val Loss Meta Info:  [56757.81, 33651.8525]\n",
      "\n",
      "Epoch: 193, NLL Loss: 1459.68583984375, Val Loss: 99960.640625, Time took: 0.40888476371765137\n",
      "Train loss Meta Info:  [1418.40367578   41.28214313]\n",
      "Val Loss Meta Info:  [56758.305, 43202.345]\n",
      "\n",
      "Epoch: 194, NLL Loss: 1459.7375859375, Val Loss: 90505.65625, Time took: 0.4051792621612549\n",
      "Train loss Meta Info:  [1418.40520703   41.33234796]\n",
      "Val Loss Meta Info:  [56758.545, 33747.1075]\n",
      "\n",
      "Epoch: 195, NLL Loss: 1459.74098828125, Val Loss: 88671.6796875, Time took: 0.42629551887512207\n",
      "Train loss Meta Info:  [1418.40205859   41.33893768]\n",
      "Val Loss Meta Info:  [56757.9, 31913.77]\n",
      "\n",
      "Epoch: 196, NLL Loss: 1459.7580390625, Val Loss: 93163.4140625, Time took: 0.4184272289276123\n",
      "Train loss Meta Info:  [1418.39582812   41.36220105]\n",
      "Val Loss Meta Info:  [56758.245, 36405.1775]\n",
      "\n",
      "Epoch: 197, NLL Loss: 1459.91928125, Val Loss: 82565.9453125, Time took: 0.4203176498413086\n",
      "Train loss Meta Info:  [1418.39688672   41.52239093]\n",
      "Val Loss Meta Info:  [56758.38, 25807.5625]\n",
      "\n",
      "Epoch: 198, NLL Loss: 1459.86726171875, Val Loss: 105005.8203125, Time took: 0.41614508628845215\n",
      "Train loss Meta Info:  [1418.39048047   41.47677612]\n",
      "Val Loss Meta Info:  [56758.68, 48247.155]\n",
      "\n",
      "Epoch: 199, NLL Loss: 1460.09020703125, Val Loss: 90299.140625, Time took: 0.418689489364624\n",
      "Train loss Meta Info:  [1418.39019141   41.70000916]\n",
      "Val Loss Meta Info:  [56758.35, 33540.7925]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=rmtpp, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hrmtpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([50, 8000, 2]), Val Data Shape: torch.Size([50, 2000, 2])\n",
      "Markers: Data Shape: torch.Size([50, 8000, 20]), Val Data Shape: torch.Size([50, 2000, 20])\n",
      "Epoch: 0, NLL Loss: 1516.4166796875, Val Loss: 62809.91015625, Time took: 0.8191773891448975\n",
      "Train loss Meta Info:  [1.45660838e+03 5.97120386e+01 9.62728846e-02]\n",
      "Val Loss Meta Info:  [61924.735, 865.41125, 19.767064208984376]\n",
      "\n",
      "Epoch: 1, NLL Loss: 1570.9606171875, Val Loss: 63048.6171875, Time took: 0.7823503017425537\n",
      "Train loss Meta Info:  [1.54753283e+03 2.29328391e+01 4.94971273e-01]\n",
      "Val Loss Meta Info:  [60706.565, 2333.8765625, 8.181640625]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1576.44079296875, Val Loss: 61415.35546875, Time took: 0.7858977317810059\n",
      "Train loss Meta Info:  [1.51797221e+03 5.82640049e+01 2.04570010e-01]\n",
      "Val Loss Meta Info:  [59194.1, 2190.0465625, 31.204609375]\n",
      "\n",
      "Epoch: 3, NLL Loss: 1534.813140625, Val Loss: 60538.9140625, Time took: 0.7918968200683594\n",
      "Train loss Meta Info:  [1.47959564e+03 5.44361400e+01 7.81387877e-01]\n",
      "Val Loss Meta Info:  [58346.8, 2166.5675, 25.54728759765625]\n",
      "\n",
      "Epoch: 4, NLL Loss: 1512.20421875, Val Loss: 60177.98828125, Time took: 0.7998480796813965\n",
      "Train loss Meta Info:  [1.45878285e+03 5.27813524e+01 6.40012155e-01]\n",
      "Val Loss Meta Info:  [57814.75, 2242.7240625, 120.52111328125]\n",
      "\n",
      "Epoch: 5, NLL Loss: 1501.31430078125, Val Loss: 60066.828125, Time took: 0.8103859424591064\n",
      "Train loss Meta Info:  [1445.45726172   52.82947961    3.02753273]\n",
      "Val Loss Meta Info:  [57547.33, 2453.203125, 66.2983447265625]\n",
      "\n",
      "Epoch: 6, NLL Loss: 1492.2239140625, Val Loss: 60100.046875, Time took: 0.812122106552124\n",
      "Train loss Meta Info:  [1438.38381641   52.17683679    1.66325678]\n",
      "Val Loss Meta Info:  [57310.09, 2710.699375, 79.266796875]\n",
      "\n",
      "Epoch: 7, NLL Loss: 1485.96901953125, Val Loss: 60177.7734375, Time took: 0.8179738521575928\n",
      "Train loss Meta Info:  [1432.45715234   51.52494177    1.98695046]\n",
      "Val Loss Meta Info:  [57283.77, 2865.0453125, 28.96021484375]\n",
      "\n",
      "Epoch: 8, NLL Loss: 1484.107875, Val Loss: 61052.73046875, Time took: 0.8185110092163086\n",
      "Train loss Meta Info:  [1.43171233e+03 5.16693143e+01 7.26210817e-01]\n",
      "Val Loss Meta Info:  [57104.325, 3938.2734375, 10.13126708984375]\n",
      "\n",
      "Epoch: 9, NLL Loss: 1478.46903125, Val Loss: 62400.6953125, Time took: 0.8184552192687988\n",
      "Train loss Meta Info:  [1.42742392e+03 5.07900522e+01 2.55070221e-01]\n",
      "Val Loss Meta Info:  [57125.255, 5255.5075, 19.93552490234375]\n",
      "\n",
      "Epoch: 10, NLL Loss: 1479.15621875, Val Loss: 62916.953125, Time took: 0.8059558868408203\n",
      "Train loss Meta Info:  [1.42800490e+03 5.06509310e+01 5.00375326e-01]\n",
      "Val Loss Meta Info:  [57064.715, 5796.745625, 55.494296875]\n",
      "\n",
      "Epoch: 11, NLL Loss: 1478.003296875, Val Loss: 65251.171875, Time took: 0.8071916103363037\n",
      "Train loss Meta Info:  [1.42641159e+03 5.02010927e+01 1.39064282e+00]\n",
      "Val Loss Meta Info:  [57024.8, 8179.270625, 47.1054052734375]\n",
      "\n",
      "Epoch: 12, NLL Loss: 1476.01816796875, Val Loss: 70177.890625, Time took: 0.8086025714874268\n",
      "Train loss Meta Info:  [1.42543187e+03 4.94085715e+01 1.17773133e+00]\n",
      "Val Loss Meta Info:  [57110.645, 13039.96, 27.2801220703125]\n",
      "\n",
      "Epoch: 13, NLL Loss: 1477.54044921875, Val Loss: 68447.5703125, Time took: 0.7971000671386719\n",
      "Train loss Meta Info:  [1.42751956e+03 4.93417041e+01 6.79174488e-01]\n",
      "Val Loss Meta Info:  [57187.21, 11236.64, 23.726083984375]\n",
      "\n",
      "Epoch: 14, NLL Loss: 1479.31918359375, Val Loss: 72028.078125, Time took: 0.8046677112579346\n",
      "Train loss Meta Info:  [1.42945906e+03 4.92702985e+01 5.89821979e-01]\n",
      "Val Loss Meta Info:  [57041.86, 14977.08375, 9.13205078125]\n",
      "\n",
      "Epoch: 15, NLL Loss: 1473.95875390625, Val Loss: 75109.7421875, Time took: 0.8075673580169678\n",
      "Train loss Meta Info:  [1.42581909e+03 4.79143271e+01 2.25323328e-01]\n",
      "Val Loss Meta Info:  [56951.94, 18150.655, 7.15316650390625]\n",
      "\n",
      "Epoch: 16, NLL Loss: 1471.14942578125, Val Loss: 84528.328125, Time took: 0.7899720668792725\n",
      "Train loss Meta Info:  [1.42357753e+03 4.73948647e+01 1.77019958e-01]\n",
      "Val Loss Meta Info:  [56972.8, 27548.365, 7.166931762695312]\n",
      "\n",
      "Epoch: 17, NLL Loss: 1471.6023515625, Val Loss: 87440.671875, Time took: 0.80135178565979\n",
      "Train loss Meta Info:  [1.42406140e+03 4.73627940e+01 1.78146822e-01]\n",
      "Val Loss Meta Info:  [56937.75, 30495.6425, 7.271434936523438]\n",
      "\n",
      "Epoch: 18, NLL Loss: 1470.68073046875, Val Loss: 96446.734375, Time took: 0.8003289699554443\n",
      "Train loss Meta Info:  [1.42339933e+03 4.71001681e+01 1.81207538e-01]\n",
      "Val Loss Meta Info:  [56936.995, 39502.7325, 7.012473754882812]\n",
      "\n",
      "Epoch: 19, NLL Loss: 1470.07427734375, Val Loss: 103678.140625, Time took: 0.8037521839141846\n",
      "Train loss Meta Info:  [1.42321394e+03 4.66857667e+01 1.74557665e-01]\n",
      "Val Loss Meta Info:  [56902.58, 46769.775, 5.79845947265625]\n",
      "\n",
      "Epoch: 20, NLL Loss: 1469.27440625, Val Loss: 101206.359375, Time took: 0.8217446804046631\n",
      "Train loss Meta Info:  [1.42237034e+03 4.67598315e+01 1.44230304e-01]\n",
      "Val Loss Meta Info:  [56911.825, 44290.25, 4.278203125]\n",
      "\n",
      "Epoch: 21, NLL Loss: 1469.0888125, Val Loss: 107266.734375, Time took: 0.8176884651184082\n",
      "Train loss Meta Info:  [1.42251827e+03 4.64642714e+01 1.06283697e-01]\n",
      "Val Loss Meta Info:  [56885.77, 50377.44, 3.5178179931640625]\n",
      "\n",
      "Epoch: 22, NLL Loss: 1468.077890625, Val Loss: 122382.25, Time took: 0.8215622901916504\n",
      "Train loss Meta Info:  [1.42183732e+03 4.61530256e+01 8.75305943e-02]\n",
      "Val Loss Meta Info:  [56882.59, 65496.365, 3.3095037841796877]\n",
      "\n",
      "Epoch: 23, NLL Loss: 1467.9626171875, Val Loss: 123062.6796875, Time took: 0.8206996917724609\n",
      "Train loss Meta Info:  [1.42172688e+03 4.61531608e+01 8.25817089e-02]\n",
      "Val Loss Meta Info:  [56856.99, 66202.47, 3.2191888427734376]\n",
      "\n",
      "Epoch: 24, NLL Loss: 1466.90763671875, Val Loss: 124065.515625, Time took: 0.8107028007507324\n",
      "Train loss Meta Info:  [1.42115197e+03 4.56752490e+01 8.04148308e-02]\n",
      "Val Loss Meta Info:  [56863.38, 67199.015, 3.1435641479492187]\n",
      "\n",
      "Epoch: 25, NLL Loss: 1467.06417578125, Val Loss: 122850.984375, Time took: 0.7903025150299072\n",
      "Train loss Meta Info:  [1.42133879e+03 4.56468433e+01 7.85387641e-02]\n",
      "Val Loss Meta Info:  [56841.14, 66006.74, 3.11486572265625]\n",
      "\n",
      "Epoch: 26, NLL Loss: 1466.315796875, Val Loss: 123897.890625, Time took: 0.7888128757476807\n",
      "Train loss Meta Info:  [1.42076274e+03 4.54752656e+01 7.78170369e-02]\n",
      "Val Loss Meta Info:  [56840.63, 67054.18, 3.070252685546875]\n",
      "\n",
      "Epoch: 27, NLL Loss: 1465.9190859375, Val Loss: 126614.1171875, Time took: 0.7986330986022949\n",
      "Train loss Meta Info:  [1.42076814e+03 4.50742875e+01 7.66826195e-02]\n",
      "Val Loss Meta Info:  [56823.185, 69787.96, 2.9797564697265626]\n",
      "\n",
      "Epoch: 28, NLL Loss: 1465.18837109375, Val Loss: 119362.515625, Time took: 0.7966091632843018\n",
      "Train loss Meta Info:  [1.42037659e+03 4.47373779e+01 7.43972819e-02]\n",
      "Val Loss Meta Info:  [56841.29, 62518.405, 2.840001220703125]\n",
      "\n",
      "Epoch: 29, NLL Loss: 1465.3748359375, Val Loss: 188187.0, Time took: 0.793006181716919\n",
      "Train loss Meta Info:  [1.42080811e+03 4.44958787e+01 7.08719519e-02]\n",
      "Val Loss Meta Info:  [56840.93, 131343.44, 2.632208251953125]\n",
      "\n",
      "Epoch: 30, NLL Loss: 1469.2431171875, Val Loss: 91155.65625, Time took: 0.8391728401184082\n",
      "Train loss Meta Info:  [1.42073988e+03 4.84376127e+01 6.56190455e-02]\n",
      "Val Loss Meta Info:  [56856.7, 34296.6175, 2.3396319580078124]\n",
      "\n",
      "Epoch: 31, NLL Loss: 1485.790015625, Val Loss: 146153.109375, Time took: 0.8423678874969482\n",
      "Train loss Meta Info:  [1.42114542e+03 6.45863005e+01 5.83100444e-02]\n",
      "Val Loss Meta Info:  [56836.615, 89314.22, 2.279920806884766]\n",
      "\n",
      "Epoch: 32, NLL Loss: 1467.94567578125, Val Loss: 275432.90625, Time took: 0.8458297252655029\n",
      "Train loss Meta Info:  [1.42055919e+03 4.73296982e+01 5.67696651e-02]\n",
      "Val Loss Meta Info:  [56842.59, 218588.0, 2.2735560607910155]\n",
      "\n",
      "Epoch: 33, NLL Loss: 1485.07961328125, Val Loss: 135745.515625, Time took: 0.8132181167602539\n",
      "Train loss Meta Info:  [1.42069345e+03 6.43296151e+01 5.65508171e-02]\n",
      "Val Loss Meta Info:  [56840.975, 78902.27, 2.283868408203125]\n",
      "\n",
      "Epoch: 34, NLL Loss: 1472.0691875, Val Loss: 116191.5078125, Time took: 0.814842939376831\n",
      "Train loss Meta Info:  [1.42075854e+03 5.12535629e+01 5.70838392e-02]\n",
      "Val Loss Meta Info:  [56823.51, 59365.465, 2.5174293518066406]\n",
      "\n",
      "Epoch: 35, NLL Loss: 1481.90355859375, Val Loss: 152957.609375, Time took: 0.8289773464202881\n",
      "Train loss Meta Info:  [1.42032346e+03 6.15169951e+01 6.30750860e-02]\n",
      "Val Loss Meta Info:  [56837.7, 96117.35, 2.5840267944335937]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, NLL Loss: 1472.6558984375, Val Loss: 233686.78125, Time took: 0.912043571472168\n",
      "Train loss Meta Info:  [1.42062735e+03 5.19639509e+01 6.46149240e-02]\n",
      "Val Loss Meta Info:  [56821.565, 176862.7, 2.512484130859375]\n",
      "\n",
      "Epoch: 37, NLL Loss: 1469.76530859375, Val Loss: 303803.25, Time took: 0.9261817932128906\n",
      "Train loss Meta Info:  [1.42019372e+03 4.95087677e+01 6.28020414e-02]\n",
      "Val Loss Meta Info:  [56832.74, 246968.12, 2.417215118408203]\n",
      "\n",
      "Epoch: 38, NLL Loss: 1476.67630859375, Val Loss: 233066.015625, Time took: 0.8218085765838623\n",
      "Train loss Meta Info:  [1.42049880e+03 5.61170577e+01 6.04277351e-02]\n",
      "Val Loss Meta Info:  [56828.6, 176235.14, 2.3116915893554686]\n",
      "\n",
      "Epoch: 39, NLL Loss: 1466.91131640625, Val Loss: 177829.15625, Time took: 0.8085103034973145\n",
      "Train loss Meta Info:  [1.42040465e+03 4.64488681e+01 5.77913826e-02]\n",
      "Val Loss Meta Info:  [56814.39, 121012.58, 2.2045576477050783]\n",
      "\n",
      "Epoch: 40, NLL Loss: 1469.13708984375, Val Loss: 174373.59375, Time took: 0.7892203330993652\n",
      "Train loss Meta Info:  [1.42003468e+03 4.90472590e+01 5.51139132e-02]\n",
      "Val Loss Meta Info:  [56849.23, 117522.29, 2.0971678161621092]\n",
      "\n",
      "Epoch: 41, NLL Loss: 1472.13725390625, Val Loss: 197531.46875, Time took: 0.7866864204406738\n",
      "Train loss Meta Info:  [1.42094255e+03 5.11423051e+01 5.24293468e-02]\n",
      "Val Loss Meta Info:  [56800.715, 140728.79, 1.98814697265625]\n",
      "\n",
      "Epoch: 42, NLL Loss: 1468.5674140625, Val Loss: 236330.796875, Time took: 0.798558235168457\n",
      "Train loss Meta Info:  [1.41970797e+03 4.88097415e+01 4.97025756e-02]\n",
      "Val Loss Meta Info:  [56811.57, 179517.34, 1.8797056579589844]\n",
      "\n",
      "Epoch: 43, NLL Loss: 1467.08576171875, Val Loss: 310740.03125, Time took: 0.7902917861938477\n",
      "Train loss Meta Info:  [1.41999464e+03 4.70440969e+01 4.69887248e-02]\n",
      "Val Loss Meta Info:  [56809.59, 253928.72, 1.77260498046875]\n",
      "\n",
      "Epoch: 44, NLL Loss: 1469.14953515625, Val Loss: 316405.53125, Time took: 0.7920022010803223\n",
      "Train loss Meta Info:  [1.41992247e+03 4.91827571e+01 4.43095649e-02]\n",
      "Val Loss Meta Info:  [56789.66, 259614.22, 1.6661099243164061]\n",
      "\n",
      "Epoch: 45, NLL Loss: 1467.79501953125, Val Loss: 264890.59375, Time took: 0.8115506172180176\n",
      "Train loss Meta Info:  [1.41944061e+03 4.83127624e+01 4.16484032e-02]\n",
      "Val Loss Meta Info:  [56790.55, 208098.44, 1.5615365600585938]\n",
      "\n",
      "Epoch: 46, NLL Loss: 1465.688453125, Val Loss: 228165.59375, Time took: 0.8031177520751953\n",
      "Train loss Meta Info:  [1.41947665e+03 4.61727559e+01 3.90361262e-02]\n",
      "Val Loss Meta Info:  [56787.58, 171376.56, 1.4599699401855468]\n",
      "\n",
      "Epoch: 47, NLL Loss: 1466.59321484375, Val Loss: 215084.25, Time took: 0.7913036346435547\n",
      "Train loss Meta Info:  [1.41939226e+03 4.71644408e+01 3.64982502e-02]\n",
      "Val Loss Meta Info:  [56784.15, 158298.74, 1.3611599731445312]\n",
      "\n",
      "Epoch: 48, NLL Loss: 1467.5644765625, Val Loss: 223290.421875, Time took: 0.7986874580383301\n",
      "Train loss Meta Info:  [1.41934141e+03 4.81890003e+01 3.40283945e-02]\n",
      "Val Loss Meta Info:  [56784.29, 166504.85, 1.264937286376953]\n",
      "\n",
      "Epoch: 49, NLL Loss: 1466.66865625, Val Loss: 260435.65625, Time took: 0.809497594833374\n",
      "Train loss Meta Info:  [1.41935054e+03 4.72865472e+01 3.16229622e-02]\n",
      "Val Loss Meta Info:  [56800.17, 203634.34, 1.1721311950683593]\n",
      "\n",
      "Epoch: 50, NLL Loss: 1465.8693203125, Val Loss: 263413.78125, Time took: 0.7983987331390381\n",
      "Train loss Meta Info:  [1.41972708e+03 4.61129201e+01 2.93028070e-02]\n",
      "Val Loss Meta Info:  [56788.415, 206624.34, 1.0839730834960937]\n",
      "\n",
      "Epoch: 51, NLL Loss: 1465.433015625, Val Loss: 267080.09375, Time took: 0.7985999584197998\n",
      "Train loss Meta Info:  [1.41941368e+03 4.59922587e+01 2.70986161e-02]\n",
      "Val Loss Meta Info:  [56801.365, 210277.7, 1.0004823303222656]\n",
      "\n",
      "Epoch: 52, NLL Loss: 1465.6215625, Val Loss: 266304.40625, Time took: 0.7959539890289307\n",
      "Train loss Meta Info:  [1.41974026e+03 4.58562889e+01 2.50110210e-02]\n",
      "Val Loss Meta Info:  [56786.93, 209516.56, 0.9216726684570312]\n",
      "\n",
      "Epoch: 53, NLL Loss: 1464.95945703125, Val Loss: 246101.21875, Time took: 0.788524866104126\n",
      "Train loss Meta Info:  [1.41934426e+03 4.55921472e+01 2.30406399e-02]\n",
      "Val Loss Meta Info:  [56791.89, 189308.52, 0.8476029968261719]\n",
      "\n",
      "Epoch: 54, NLL Loss: 1464.768203125, Val Loss: 231281.59375, Time took: 0.7980031967163086\n",
      "Train loss Meta Info:  [1.41946034e+03 4.52866396e+01 2.11890176e-02]\n",
      "Val Loss Meta Info:  [56783.93, 174496.92, 0.7782992553710938]\n",
      "\n",
      "Epoch: 55, NLL Loss: 1464.35983203125, Val Loss: 289010.625, Time took: 0.829578161239624\n",
      "Train loss Meta Info:  [1.41925607e+03 4.50843174e+01 1.94567279e-02]\n",
      "Val Loss Meta Info:  [56784.86, 232225.08, 0.7136744689941407]\n",
      "\n",
      "Epoch: 56, NLL Loss: 1464.37125390625, Val Loss: 200069.5625, Time took: 0.8236169815063477\n",
      "Train loss Meta Info:  [1.41930804e+03 4.50454034e+01 1.78415595e-02]\n",
      "Val Loss Meta Info:  [56793.17, 143275.7, 0.6535810852050781]\n",
      "\n",
      "Epoch: 57, NLL Loss: 1465.1112109375, Val Loss: 279402.84375, Time took: 0.7924680709838867\n",
      "Train loss Meta Info:  [1.41951080e+03 4.55840469e+01 1.63398548e-02]\n",
      "Val Loss Meta Info:  [56790.885, 222611.36, 0.5982995223999024]\n",
      "\n",
      "Epoch: 58, NLL Loss: 1464.52105078125, Val Loss: 269797.15625, Time took: 0.8168134689331055\n",
      "Train loss Meta Info:  [1.41944773e+03 4.50583079e+01 1.49582513e-02]\n",
      "Val Loss Meta Info:  [56788.105, 213008.5, 0.5471891784667968]\n",
      "\n",
      "Epoch: 59, NLL Loss: 1464.59698046875, Val Loss: 241352.0, Time took: 0.8415179252624512\n",
      "Train loss Meta Info:  [1.41935772e+03 4.52255717e+01 1.36807083e-02]\n",
      "Val Loss Meta Info:  [56780.37, 184571.12, 0.4998497009277344]\n",
      "\n",
      "Epoch: 60, NLL Loss: 1464.05356640625, Val Loss: 231801.96875, Time took: 0.813215970993042\n",
      "Train loss Meta Info:  [1.41918097e+03 4.48600948e+01 1.24972318e-02]\n",
      "Val Loss Meta Info:  [56789.925, 175011.56, 0.45698596954345705]\n",
      "\n",
      "Epoch: 61, NLL Loss: 1464.35536328125, Val Loss: 266419.6875, Time took: 0.8447399139404297\n",
      "Train loss Meta Info:  [1.41944450e+03 4.48994538e+01 1.14257246e-02]\n",
      "Val Loss Meta Info:  [56788.94, 209630.34, 0.41866584777832033]\n",
      "\n",
      "Epoch: 62, NLL Loss: 1464.00422265625, Val Loss: 172553.59375, Time took: 0.8190221786499023\n",
      "Train loss Meta Info:  [1.41941018e+03 4.45835565e+01 1.04678876e-02]\n",
      "Val Loss Meta Info:  [56793.075, 115760.15, 0.3838892364501953]\n",
      "\n",
      "Epoch: 63, NLL Loss: 1463.92515234375, Val Loss: 176389.171875, Time took: 0.7849404811859131\n",
      "Train loss Meta Info:  [1.41949021e+03 4.44253970e+01 9.59867522e-03]\n",
      "Val Loss Meta Info:  [56779.49, 119609.35, 0.35263092041015626]\n",
      "\n",
      "Epoch: 64, NLL Loss: 1463.19619140625, Val Loss: 174666.453125, Time took: 0.7848820686340332\n",
      "Train loss Meta Info:  [1.41914654e+03 4.40408890e+01 8.81750582e-03]\n",
      "Val Loss Meta Info:  [56777.085, 117889.06, 0.32424339294433596]\n",
      "\n",
      "Epoch: 65, NLL Loss: 1463.12728125, Val Loss: 170158.15625, Time took: 0.7821395397186279\n",
      "Train loss Meta Info:  [1.41910868e+03 4.40104781e+01 8.10813361e-03]\n",
      "Val Loss Meta Info:  [56788.125, 113369.74, 0.29845247268676756]\n",
      "\n",
      "Epoch: 66, NLL Loss: 1463.65335546875, Val Loss: 170736.734375, Time took: 0.791496753692627\n",
      "Train loss Meta Info:  [1.41936011e+03 4.42857374e+01 7.46372525e-03]\n",
      "Val Loss Meta Info:  [56783.34, 113953.13, 0.2751591682434082]\n",
      "\n",
      "Epoch: 67, NLL Loss: 1463.253671875, Val Loss: 172244.21875, Time took: 0.7915029525756836\n",
      "Train loss Meta Info:  [1.41921950e+03 4.40272971e+01 6.88180511e-03]\n",
      "Val Loss Meta Info:  [56781.645, 115462.31, 0.2541900444030762]\n",
      "\n",
      "Epoch: 68, NLL Loss: 1463.45880859375, Val Loss: 161665.859375, Time took: 0.7961914539337158\n",
      "Train loss Meta Info:  [1.41919367e+03 4.42587067e+01 6.35795096e-03]\n",
      "Val Loss Meta Info:  [56773.96, 104891.69, 0.23536979675292968]\n",
      "\n",
      "Epoch: 69, NLL Loss: 1463.14576171875, Val Loss: 157104.375, Time took: 0.7897682189941406\n",
      "Train loss Meta Info:  [1.41898293e+03 4.41568893e+01 5.88769203e-03]\n",
      "Val Loss Meta Info:  [56776.695, 100327.46, 0.21837417602539064]\n",
      "\n",
      "Epoch: 70, NLL Loss: 1463.2621484375, Val Loss: 165198.453125, Time took: 0.7906780242919922\n",
      "Train loss Meta Info:  [1.41905795e+03 4.41987172e+01 5.46303056e-03]\n",
      "Val Loss Meta Info:  [56774.125, 108424.13, 0.20289846420288085]\n",
      "\n",
      "Epoch: 71, NLL Loss: 1462.864671875, Val Loss: 166994.953125, Time took: 0.7893991470336914\n",
      "Train loss Meta Info:  [1.41901233e+03 4.38472937e+01 5.07634714e-03]\n",
      "Val Loss Meta Info:  [56770.675, 110224.08, 0.18902767181396485]\n",
      "\n",
      "Epoch: 72, NLL Loss: 1463.11060546875, Val Loss: 156879.109375, Time took: 0.7851574420928955\n",
      "Train loss Meta Info:  [1.41891575e+03 4.41901259e+01 4.72972475e-03]\n",
      "Val Loss Meta Info:  [56770.57, 100108.36, 0.1766748046875]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, NLL Loss: 1462.6758125, Val Loss: 151667.25, Time took: 0.7836148738861084\n",
      "Train loss Meta Info:  [1.41889889e+03 4.37725499e+01 4.42096000e-03]\n",
      "Val Loss Meta Info:  [56774.05, 94893.01, 0.1654181671142578]\n",
      "\n",
      "Epoch: 74, NLL Loss: 1462.94342578125, Val Loss: 171977.875, Time took: 0.8017199039459229\n",
      "Train loss Meta Info:  [1.41897706e+03 4.39622522e+01 4.13953975e-03]\n",
      "Val Loss Meta Info:  [56768.995, 115208.74, 0.15500106811523437]\n",
      "\n",
      "Epoch: 75, NLL Loss: 1462.580546875, Val Loss: 164839.5625, Time took: 0.8095505237579346\n",
      "Train loss Meta Info:  [1.41883827e+03 4.37383844e+01 3.87902986e-03]\n",
      "Val Loss Meta Info:  [56772.385, 108067.03, 0.14542343139648437]\n",
      "\n",
      "Epoch: 76, NLL Loss: 1462.69693359375, Val Loss: 139525.171875, Time took: 0.8025224208831787\n",
      "Train loss Meta Info:  [1.41891356e+03 4.37798141e+01 3.63939515e-03]\n",
      "Val Loss Meta Info:  [56767.475, 82757.56, 0.13668516159057617]\n",
      "\n",
      "Epoch: 77, NLL Loss: 1462.35306640625, Val Loss: 135727.609375, Time took: 0.8195743560791016\n",
      "Train loss Meta Info:  [1.41880644e+03 4.35431842e+01 3.42067941e-03]\n",
      "Val Loss Meta Info:  [56768.78, 78958.705, 0.12861039161682128]\n",
      "\n",
      "Epoch: 78, NLL Loss: 1462.40112109375, Val Loss: 134898.359375, Time took: 0.835230827331543\n",
      "Train loss Meta Info:  [1.41883392e+03 4.35639197e+01 3.21855401e-03]\n",
      "Val Loss Meta Info:  [56765.15, 78133.095, 0.1210871124267578]\n",
      "\n",
      "Epoch: 79, NLL Loss: 1462.18312109375, Val Loss: 131712.609375, Time took: 0.8329665660858154\n",
      "Train loss Meta Info:  [1.41874577e+03 4.34343682e+01 3.03027228e-03]\n",
      "Val Loss Meta Info:  [56766.315, 74946.19, 0.1141697883605957]\n",
      "\n",
      "Epoch: 80, NLL Loss: 1462.1401015625, Val Loss: 130104.5390625, Time took: 0.8448817729949951\n",
      "Train loss Meta Info:  [1.41875331e+03 4.33839706e+01 2.85717630e-03]\n",
      "Val Loss Meta Info:  [56765.73, 73338.695, 0.10772427558898925]\n",
      "\n",
      "Epoch: 81, NLL Loss: 1462.16492578125, Val Loss: 125355.375, Time took: 0.8362765312194824\n",
      "Train loss Meta Info:  [1.41874251e+03 4.34197501e+01 2.69587204e-03]\n",
      "Val Loss Meta Info:  [56764.73, 68590.56, 0.10166862487792969]\n",
      "\n",
      "Epoch: 82, NLL Loss: 1462.11700390625, Val Loss: 121125.4296875, Time took: 0.8432540893554688\n",
      "Train loss Meta Info:  [1.41872019e+03 4.33943242e+01 2.54432128e-03]\n",
      "Val Loss Meta Info:  [56765.235, 64360.1, 0.09600288391113282]\n",
      "\n",
      "Epoch: 83, NLL Loss: 1462.0726875, Val Loss: 120932.375, Time took: 0.8303842544555664\n",
      "Train loss Meta Info:  [1.41871885e+03 4.33515123e+01 2.40255205e-03]\n",
      "Val Loss Meta Info:  [56764.31, 64167.975, 0.09067310333251953]\n",
      "\n",
      "Epoch: 84, NLL Loss: 1461.93869921875, Val Loss: 118469.6484375, Time took: 0.8339381217956543\n",
      "Train loss Meta Info:  [1.41868338e+03 4.32530595e+01 2.26922275e-03]\n",
      "Val Loss Meta Info:  [56765.31, 61704.245, 0.08565895080566406]\n",
      "\n",
      "Epoch: 85, NLL Loss: 1461.87992578125, Val Loss: 116576.796875, Time took: 0.8608589172363281\n",
      "Train loss Meta Info:  [1.41871101e+03 4.31666998e+01 2.14382686e-03]\n",
      "Val Loss Meta Info:  [56763.675, 59813.04, 0.08092941284179687]\n",
      "\n",
      "Epoch: 86, NLL Loss: 1461.8574140625, Val Loss: 116740.0390625, Time took: 0.8146729469299316\n",
      "Train loss Meta Info:  [1.41865743e+03 4.31979711e+01 2.02558696e-03]\n",
      "Val Loss Meta Info:  [56764.05, 59975.91, 0.0765103530883789]\n",
      "\n",
      "Epoch: 87, NLL Loss: 1461.88132421875, Val Loss: 113408.4609375, Time took: 0.8281004428863525\n",
      "Train loss Meta Info:  [1.41868204e+03 4.31974329e+01 1.91515864e-03]\n",
      "Val Loss Meta Info:  [56763.38, 56645.015, 0.0723002815246582]\n",
      "\n",
      "Epoch: 88, NLL Loss: 1461.79897265625, Val Loss: 113757.0703125, Time took: 0.8363072872161865\n",
      "Train loss Meta Info:  [1.41866309e+03 4.31340144e+01 1.80997558e-03]\n",
      "Val Loss Meta Info:  [56762.51, 56994.51, 0.06834507942199707]\n",
      "\n",
      "Epoch: 89, NLL Loss: 1461.71691796875, Val Loss: 112814.0, Time took: 0.853949785232544\n",
      "Train loss Meta Info:  [1.41863973e+03 4.30755252e+01 1.71114096e-03]\n",
      "Val Loss Meta Info:  [56763.24, 56050.7, 0.06459516048431396]\n",
      "\n",
      "Epoch: 90, NLL Loss: 1461.7044375, Val Loss: 108819.0859375, Time took: 0.8259477615356445\n",
      "Train loss Meta Info:  [1.41865570e+03 4.30471473e+01 1.61735988e-03]\n",
      "Val Loss Meta Info:  [56762.385, 52056.64, 0.06102606773376465]\n",
      "\n",
      "Epoch: 91, NLL Loss: 1461.644609375, Val Loss: 109915.234375, Time took: 0.8241560459136963\n",
      "Train loss Meta Info:  [1.41862871e+03 4.30143469e+01 1.52801797e-03]\n",
      "Val Loss Meta Info:  [56762.2, 53152.98, 0.05768857479095459]\n",
      "\n",
      "Epoch: 92, NLL Loss: 1461.63784765625, Val Loss: 106822.7265625, Time took: 0.8297996520996094\n",
      "Train loss Meta Info:  [1.41862909e+03 4.30073854e+01 1.44443124e-03]\n",
      "Val Loss Meta Info:  [56762.21, 50060.48, 0.05451704978942871]\n",
      "\n",
      "Epoch: 93, NLL Loss: 1461.60560546875, Val Loss: 107215.84375, Time took: 0.8321030139923096\n",
      "Train loss Meta Info:  [1.41862009e+03 4.29841049e+01 1.36497729e-03]\n",
      "Val Loss Meta Info:  [56763.09, 50452.705, 0.05153693675994873]\n",
      "\n",
      "Epoch: 94, NLL Loss: 1461.58291015625, Val Loss: 104347.4609375, Time took: 0.834047794342041\n",
      "Train loss Meta Info:  [1.41862971e+03 4.29519382e+01 1.29031009e-03]\n",
      "Val Loss Meta Info:  [56761.78, 47585.62, 0.048725371360778806]\n",
      "\n",
      "Epoch: 95, NLL Loss: 1461.58841015625, Val Loss: 105126.0859375, Time took: 0.8366312980651855\n",
      "Train loss Meta Info:  [1.41860304e+03 4.29841348e+01 1.21984540e-03]\n",
      "Val Loss Meta Info:  [56761.435, 48364.615, 0.0460775089263916]\n",
      "\n",
      "Epoch: 96, NLL Loss: 1461.5482578125, Val Loss: 102476.046875, Time took: 0.8374452590942383\n",
      "Train loss Meta Info:  [1.41859573e+03 4.29514092e+01 1.15351839e-03]\n",
      "Val Loss Meta Info:  [56761.77, 45714.24, 0.04357597351074219]\n",
      "\n",
      "Epoch: 97, NLL Loss: 1461.62457421875, Val Loss: 106542.8671875, Time took: 0.8578159809112549\n",
      "Train loss Meta Info:  [1.41860970e+03 4.30137811e+01 1.09087785e-03]\n",
      "Val Loss Meta Info:  [56761.755, 49781.08, 0.04122496604919434]\n",
      "\n",
      "Epoch: 98, NLL Loss: 1461.57530859375, Val Loss: 101807.0546875, Time took: 0.8313932418823242\n",
      "Train loss Meta Info:  [1.41860182e+03 4.29723809e+01 1.03214471e-03]\n",
      "Val Loss Meta Info:  [56761.68, 45045.34, 0.03899370431900025]\n",
      "\n",
      "Epoch: 99, NLL Loss: 1461.52394140625, Val Loss: 104739.640625, Time took: 0.8411531448364258\n",
      "Train loss Meta Info:  [1.41859294e+03 4.29300723e+01 9.76429334e-04]\n",
      "Val Loss Meta Info:  [56762.19, 47977.405, 0.03691556930541992]\n",
      "\n",
      "Epoch: 100, NLL Loss: 1461.3776484375, Val Loss: 106293.4296875, Time took: 0.8198838233947754\n",
      "Train loss Meta Info:  [1.41859294e+03 4.27837650e+01 9.24663853e-04]\n",
      "Val Loss Meta Info:  [56762.1, 49531.31, 0.03496350049972534]\n",
      "\n",
      "Epoch: 101, NLL Loss: 1461.38252734375, Val Loss: 100572.109375, Time took: 0.8388910293579102\n",
      "Train loss Meta Info:  [1.41858421e+03 4.27973972e+01 8.76108222e-04]\n",
      "Val Loss Meta Info:  [56762.68, 43809.395, 0.0331231689453125]\n",
      "\n",
      "Epoch: 102, NLL Loss: 1461.4815546875, Val Loss: 104877.796875, Time took: 0.8001296520233154\n",
      "Train loss Meta Info:  [1.41860382e+03 4.28769587e+01 8.30363519e-04]\n",
      "Val Loss Meta Info:  [56762.535, 48115.235, 0.03140942573547363]\n",
      "\n",
      "Epoch: 103, NLL Loss: 1461.38788671875, Val Loss: 98492.3046875, Time took: 0.8244774341583252\n",
      "Train loss Meta Info:  [1.41858963e+03 4.27974737e+01 7.87857473e-04]\n",
      "Val Loss Meta Info:  [56761.765, 41730.5175, 0.029773621559143065]\n",
      "\n",
      "Epoch: 104, NLL Loss: 1461.2857890625, Val Loss: 101082.1796875, Time took: 0.7984795570373535\n",
      "Train loss Meta Info:  [1.41857721e+03 4.27077932e+01 7.47172656e-04]\n",
      "Val Loss Meta Info:  [56762.0, 44320.15, 0.028220286369323732]\n",
      "\n",
      "Epoch: 105, NLL Loss: 1461.1711171875, Val Loss: 100385.5859375, Time took: 0.8178448677062988\n",
      "Train loss Meta Info:  [1.41858138e+03 4.25890503e+01 7.08484193e-04]\n",
      "Val Loss Meta Info:  [56761.695, 43623.865, 0.026735687255859376]\n",
      "\n",
      "Epoch: 106, NLL Loss: 1461.10128515625, Val Loss: 97297.390625, Time took: 0.8284397125244141\n",
      "Train loss Meta Info:  [1.41857539e+03 4.25252736e+01 6.71370890e-04]\n",
      "Val Loss Meta Info:  [56761.95, 40535.41, 0.025332951545715333]\n",
      "\n",
      "Epoch: 107, NLL Loss: 1461.12555859375, Val Loss: 107282.109375, Time took: 0.8258168697357178\n",
      "Train loss Meta Info:  [1.41858378e+03 4.25411387e+01 6.36180822e-04]\n",
      "Val Loss Meta Info:  [56763.075, 50519.02, 0.02398360013961792]\n",
      "\n",
      "Epoch: 108, NLL Loss: 1461.428328125, Val Loss: 90186.234375, Time took: 0.797950267791748\n",
      "Train loss Meta Info:  [1.41859672e+03 4.28309916e+01 6.02329466e-04]\n",
      "Val Loss Meta Info:  [56763.96, 33422.2625, 0.022726287841796877]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109, NLL Loss: 1462.52032421875, Val Loss: 113844.515625, Time took: 0.8265259265899658\n",
      "Train loss Meta Info:  [1.41863086e+03 4.38888154e+01 5.70653412e-04]\n",
      "Val Loss Meta Info:  [56766.93, 57077.56, 0.02152087688446045]\n",
      "\n",
      "Epoch: 110, NLL Loss: 1462.68553515625, Val Loss: 98876.3359375, Time took: 0.8267881870269775\n",
      "Train loss Meta Info:  [1.41869123e+03 4.39938277e+01 5.40515340e-04]\n",
      "Val Loss Meta Info:  [56763.47, 42112.845, 0.020397939682006837]\n",
      "\n",
      "Epoch: 111, NLL Loss: 1462.720203125, Val Loss: 108804.890625, Time took: 0.7865138053894043\n",
      "Train loss Meta Info:  [1.41861566e+03 4.41040575e+01 5.12210951e-04]\n",
      "Val Loss Meta Info:  [56761.98, 52042.89, 0.019310375452041628]\n",
      "\n",
      "Epoch: 112, NLL Loss: 1461.52734375, Val Loss: 127624.4375, Time took: 0.7904365062713623\n",
      "Train loss Meta Info:  [1.41857416e+03 4.29526973e+01 4.85025334e-04]\n",
      "Val Loss Meta Info:  [56764.8, 70859.625, 0.018296420574188232]\n",
      "\n",
      "Epoch: 113, NLL Loss: 1464.18470703125, Val Loss: 104005.890625, Time took: 0.8037028312683105\n",
      "Train loss Meta Info:  [1.41864327e+03 4.55409573e+01 4.59828136e-04]\n",
      "Val Loss Meta Info:  [56768.63, 47237.235, 0.01728017449378967]\n",
      "\n",
      "Epoch: 114, NLL Loss: 1464.34471875, Val Loss: 111200.03125, Time took: 0.8219118118286133\n",
      "Train loss Meta Info:  [1.41874827e+03 4.55959761e+01 4.34123745e-04]\n",
      "Val Loss Meta Info:  [56762.0, 54438.005, 0.016369421482086182]\n",
      "\n",
      "Epoch: 115, NLL Loss: 1462.67005859375, Val Loss: 145438.796875, Time took: 0.8100926876068115\n",
      "Train loss Meta Info:  [1.41857846e+03 4.40911566e+01 4.11530138e-04]\n",
      "Val Loss Meta Info:  [56776.745, 88662.04, 0.015555531978607177]\n",
      "\n",
      "Epoch: 116, NLL Loss: 1463.86109765625, Val Loss: 136981.453125, Time took: 0.7812654972076416\n",
      "Train loss Meta Info:  [1.41893651e+03 4.49242264e+01 3.91650459e-04]\n",
      "Val Loss Meta Info:  [56763.68, 80217.79, 0.01472588062286377]\n",
      "\n",
      "Epoch: 117, NLL Loss: 1462.00073828125, Val Loss: 120695.8359375, Time took: 0.7803597450256348\n",
      "Train loss Meta Info:  [1.41862257e+03 4.33778721e+01 3.70932399e-04]\n",
      "Val Loss Meta Info:  [56781.575, 63914.265, 0.013926464319229125]\n",
      "\n",
      "Epoch: 118, NLL Loss: 1463.0653125, Val Loss: 123253.7109375, Time took: 0.7801744937896729\n",
      "Train loss Meta Info:  [1.41907081e+03 4.39941984e+01 3.51014611e-04]\n",
      "Val Loss Meta Info:  [56764.585, 66489.105, 0.01319720983505249]\n",
      "\n",
      "Epoch: 119, NLL Loss: 1462.164765625, Val Loss: 144429.609375, Time took: 0.793736457824707\n",
      "Train loss Meta Info:  [1.41862606e+03 4.35384110e+01 3.33285492e-04]\n",
      "Val Loss Meta Info:  [56787.79, 87641.83, 0.01254143238067627]\n",
      "\n",
      "Epoch: 120, NLL Loss: 1462.51273828125, Val Loss: 143553.171875, Time took: 0.8192319869995117\n",
      "Train loss Meta Info:  [1.41920771e+03 4.33047175e+01 3.17487506e-04]\n",
      "Val Loss Meta Info:  [56764.64, 86788.52, 0.011926779747009278]\n",
      "\n",
      "Epoch: 121, NLL Loss: 1461.92957421875, Val Loss: 125515.1953125, Time took: 0.8058924674987793\n",
      "Train loss Meta Info:  [1.41864258e+03 4.32866932e+01 3.02347837e-04]\n",
      "Val Loss Meta Info:  [56788.84, 68726.35, 0.011345341205596923]\n",
      "\n",
      "Epoch: 122, NLL Loss: 1462.31365625, Val Loss: 122248.234375, Time took: 0.8172116279602051\n",
      "Train loss Meta Info:  [1.41925567e+03 4.30576766e+01 2.87877765e-04]\n",
      "Val Loss Meta Info:  [56766.18, 65482.035, 0.010773735046386719]\n",
      "\n",
      "Epoch: 123, NLL Loss: 1461.7538359375, Val Loss: 134401.734375, Time took: 0.824429988861084\n",
      "Train loss Meta Info:  [1.41867438e+03 4.30791693e+01 2.73905232e-04]\n",
      "Val Loss Meta Info:  [56786.57, 77615.18, 0.010194250345230103]\n",
      "\n",
      "Epoch: 124, NLL Loss: 1462.1123359375, Val Loss: 127663.875, Time took: 0.8248138427734375\n",
      "Train loss Meta Info:  [1.41915911e+03 4.29529171e+01 2.59766094e-04]\n",
      "Val Loss Meta Info:  [56767.42, 70896.44, 0.009647864699363708]\n",
      "\n",
      "Epoch: 125, NLL Loss: 1461.5618046875, Val Loss: 117703.9609375, Time took: 0.8153080940246582\n",
      "Train loss Meta Info:  [1.41868475e+03 4.28767139e+01 2.46018550e-04]\n",
      "Val Loss Meta Info:  [56778.255, 60925.695, 0.00915367305278778]\n",
      "\n",
      "Epoch: 126, NLL Loss: 1461.89761328125, Val Loss: 119463.2109375, Time took: 0.8442656993865967\n",
      "Train loss Meta Info:  [1.41897414e+03 4.29232917e+01 2.33439559e-04]\n",
      "Val Loss Meta Info:  [56768.235, 62694.965, 0.008670324683189392]\n",
      "\n",
      "Epoch: 127, NLL Loss: 1461.50193359375, Val Loss: 125875.0859375, Time took: 0.8387002944946289\n",
      "Train loss Meta Info:  [1.41871339e+03 4.27883626e+01 2.21460089e-04]\n",
      "Val Loss Meta Info:  [56771.97, 69103.09, 0.00823872685432434]\n",
      "\n",
      "Epoch: 128, NLL Loss: 1461.65403515625, Val Loss: 119679.734375, Time took: 0.8419013023376465\n",
      "Train loss Meta Info:  [1.41878083e+03 4.28730635e+01 2.11035256e-04]\n",
      "Val Loss Meta Info:  [56769.55, 62910.155, 0.007826855778694153]\n",
      "\n",
      "Epoch: 129, NLL Loss: 1461.355046875, Val Loss: 110152.296875, Time took: 0.8179435729980469\n",
      "Train loss Meta Info:  [1.41870363e+03 4.26512515e+01 2.01007328e-04]\n",
      "Val Loss Meta Info:  [56766.585, 53385.705, 0.007417775392532348]\n",
      "\n",
      "Epoch: 130, NLL Loss: 1461.43169921875, Val Loss: 121725.9296875, Time took: 0.7886173725128174\n",
      "Train loss Meta Info:  [1.41864275e+03 4.27887713e+01 1.91040534e-04]\n",
      "Val Loss Meta Info:  [56769.6, 64956.315, 0.007053873538970947]\n",
      "\n",
      "Epoch: 131, NLL Loss: 1461.28145703125, Val Loss: 126073.734375, Time took: 0.8005344867706299\n",
      "Train loss Meta Info:  [1.41871793e+03 4.25633533e+01 1.82418992e-04]\n",
      "Val Loss Meta Info:  [56764.44, 69309.3, 0.006726016402244568]\n",
      "\n",
      "Epoch: 132, NLL Loss: 1461.238796875, Val Loss: 116708.0078125, Time took: 0.8088352680206299\n",
      "Train loss Meta Info:  [1.41858419e+03 4.26544313e+01 1.74690153e-04]\n",
      "Val Loss Meta Info:  [56768.965, 59939.045, 0.006391539573669434]\n",
      "\n",
      "Epoch: 133, NLL Loss: 1461.1811953125, Val Loss: 116208.5703125, Time took: 0.8009505271911621\n",
      "Train loss Meta Info:  [1.41867815e+03 4.25028739e+01 1.66461091e-04]\n",
      "Val Loss Meta Info:  [56765.65, 59442.91, 0.0060642421245574955]\n",
      "\n",
      "Epoch: 134, NLL Loss: 1461.0571796875, Val Loss: 125897.65625, Time took: 0.789189338684082\n",
      "Train loss Meta Info:  [1.41859200e+03 4.24650022e+01 1.58155049e-04]\n",
      "Val Loss Meta Info:  [56767.19, 69130.45, 0.005744587182998657]\n",
      "\n",
      "Epoch: 135, NLL Loss: 1461.147328125, Val Loss: 115642.9375, Time took: 0.8039810657501221\n",
      "Train loss Meta Info:  [1.41863268e+03 4.25145025e+01 1.49925574e-04]\n",
      "Val Loss Meta Info:  [56766.03, 58876.9, 0.005431591272354126]\n",
      "\n",
      "Epoch: 136, NLL Loss: 1460.97710546875, Val Loss: 113450.25, Time took: 0.7865259647369385\n",
      "Train loss Meta Info:  [1.41860253e+03 4.23744360e+01 1.41792018e-04]\n",
      "Val Loss Meta Info:  [56765.82, 56684.435, 0.005135545134544372]\n",
      "\n",
      "Epoch: 137, NLL Loss: 1460.93578125, Val Loss: 129613.0234375, Time took: 0.7846508026123047\n",
      "Train loss Meta Info:  [1.41858973e+03 4.23458655e+01 1.34071450e-04]\n",
      "Val Loss Meta Info:  [56765.545, 72847.485, 0.004854265451431274]\n",
      "\n",
      "Epoch: 138, NLL Loss: 1460.98858203125, Val Loss: 104066.71875, Time took: 0.7831053733825684\n",
      "Train loss Meta Info:  [1.41856571e+03 4.24227151e+01 1.26702272e-04]\n",
      "Val Loss Meta Info:  [56765.73, 47300.965, 0.00460476666688919]\n",
      "\n",
      "Epoch: 139, NLL Loss: 1460.97460546875, Val Loss: 114611.5859375, Time took: 0.7948997020721436\n",
      "Train loss Meta Info:  [1.41858404e+03 4.23904219e+01 1.20129449e-04]\n",
      "Val Loss Meta Info:  [56763.125, 57848.465, 0.0043730628490448]\n",
      "\n",
      "Epoch: 140, NLL Loss: 1460.74467578125, Val Loss: 114432.0390625, Time took: 0.8007004261016846\n",
      "Train loss Meta Info:  [1.41851572e+03 4.22288015e+01 1.14172355e-04]\n",
      "Val Loss Meta Info:  [56766.84, 57665.18, 0.00416610449552536]\n",
      "\n",
      "Epoch: 141, NLL Loss: 1460.78471875, Val Loss: 98887.3984375, Time took: 0.8171331882476807\n",
      "Train loss Meta Info:  [1.41859844e+03 4.21861068e+01 1.08922753e-04]\n",
      "Val Loss Meta Info:  [56762.645, 42124.76, 0.003983646333217621]\n",
      "\n",
      "Epoch: 142, NLL Loss: 1460.787046875, Val Loss: 128282.2109375, Time took: 0.8131499290466309\n",
      "Train loss Meta Info:  [1.41849848e+03 4.22883964e+01 1.04353301e-04]\n",
      "Val Loss Meta Info:  [56766.5, 71515.725, 0.0038156002759933473]\n",
      "\n",
      "Epoch: 143, NLL Loss: 1461.105671875, Val Loss: 91726.8984375, Time took: 0.821225643157959\n",
      "Train loss Meta Info:  [1.41857203e+03 4.25334536e+01 1.00341894e-04]\n",
      "Val Loss Meta Info:  [56763.64, 34963.265, 0.0036520513892173766]\n",
      "\n",
      "Epoch: 144, NLL Loss: 1461.6177265625, Val Loss: 128913.015625, Time took: 0.8155620098114014\n",
      "Train loss Meta Info:  [1.41851082e+03 4.31067693e+01 9.61961516e-05]\n",
      "Val Loss Meta Info:  [56764.63, 72148.4, 0.00350678950548172]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, NLL Loss: 1461.4047421875, Val Loss: 91369.0, Time took: 0.8151271343231201\n",
      "Train loss Meta Info:  [1.41851662e+03 4.28880074e+01 9.27737650e-05]\n",
      "Val Loss Meta Info:  [56764.09, 34604.905, 0.0033290630578994753]\n",
      "\n",
      "Epoch: 146, NLL Loss: 1461.3312265625, Val Loss: 111276.2578125, Time took: 0.8181271553039551\n",
      "Train loss Meta Info:  [1.41852264e+03 4.28085059e+01 8.79193179e-05]\n",
      "Val Loss Meta Info:  [56763.08, 54513.18, 0.0031751957535743713]\n",
      "\n",
      "Epoch: 147, NLL Loss: 1460.66658203125, Val Loss: 109094.140625, Time took: 0.8416290283203125\n",
      "Train loss Meta Info:  [1.41847478e+03 4.21917319e+01 8.38501276e-05]\n",
      "Val Loss Meta Info:  [56764.61, 52329.535, 0.003019447922706604]\n",
      "\n",
      "Epoch: 148, NLL Loss: 1460.6030703125, Val Loss: 92733.328125, Time took: 0.8080394268035889\n",
      "Train loss Meta Info:  [1.41850906e+03 4.20939410e+01 7.95103858e-05]\n",
      "Val Loss Meta Info:  [56762.94, 35970.385, 0.0028577205538749696]\n",
      "\n",
      "Epoch: 149, NLL Loss: 1460.91134765625, Val Loss: 124015.25, Time took: 0.8218348026275635\n",
      "Train loss Meta Info:  [1.41847406e+03 4.24372446e+01 7.49364735e-05]\n",
      "Val Loss Meta Info:  [56763.44, 67251.815, 0.002726273536682129]\n",
      "\n",
      "Epoch: 150, NLL Loss: 1461.02625, Val Loss: 99154.28125, Time took: 0.8154633045196533\n",
      "Train loss Meta Info:  [1.41848093e+03 4.25452625e+01 7.13720656e-05]\n",
      "Val Loss Meta Info:  [56763.4, 42390.87, 0.0025748246908187866]\n",
      "\n",
      "Epoch: 151, NLL Loss: 1460.7729296875, Val Loss: 110512.4765625, Time took: 0.8136053085327148\n",
      "Train loss Meta Info:  [1.41848159e+03 4.22913511e+01 6.71698814e-05]\n",
      "Val Loss Meta Info:  [56762.54, 53749.94, 0.002451246380805969]\n",
      "\n",
      "Epoch: 152, NLL Loss: 1460.46531640625, Val Loss: 115825.359375, Time took: 0.8028748035430908\n",
      "Train loss Meta Info:  [1.41845214e+03 4.20131480e+01 6.38794666e-05]\n",
      "Val Loss Meta Info:  [56763.67, 59061.69, 0.002328890860080719]\n",
      "\n",
      "Epoch: 153, NLL Loss: 1460.63876171875, Val Loss: 96451.3359375, Time took: 0.8175208568572998\n",
      "Train loss Meta Info:  [1.41847000e+03 4.21687104e+01 6.07321355e-05]\n",
      "Val Loss Meta Info:  [56762.76, 39688.58, 0.002207351326942444]\n",
      "\n",
      "Epoch: 154, NLL Loss: 1460.81361328125, Val Loss: 121402.7109375, Time took: 0.8014023303985596\n",
      "Train loss Meta Info:  [1.41845017e+03 4.23634199e+01 5.76702070e-05]\n",
      "Val Loss Meta Info:  [56762.695, 64640.015, 0.0020647788047790526]\n",
      "\n",
      "Epoch: 155, NLL Loss: 1460.64577734375, Val Loss: 105852.46875, Time took: 0.7971177101135254\n",
      "Train loss Meta Info:  [1.41844539e+03 4.22004037e+01 5.43026138e-05]\n",
      "Val Loss Meta Info:  [56762.18, 49090.28, 0.0019584682583808897]\n",
      "\n",
      "Epoch: 156, NLL Loss: 1460.42471484375, Val Loss: 102744.5, Time took: 0.803396463394165\n",
      "Train loss Meta Info:  [1.41844659e+03 4.19781294e+01 5.15458120e-05]\n",
      "Val Loss Meta Info:  [56762.37, 45982.135, 0.0018553538620471955]\n",
      "\n",
      "Epoch: 157, NLL Loss: 1460.43599609375, Val Loss: 120549.328125, Time took: 0.7988040447235107\n",
      "Train loss Meta Info:  [1.41842916e+03 4.20068367e+01 4.89652889e-05]\n",
      "Val Loss Meta Info:  [56763.39, 63785.955, 0.0017554590106010437]\n",
      "\n",
      "Epoch: 158, NLL Loss: 1460.59615234375, Val Loss: 90348.109375, Time took: 0.8110668659210205\n",
      "Train loss Meta Info:  [1.41843943e+03 4.21566990e+01 4.66393666e-05]\n",
      "Val Loss Meta Info:  [56762.29, 33585.81, 0.0016701819002628326]\n",
      "\n",
      "Epoch: 159, NLL Loss: 1460.60788671875, Val Loss: 114517.59375, Time took: 0.810056209564209\n",
      "Train loss Meta Info:  [1.41842360e+03 4.21842752e+01 4.45274164e-05]\n",
      "Val Loss Meta Info:  [56762.595, 57755.015, 0.0015861596167087554]\n",
      "\n",
      "Epoch: 160, NLL Loss: 1460.49153125, Val Loss: 95034.0703125, Time took: 0.8046727180480957\n",
      "Train loss Meta Info:  [1.41841850e+03 4.20730314e+01 4.26783125e-05]\n",
      "Val Loss Meta Info:  [56762.765, 38271.3, 0.0015078695118427277]\n",
      "\n",
      "Epoch: 161, NLL Loss: 1460.34913671875, Val Loss: 99245.359375, Time took: 0.8291430473327637\n",
      "Train loss Meta Info:  [1.41842326e+03 4.19258817e+01 4.07109126e-05]\n",
      "Val Loss Meta Info:  [56762.685, 42482.675, 0.0014358599483966826]\n",
      "\n",
      "Epoch: 162, NLL Loss: 1460.253265625, Val Loss: 97757.6171875, Time took: 0.8243165016174316\n",
      "Train loss Meta Info:  [1.41841017e+03 4.18430896e+01 3.89047709e-05]\n",
      "Val Loss Meta Info:  [56762.9, 40994.7175, 0.0013668344914913178]\n",
      "\n",
      "Epoch: 163, NLL Loss: 1460.2722578125, Val Loss: 87843.75, Time took: 0.8113021850585938\n",
      "Train loss Meta Info:  [1.41841938e+03 4.18528827e+01 3.70737080e-05]\n",
      "Val Loss Meta Info:  [56762.41, 31081.3425, 0.0012973441183567046]\n",
      "\n",
      "Epoch: 164, NLL Loss: 1460.36572265625, Val Loss: 116338.7890625, Time took: 0.7977886199951172\n",
      "Train loss Meta Info:  [1.41840909e+03 4.19566450e+01 3.51242278e-05]\n",
      "Val Loss Meta Info:  [56763.04, 59575.755, 0.0012388215959072114]\n",
      "\n",
      "Epoch: 165, NLL Loss: 1460.60438671875, Val Loss: 82497.8359375, Time took: 0.7889788150787354\n",
      "Train loss Meta Info:  [1.41840464e+03 4.21997465e+01 3.36025149e-05]\n",
      "Val Loss Meta Info:  [56763.25, 25734.575, 0.0011734689772129059]\n",
      "\n",
      "Epoch: 166, NLL Loss: 1461.27662109375, Val Loss: 128636.75, Time took: 0.7987933158874512\n",
      "Train loss Meta Info:  [1.41841388e+03 4.28627402e+01 3.16590279e-05]\n",
      "Val Loss Meta Info:  [56763.45, 71873.3, 0.0011275798082351685]\n",
      "\n",
      "Epoch: 167, NLL Loss: 1461.69301953125, Val Loss: 86720.1015625, Time took: 0.7982745170593262\n",
      "Train loss Meta Info:  [1.41841100e+03 4.32820182e+01 3.05682199e-05]\n",
      "Val Loss Meta Info:  [56762.6, 29957.4975, 0.0010710305720567704]\n",
      "\n",
      "Epoch: 168, NLL Loss: 1461.60443359375, Val Loss: 110795.9765625, Time took: 0.811377763748169\n",
      "Train loss Meta Info:  [1.41839638e+03 4.32080447e+01 2.88161180e-05]\n",
      "Val Loss Meta Info:  [56762.88, 54033.09, 0.001027662307024002]\n",
      "\n",
      "Epoch: 169, NLL Loss: 1460.37875, Val Loss: 113361.140625, Time took: 0.8604636192321777\n",
      "Train loss Meta Info:  [1.41839620e+03 4.19825609e+01 2.77987193e-05]\n",
      "Val Loss Meta Info:  [56763.33, 56597.82, 0.0009921632707118988]\n",
      "\n",
      "Epoch: 170, NLL Loss: 1460.7259296875, Val Loss: 97408.1796875, Time took: 0.8128540515899658\n",
      "Train loss Meta Info:  [1.41839126e+03 4.23346745e+01 2.69785942e-05]\n",
      "Val Loss Meta Info:  [56763.355, 40644.8225, 0.0009628155082464218]\n",
      "\n",
      "Epoch: 171, NLL Loss: 1460.9997890625, Val Loss: 103501.21875, Time took: 0.7959456443786621\n",
      "Train loss Meta Info:  [1.41839129e+03 4.26084638e+01 2.62104975e-05]\n",
      "Val Loss Meta Info:  [56762.99, 46738.215, 0.0009376154839992523]\n",
      "\n",
      "Epoch: 172, NLL Loss: 1460.3810078125, Val Loss: 115724.046875, Time took: 0.794041633605957\n",
      "Train loss Meta Info:  [1.41837616e+03 4.20048359e+01 2.57210846e-05]\n",
      "Val Loss Meta Info:  [56764.21, 58959.85, 0.0009093227237462997]\n",
      "\n",
      "Epoch: 173, NLL Loss: 1461.05261328125, Val Loss: 98056.7265625, Time took: 0.7982327938079834\n",
      "Train loss Meta Info:  [1.41839964e+03 4.26529694e+01 2.51489824e-05]\n",
      "Val Loss Meta Info:  [56763.455, 41293.27, 0.0008836568892002106]\n",
      "\n",
      "Epoch: 174, NLL Loss: 1460.58222265625, Val Loss: 98868.25, Time took: 0.7961876392364502\n",
      "Train loss Meta Info:  [1.41837825e+03 4.22039374e+01 2.43677554e-05]\n",
      "Val Loss Meta Info:  [56763.27, 42104.985, 0.0008607357740402222]\n",
      "\n",
      "Epoch: 175, NLL Loss: 1460.50776171875, Val Loss: 118449.2109375, Time took: 0.7913126945495605\n",
      "Train loss Meta Info:  [1.41837940e+03 4.21283429e+01 2.38114026e-05]\n",
      "Val Loss Meta Info:  [56763.57, 61685.64, 0.0008446703851222992]\n",
      "\n",
      "Epoch: 176, NLL Loss: 1460.80603515625, Val Loss: 96736.6171875, Time took: 0.7949936389923096\n",
      "Train loss Meta Info:  [1.41837606e+03 4.24299680e+01 2.35973281e-05]\n",
      "Val Loss Meta Info:  [56763.6, 39973.02, 0.0008382702618837356]\n",
      "\n",
      "Epoch: 177, NLL Loss: 1460.22671484375, Val Loss: 89384.046875, Time took: 0.7905769348144531\n",
      "Train loss Meta Info:  [1.41836548e+03 4.18612344e+01 2.34390852e-05]\n",
      "Val Loss Meta Info:  [56763.39, 32620.66, 0.0008325479924678802]\n",
      "\n",
      "Epoch: 178, NLL Loss: 1460.4321171875, Val Loss: 107744.28125, Time took: 0.7921528816223145\n",
      "Train loss Meta Info:  [1.41836228e+03 4.20698660e+01 2.33725231e-05]\n",
      "Val Loss Meta Info:  [56764.23, 50980.045, 0.0008264786005020142]\n",
      "\n",
      "Epoch: 179, NLL Loss: 1460.6471953125, Val Loss: 87661.859375, Time took: 0.7986485958099365\n",
      "Train loss Meta Info:  [1.41836299e+03 4.22841981e+01 2.33836255e-05]\n",
      "Val Loss Meta Info:  [56764.1, 30897.755, 0.0008118028193712235]\n",
      "\n",
      "Epoch: 180, NLL Loss: 1460.24863671875, Val Loss: 89894.8671875, Time took: 0.7948293685913086\n",
      "Train loss Meta Info:  [1.41835833e+03 4.18902877e+01 2.28819838e-05]\n",
      "Val Loss Meta Info:  [56763.91, 33130.96, 0.0008001868426799774]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181, NLL Loss: 1460.1328828125, Val Loss: 105614.28125, Time took: 0.8182809352874756\n",
      "Train loss Meta Info:  [1.41835580e+03 4.17770632e+01 2.25267973e-05]\n",
      "Val Loss Meta Info:  [56764.64, 48849.66, 0.0007879181206226349]\n",
      "\n",
      "Epoch: 182, NLL Loss: 1460.454734375, Val Loss: 84346.578125, Time took: 0.8206558227539062\n",
      "Train loss Meta Info:  [1.41836198e+03 4.20927329e+01 2.22260865e-05]\n",
      "Val Loss Meta Info:  [56764.27, 27582.305, 0.0007685727626085281]\n",
      "\n",
      "Epoch: 183, NLL Loss: 1460.49633984375, Val Loss: 103949.5546875, Time took: 0.7859094142913818\n",
      "Train loss Meta Info:  [1.41835362e+03 4.21427414e+01 2.16277951e-05]\n",
      "Val Loss Meta Info:  [56764.09, 47185.465, 0.0007667206972837448]\n",
      "\n",
      "Epoch: 184, NLL Loss: 1460.11751953125, Val Loss: 95732.8984375, Time took: 0.787747859954834\n",
      "Train loss Meta Info:  [1.41834431e+03 4.17732163e+01 2.16699491e-05]\n",
      "Val Loss Meta Info:  [56764.13, 38968.76, 0.000762847512960434]\n",
      "\n",
      "Epoch: 185, NLL Loss: 1460.01125, Val Loss: 84505.3203125, Time took: 0.8196208477020264\n",
      "Train loss Meta Info:  [1.41834327e+03 4.16679661e+01 2.15792647e-05]\n",
      "Val Loss Meta Info:  [56764.04, 27741.2675, 0.0007533396780490875]\n",
      "\n",
      "Epoch: 186, NLL Loss: 1460.2718125, Val Loss: 119805.125, Time took: 0.8056836128234863\n",
      "Train loss Meta Info:  [1.41833646e+03 4.19353599e+01 2.12895815e-05]\n",
      "Val Loss Meta Info:  [56764.72, 63040.41, 0.0007629299908876419]\n",
      "\n",
      "Epoch: 187, NLL Loss: 1460.82760546875, Val Loss: 81688.0390625, Time took: 0.8031468391418457\n",
      "Train loss Meta Info:  [1.41834371e+03 4.24838875e+01 2.15787849e-05]\n",
      "Val Loss Meta Info:  [56764.65, 24923.3825, 0.0007335470616817475]\n",
      "\n",
      "Epoch: 188, NLL Loss: 1461.23983203125, Val Loss: 112775.15625, Time took: 0.819056510925293\n",
      "Train loss Meta Info:  [1.41834226e+03 4.28975401e+01 2.06169962e-05]\n",
      "Val Loss Meta Info:  [56765.01, 56010.15, 0.0007465294003486633]\n",
      "\n",
      "Epoch: 189, NLL Loss: 1460.3889921875, Val Loss: 106884.296875, Time took: 0.8126957416534424\n",
      "Train loss Meta Info:  [1.41833929e+03 4.20497092e+01 2.10257425e-05]\n",
      "Val Loss Meta Info:  [56764.945, 50119.345, 0.0007450753450393677]\n",
      "\n",
      "Epoch: 190, NLL Loss: 1460.1181015625, Val Loss: 99273.296875, Time took: 0.8311388492584229\n",
      "Train loss Meta Info:  [1.41833715e+03 4.17809534e+01 2.09474091e-05]\n",
      "Val Loss Meta Info:  [56764.88, 42508.415, 0.0007571837306022644]\n",
      "\n",
      "Epoch: 191, NLL Loss: 1460.5761875, Val Loss: 107090.7578125, Time took: 0.8179736137390137\n",
      "Train loss Meta Info:  [1.41833579e+03 4.22404081e+01 2.11883177e-05]\n",
      "Val Loss Meta Info:  [56764.85, 50325.91, 0.0007815851271152496]\n",
      "\n",
      "Epoch: 192, NLL Loss: 1460.17965625, Val Loss: 105063.875, Time took: 0.8324921131134033\n",
      "Train loss Meta Info:  [1.41832785e+03 4.18518390e+01 2.19594585e-05]\n",
      "Val Loss Meta Info:  [56764.7, 48299.17, 0.0008077540248632431]\n",
      "\n",
      "Epoch: 193, NLL Loss: 1460.125546875, Val Loss: 98998.515625, Time took: 0.8160035610198975\n",
      "Train loss Meta Info:  [1.41832483e+03 4.18007066e+01 2.26408710e-05]\n",
      "Val Loss Meta Info:  [56765.115, 42233.4, 0.0008273199945688247]\n",
      "\n",
      "Epoch: 194, NLL Loss: 1460.40077734375, Val Loss: 108052.1953125, Time took: 0.8250086307525635\n",
      "Train loss Meta Info:  [1.41832305e+03 4.20777311e+01 2.30152022e-05]\n",
      "Val Loss Meta Info:  [56765.525, 51286.67, 0.0008393774926662445]\n",
      "\n",
      "Epoch: 195, NLL Loss: 1460.03946484375, Val Loss: 106275.046875, Time took: 0.7954778671264648\n",
      "Train loss Meta Info:  [1.41832275e+03 4.17167173e+01 2.33942654e-05]\n",
      "Val Loss Meta Info:  [56765.315, 49509.75, 0.000849732756614685]\n",
      "\n",
      "Epoch: 196, NLL Loss: 1459.96308984375, Val Loss: 81363.1171875, Time took: 0.8087203502655029\n",
      "Train loss Meta Info:  [1.41831618e+03 4.16468865e+01 2.36284561e-05]\n",
      "Val Loss Meta Info:  [56765.1, 24598.01, 0.0008730859309434891]\n",
      "\n",
      "Epoch: 197, NLL Loss: 1460.29258203125, Val Loss: 102286.5390625, Time took: 0.8148601055145264\n",
      "Train loss Meta Info:  [1.41831752e+03 4.19750544e+01 2.41366758e-05]\n",
      "Val Loss Meta Info:  [56765.85, 45520.675, 0.0009005376696586609]\n",
      "\n",
      "Epoch: 198, NLL Loss: 1460.352671875, Val Loss: 79478.8125, Time took: 0.8281581401824951\n",
      "Train loss Meta Info:  [1.41831928e+03 4.20334117e+01 2.49939543e-05]\n",
      "Val Loss Meta Info:  [56765.645, 22713.1675, 0.0009162931144237518]\n",
      "\n",
      "Epoch: 199, NLL Loss: 1460.2400546875, Val Loss: 92160.796875, Time took: 0.8079607486724854\n",
      "Train loss Meta Info:  [1.41831297e+03 4.19270845e+01 2.52277787e-05]\n",
      "Val Loss Meta Info:  [56766.125, 35394.6725, 0.0009328173100948333]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=hrmtpp, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
