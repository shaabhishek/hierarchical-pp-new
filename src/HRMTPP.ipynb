{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define RMTPP Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMTPP(nn.Module):\n",
    "    def __init__(self, marker_type='real', marker_dim=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.marker_dim = marker_dim\n",
    "        \n",
    "        # Dimensions for embedding inputs\n",
    "        self.marker_embed_dim = 64\n",
    "        self.time_embed_dim = 64\n",
    "        # Networks for embedding inputs\n",
    "        self.create_embedding_nets()\n",
    "        \n",
    "        # This is the layer that encodes the history\n",
    "        self.hidden_layer_dim = 128\n",
    "        # Create RNN layer Network\n",
    "        self.create_rnn()\n",
    "        \n",
    "        # Hidden shared layer size (bw mu and var)\n",
    "        # while generating marker from hidden state\n",
    "        self.marker_shared_dim = 64\n",
    "        # Create Network for Marker generation from hidden_seq\n",
    "        self.create_marker_generation_net()\n",
    "        self.create_time_likelihood_net()\n",
    "\n",
    "    ############ UTILITY METHODS #############\n",
    "        \n",
    "    def _one_hot_marker(self, marker_seq):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "            marker_seq: Tensor of shape TxBSx1\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    ############ NETWORKS #############    \n",
    "    \n",
    "    def create_rnn(self):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "            marker_embed_dim: dimension of embedded markers\n",
    "            time_embed_dim: dimension of embedded times,intervals\n",
    "            hidden_layer_dim: dimension of hidden state of recurrent layer\n",
    "        \"\"\"\n",
    "\n",
    "        ### Vanilla RNN\n",
    "#         self.rnn = nn.RNN(\n",
    "#             input_size=self.marker_embed_dim+self.time_embed_dim,\n",
    "#             hidden_size=self.hidden_layer_dim,\n",
    "#             nonlinearity='relu'\n",
    "#         )\n",
    "        ### GRU\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.marker_embed_dim+self.time_embed_dim,\n",
    "            hidden_size=self.hidden_layer_dim,\n",
    "        )\n",
    "    \n",
    "    def create_embedding_nets(self):\n",
    "        # marker_dim is passed. timeseries_dim is 2\n",
    "        self.marker_embedding_net = nn.Linear(self.marker_dim, self.marker_embed_dim)\n",
    "        \n",
    "        self.time_embedding_net = nn.Sequential(\n",
    "            nn.Linear(2, self.time_embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.time_embed_dim, self.time_embed_dim)\n",
    "        )\n",
    "        \n",
    "    def create_marker_generation_net(self):\n",
    "        \"\"\"\n",
    "            Generate network to create marker sufficient statistics using\n",
    "            rnn's hidden layer\n",
    "        \"\"\"\n",
    "        self.marker_gen_hidden = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim, self.marker_shared_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.generated_marker_mu = nn.Linear(self.marker_shared_dim, self.marker_dim)\n",
    "        self.generated_marker_var = nn.Sequential(\n",
    "            nn.Linear(self.marker_shared_dim, self.marker_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def create_time_likelihood_net(self):\n",
    "        self.h_influence = nn.Linear(self.hidden_layer_dim, 1, bias=False)\n",
    "        self.base_intensity = nn.Parameter(torch.zeros(1,1,1))\n",
    "        self.wt = nn.Parameter(torch.tensor([[[1e-6]]]))\n",
    "    \n",
    "    \n",
    "    ############ METHODS #############\n",
    "    \n",
    "    def _embed_data(self, marker_seq, time_seq):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "            marker_seq: Tensor of shape TxBSx marker_dim\n",
    "            time_seq: Tensor of shape TxBSx 2\n",
    "            Output:\n",
    "            marker_seq_emb: Tensor of shape T x BS x marker_embed_dim\n",
    "            time_seq_emb: Tensor of shape T x BS x time_embed_dim\n",
    "        \"\"\"\n",
    "        marker_seq_emb = self.marker_embedding_net(marker_seq)\n",
    "        time_seq_emb = self.time_embedding_net(time_seq)\n",
    "        return marker_seq_emb, time_seq_emb\n",
    "    \n",
    "    \n",
    "    \n",
    "    def marker_log_likelihood(self, h_seq, marker_seq):\n",
    "        \"\"\"\n",
    "        Use the h_seq to generate the distribution for the markers,\n",
    "        and use that distribution to compute the log likelihood of the marker_seq\n",
    "            Input:  \n",
    "                    h_seq   : Tensor of shape T x BS x hidden_layer_dim (if real)\n",
    "                    marker_seq : Tensor of shape T x BS x marker_dim\n",
    "            Output:\n",
    "                    log_likelihood_marker_seq : T x BS x marker_dim\n",
    "        \"\"\"\n",
    "        marker_gen_shared = self.marker_gen_hidden(h_seq)\n",
    "        mu, var = self.generated_marker_mu(marker_gen_shared), self.generated_marker_var(marker_gen_shared)\n",
    "        \n",
    "        marker_gen_dist = Normal(mu, var.sqrt())\n",
    "        log_likelihood_marker_seq = marker_gen_dist.log_prob(marker_seq)\n",
    "        \n",
    "        return log_likelihood_marker_seq\n",
    "        \n",
    "        \n",
    "    def time_log_likelihood(self, h_seq, time_seq):\n",
    "        \"\"\"\n",
    "        Use the h_seq to compute the log likelihood of the time_seq\n",
    "        using the formula in the paper\n",
    "            Input:  \n",
    "                    h_seq   : Tensor of shape T x BS x hidden_layer_dim (if real)\n",
    "                    time_seq : Tensor of shape T x BS x 2 . Last dimension is [times, intervals]\n",
    "            Output:\n",
    "                    log_likelihood_time_seq : T x BS x 1\n",
    "        \"\"\"\n",
    "#         import pdb; pdb.set_trace()\n",
    "        past_influence = self.h_influence(h_seq)\n",
    "        current_influence = self.wt * time_seq[:,:,1:2]\n",
    "        base_intensity = self.base_intensity\n",
    "        \n",
    "        term1 = past_influence + current_influence + base_intensity\n",
    "        term2 = past_influence + base_intensity\n",
    "        \n",
    "        # After factorizing the formula in the paper\n",
    "        log_likelihood_time_seq = term1 + (term2.exp() - term1.exp())/self.wt\n",
    "        \n",
    "        return log_likelihood_time_seq\n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    def forward(self, marker_seq, time_seq, **kwargs):\n",
    "        # Transform markers and timesteps into the embedding spaces\n",
    "        marker_seq_emb, time_seq_emb = self._embed_data(marker_seq, time_seq)\n",
    "        T,BS,_ = marker_seq_emb.shape\n",
    "        \n",
    "        # Run RNN over the concatenated sequence [marker_seq_emb, time_seq_emb]\n",
    "        time_marker_combined = torch.cat([marker_seq_emb, time_seq_emb], dim=-1)\n",
    "        h_0 = torch.zeros(1, BS, self.hidden_layer_dim).to(device)\n",
    "        hidden_seq, _ = self.rnn(time_marker_combined, h_0)\n",
    "        hidden_combined = torch.cat([h_0, hidden_seq], dim=0)\n",
    "        \n",
    "        # compute the marker and time log likelihoods\n",
    "        # h_0 is used to generate marker_1 and so on...\n",
    "        marker_ll = self.marker_log_likelihood(hidden_combined[:-1], marker_seq)\n",
    "        # h_0 is used to generate timestamp_1 and so on...\n",
    "        time_ll = self.time_log_likelihood(hidden_combined[:-1], time_seq)\n",
    "        \n",
    "        likelihood_loss = marker_ll.sum() + time_ll.sum()\n",
    "        NLL = -likelihood_loss\n",
    "        \n",
    "        # NLL is used for optimization,\n",
    "        # the individual LL values are used for logging\n",
    "        return NLL, [-marker_ll.sum().item(), -time_ll.sum().item() ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRMTPP(RMTPP):\n",
    "    def __init__(self, latent_dim=20, **kwargs):\n",
    "        self.latent_dim = latent_dim\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.create_inference_net()\n",
    "        self.create_marker_generation_net()\n",
    "        self.create_time_likelihood_net()\n",
    "    \n",
    "    ## Utility Methods ##\n",
    "    def _reparameterize(self, mu, var):\n",
    "        epsilon = torch.randn_like(mu)\n",
    "        return mu + epsilon*var.sqrt()\n",
    "    \n",
    "    def create_inference_net(self):\n",
    "        self.inference_rnn = nn.GRU(\n",
    "            input_size = self.marker_embed_dim+self.time_embed_dim,\n",
    "            hidden_size = self.hidden_layer_dim\n",
    "        )\n",
    "        \n",
    "        self.inference_intermediate_net = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim, self.hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.posterior_mean_net = nn.Linear(self.hidden_layer_dim, self.latent_dim)\n",
    "        self.posterior_var_net = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim, self.latent_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "    def create_marker_generation_net(self):\n",
    "        \"\"\"\n",
    "            Generate network to create marker sufficient statistics using\n",
    "            rnn's hidden layer and latent variable\n",
    "        \"\"\"\n",
    "        self.marker_gen_hidden = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_dim+self.latent_dim, self.marker_shared_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.generated_marker_mu = nn.Linear(self.marker_shared_dim, self.marker_dim)\n",
    "        self.generated_marker_var = nn.Sequential(\n",
    "            nn.Linear(self.marker_shared_dim, self.marker_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def create_time_likelihood_net(self):\n",
    "        self.h_influence = nn.Linear(self.hidden_layer_dim+self.latent_dim, 1, bias=False)\n",
    "        self.base_intensity = nn.Parameter(torch.zeros(1,1,1))\n",
    "        self.wt = nn.Parameter(torch.randn(1,1,1))\n",
    "    \n",
    "        \n",
    "    def _inference(self, hidden_seq):\n",
    "        \"\"\"\n",
    "        Use the hidden_seq to compute the posterior\n",
    "        q(z | x) = NN(RNN(x(1...T))) = NN(h_T)\n",
    "        Also, compute a sampled value and return\n",
    "            Input:  \n",
    "                    hidden_seq   : Tensor of shape (T+1) x BS x hidden_layer_dim (first timestep is h_0)\n",
    "            Output:\n",
    "                    z_sampled: Tensor of shape 1 x BS x latent_dim\n",
    "                    z_mean: Tensor of shape 1 x BS x latent_dim\n",
    "                    z_var: Tensor of shape 1 x BS x latent_dim\n",
    "        \"\"\"\n",
    "        \n",
    "        intermediate_layer = self.inference_intermediate_net(hidden_seq[-1:])\n",
    "        z_mean = self.posterior_mean_net(intermediate_layer)\n",
    "        z_var = self.posterior_var_net(intermediate_layer)\n",
    "        z_sampled = self._reparameterize(z_mean, z_var)\n",
    "        \n",
    "        return z_sampled, z_mean, z_var\n",
    "    \n",
    "    def hz_combined(self, hidden_seq, z):\n",
    "        \"\"\"\n",
    "        Concatenate the z to the hidden_seq along the last dimension\n",
    "            Input:  \n",
    "                    hidden_seq   : Tensor of shape (T+1) x BS x hidden_layer_dim (first timestep is h_0)\n",
    "                    z: Tensor of shape 1 x BS x latent_dim\n",
    "            Output:\n",
    "                    hz = Tensor of shape (T+1) x BS x (hidden_layer_dim+latent_dim)\n",
    "        \"\"\"\n",
    "        # Extract timelength\n",
    "        T, _, _ = hidden_seq.shape\n",
    "        # Expand z on the time dimension, leaving everything else the same\n",
    "        z_broadcast = z.expand(T, -1, -1)\n",
    "        \n",
    "        hz = torch.cat([hidden_seq, z_broadcast], dim=-1)\n",
    "        \n",
    "        return hz\n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    def forward(self, marker_seq, time_seq, anneal=1.):\n",
    "        # Transform markers and timesteps into the embedding spaces\n",
    "        marker_seq_emb, time_seq_emb = self._embed_data(marker_seq, time_seq)\n",
    "        T,BS,_ = marker_seq_emb.shape\n",
    "        \n",
    "        # Run RNN over the concatenated sequence [marker_seq_emb, time_seq_emb]\n",
    "        time_marker_combined = torch.cat([marker_seq_emb, time_seq_emb], dim=-1)\n",
    "        h_0 = torch.zeros(1, BS, self.hidden_layer_dim).to(device)\n",
    "        # Run RNN\n",
    "        hidden_seq, _ = self.rnn(time_marker_combined, h_0)\n",
    "        # Append h_0 to h_1 .. h_T\n",
    "        hidden_seq = torch.cat([h_0, hidden_seq], dim=0)\n",
    "        \n",
    "        ## Inference\n",
    "        # Get the sampled value and (mean + var) latent variable\n",
    "        # using the hidden state sequence\n",
    "        posterior_sample, posterior_mean, posterior_var = self._inference(hidden_seq)\n",
    "        posterior_dist = Normal(posterior_mean, posterior_var.sqrt())\n",
    "\n",
    "        # Prior is just a Normal(0,1) dist\n",
    "        prior_dist = Normal(0,1)\n",
    "\n",
    "        ## Generative Part\n",
    "        \n",
    "        # Use the embedded markers and times to create another set of \n",
    "        # hidden vectors. Can reuse the h_0 and time_marker combined computed above\n",
    "\n",
    "        # Use an RNN to summarize the x1 ... xT sequence\n",
    "        hidden_seq, _ = self.rnn(time_marker_combined, h_0)\n",
    "        hidden_seq = torch.cat([h_0, hidden_seq], dim=0)\n",
    "        \n",
    "        # Combine hidden_seq and z to form the input for the generative part\n",
    "        hz_combined = self.hz_combined(hidden_seq, posterior_sample)\n",
    "        \n",
    "        # compute the marker and time log likelihoods\n",
    "        # z,h_0 is used to generate marker_1 and so on...\n",
    "        marker_ll = self.marker_log_likelihood(hz_combined[:-1], marker_seq)\n",
    "        # z,h_0 is used to generate timestamp_1 and so on...\n",
    "        time_ll = self.time_log_likelihood(hz_combined[:-1], time_seq)\n",
    "        \n",
    "        likelihood_loss = marker_ll.sum() + time_ll.sum()\n",
    "        NLL = -likelihood_loss\n",
    "        \n",
    "        KL = kl_divergence(posterior_dist, prior_dist).sum()\n",
    "        \n",
    "        loss = NLL + anneal*10*KL\n",
    "        \n",
    "        # NLL and KL are used for optimization,\n",
    "        # the individual LL values are used for logging\n",
    "        return loss, [-marker_ll.sum().item(), -time_ll.sum().item(), KL.item()]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_ import generate_mpp, test_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import train\n",
    "from hrmtpp import hrmtpp\n",
    "from rmtpp import rmtpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, data = None, val_data=None, lr= 1e-2, l2_reg=1e-2, epoch = 200, batch_size = 200):\n",
    "    if data == None:\n",
    "        data, val_data = generate_mpp()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=l2_reg)\n",
    "\n",
    "    for epoch_number in range(epoch):\n",
    "        train(model, epoch_number, data, optimizer, batch_size, val_data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, data, val_data):\n",
    "    model = model().to(device)\n",
    "#     data, _ = generate_mpp(type='hawkes', num_sample=1000)\n",
    "#     val_data, _ = generate_mpp(type='hawkes', num_sample = 200)\n",
    "    print(\"Times: Data Shape: {}, Val Data Shape: {}\".format(data['t'].shape, val_data['t'].shape))\n",
    "    print(\"Markers: Data Shape: {}, Val Data Shape: {}\".format(data['x'].shape, val_data['x'].shape))\n",
    "    trainer(model, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data, _ = generate_mpp(type='hawkes', num_sample=1000)\n",
    "# val_data, _ = generate_mpp(type='hawkes', num_sample = 200)\n",
    "data, _ = generate_mpp(type='autoregressive', time_step=50, num_sample=1000, num_clusters=10, m=8)\n",
    "data, val_data = test_val_split(data, val_ratio=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMTPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([50, 8000, 2]), Val Data Shape: torch.Size([50, 2000, 2])\n",
      "Markers: Data Shape: torch.Size([50, 8000, 20]), Val Data Shape: torch.Size([50, 2000, 20])\n",
      "Epoch: 0, NLL Loss: 1534.8873046875, Val Loss: 62688.44921875, Time took: 0.5179219245910645\n",
      "Train loss Meta Info:  [1470.94384375   63.94345837]\n",
      "Val Loss Meta Info:  [57992.555, 4695.8971875]\n",
      "\n",
      "Epoch: 1, NLL Loss: 1567.135203125, Val Loss: 60602.47265625, Time took: 0.4047243595123291\n",
      "Train loss Meta Info:  [1449.47568359  117.65953296]\n",
      "Val Loss Meta Info:  [58507.18, 2095.2965625]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1513.94424609375, Val Loss: 61989.109375, Time took: 0.40695929527282715\n",
      "Train loss Meta Info:  [1462.4589375    51.48530933]\n",
      "Val Loss Meta Info:  [57767.58, 4221.53]\n",
      "\n",
      "Epoch: 3, NLL Loss: 1536.696671875, Val Loss: 59942.40234375, Time took: 0.4000675678253174\n",
      "Train loss Meta Info:  [1444.10030469   92.59635291]\n",
      "Val Loss Meta Info:  [57271.87, 2670.53625]\n",
      "\n",
      "Epoch: 4, NLL Loss: 1484.109796875, Val Loss: 60032.1953125, Time took: 0.3984873294830322\n",
      "Train loss Meta Info:  [1431.59547656   52.51430969]\n",
      "Val Loss Meta Info:  [57128.205, 2903.99]\n",
      "\n",
      "Epoch: 5, NLL Loss: 1484.76216796875, Val Loss: 60471.44921875, Time took: 0.40341711044311523\n",
      "Train loss Meta Info:  [1427.92233203   56.8398457 ]\n",
      "Val Loss Meta Info:  [57065.79, 3405.658125]\n",
      "\n",
      "Epoch: 6, NLL Loss: 1489.00830859375, Val Loss: 60991.98046875, Time took: 0.39897966384887695\n",
      "Train loss Meta Info:  [1426.367625     62.64068188]\n",
      "Val Loss Meta Info:  [56966.7, 4025.28125]\n",
      "\n",
      "Epoch: 7, NLL Loss: 1487.397078125, Val Loss: 62015.078125, Time took: 0.3988981246948242\n",
      "Train loss Meta Info:  [1423.90782031   63.48925952]\n",
      "Val Loss Meta Info:  [56917.33, 5097.74875]\n",
      "\n",
      "Epoch: 8, NLL Loss: 1482.8526875, Val Loss: 64360.0703125, Time took: 0.40188002586364746\n",
      "Train loss Meta Info:  [1422.70834766   60.14435107]\n",
      "Val Loss Meta Info:  [56890.21, 7469.8575]\n",
      "\n",
      "Epoch: 9, NLL Loss: 1476.91053125, Val Loss: 69467.2421875, Time took: 0.40689635276794434\n",
      "Train loss Meta Info:  [1422.04884766   54.86168311]\n",
      "Val Loss Meta Info:  [56892.565, 12574.675]\n",
      "\n",
      "Epoch: 10, NLL Loss: 1473.17072265625, Val Loss: 77743.3671875, Time took: 0.4009072780609131\n",
      "Train loss Meta Info:  [1422.09735547   51.07336707]\n",
      "Val Loss Meta Info:  [56908.91, 20834.45875]\n",
      "\n",
      "Epoch: 11, NLL Loss: 1474.26366015625, Val Loss: 87588.0546875, Time took: 0.4074399471282959\n",
      "Train loss Meta Info:  [1422.47277344   51.79087708]\n",
      "Val Loss Meta Info:  [56896.105, 30691.96]\n",
      "\n",
      "Epoch: 12, NLL Loss: 1476.686625, Val Loss: 93310.21875, Time took: 0.40576744079589844\n",
      "Train loss Meta Info:  [1422.14569141   54.54094788]\n",
      "Val Loss Meta Info:  [56864.805, 36445.42]\n",
      "\n",
      "Epoch: 13, NLL Loss: 1475.37046875, Val Loss: 94143.03125, Time took: 0.3959498405456543\n",
      "Train loss Meta Info:  [1421.37747266   53.99299902]\n",
      "Val Loss Meta Info:  [56838.605, 37304.4275]\n",
      "\n",
      "Epoch: 14, NLL Loss: 1472.384375, Val Loss: 91965.8046875, Time took: 0.3957631587982178\n",
      "Train loss Meta Info:  [1420.747625     51.63675415]\n",
      "Val Loss Meta Info:  [56821.32, 35144.4925]\n",
      "\n",
      "Epoch: 15, NLL Loss: 1470.76456640625, Val Loss: 89198.65625, Time took: 0.3998067378997803\n",
      "Train loss Meta Info:  [1420.33204297   50.4325177 ]\n",
      "Val Loss Meta Info:  [56808.735, 32389.9225]\n",
      "\n",
      "Epoch: 16, NLL Loss: 1470.63507421875, Val Loss: 87054.3515625, Time took: 0.4047880172729492\n",
      "Train loss Meta Info:  [1420.02102734   50.61404297]\n",
      "Val Loss Meta Info:  [56800.155, 30254.1975]\n",
      "\n",
      "Epoch: 17, NLL Loss: 1470.617546875, Val Loss: 91032.15625, Time took: 0.3995072841644287\n",
      "Train loss Meta Info:  [1419.79822266   50.8193252 ]\n",
      "Val Loss Meta Info:  [56791.485, 34240.68]\n",
      "\n",
      "Epoch: 18, NLL Loss: 1470.51306640625, Val Loss: 89718.53125, Time took: 0.3977775573730469\n",
      "Train loss Meta Info:  [1419.58605078   50.9270061 ]\n",
      "Val Loss Meta Info:  [56784.985, 32933.5425]\n",
      "\n",
      "Epoch: 19, NLL Loss: 1469.714984375, Val Loss: 88840.15625, Time took: 0.4008612632751465\n",
      "Train loss Meta Info:  [1419.42471484   50.29027368]\n",
      "Val Loss Meta Info:  [56785.86, 32054.295]\n",
      "\n",
      "Epoch: 20, NLL Loss: 1468.424203125, Val Loss: 94248.4765625, Time took: 0.3972797393798828\n",
      "Train loss Meta Info:  [1419.44460938   48.9795885 ]\n",
      "Val Loss Meta Info:  [56795.08, 37453.405]\n",
      "\n",
      "Epoch: 21, NLL Loss: 1469.24368359375, Val Loss: 91505.0859375, Time took: 0.39479565620422363\n",
      "Train loss Meta Info:  [1419.67562109   49.56806177]\n",
      "Val Loss Meta Info:  [56790.24, 34714.8475]\n",
      "\n",
      "Epoch: 22, NLL Loss: 1468.32690234375, Val Loss: 87790.1171875, Time took: 0.3967323303222656\n",
      "Train loss Meta Info:  [1419.56077344   48.7661283 ]\n",
      "Val Loss Meta Info:  [56783.64, 31006.485]\n",
      "\n",
      "Epoch: 23, NLL Loss: 1467.82199609375, Val Loss: 83813.8515625, Time took: 0.4005749225616455\n",
      "Train loss Meta Info:  [1419.40629687   48.41570172]\n",
      "Val Loss Meta Info:  [56779.73, 27034.125]\n",
      "\n",
      "Epoch: 24, NLL Loss: 1467.3776171875, Val Loss: 81734.453125, Time took: 0.3967297077178955\n",
      "Train loss Meta Info:  [1419.31677734   48.06083978]\n",
      "Val Loss Meta Info:  [56780.33, 24954.125]\n",
      "\n",
      "Epoch: 25, NLL Loss: 1467.289796875, Val Loss: 77492.671875, Time took: 0.39863061904907227\n",
      "Train loss Meta Info:  [1419.32145313   47.968341  ]\n",
      "Val Loss Meta Info:  [56781.86, 20710.81375]\n",
      "\n",
      "Epoch: 26, NLL Loss: 1467.05127734375, Val Loss: 73864.4375, Time took: 0.4020085334777832\n",
      "Train loss Meta Info:  [1419.36510156   47.68617712]\n",
      "Val Loss Meta Info:  [56777.78, 17086.66]\n",
      "\n",
      "Epoch: 27, NLL Loss: 1466.5892890625, Val Loss: 71113.046875, Time took: 0.39782142639160156\n",
      "Train loss Meta Info:  [1419.27099219   47.31829913]\n",
      "Val Loss Meta Info:  [56773.61, 14339.44]\n",
      "\n",
      "Epoch: 28, NLL Loss: 1466.10702734375, Val Loss: 69135.9921875, Time took: 0.395158052444458\n",
      "Train loss Meta Info:  [1419.1715625    46.93545953]\n",
      "Val Loss Meta Info:  [56771.42, 12364.57625]\n",
      "\n",
      "Epoch: 29, NLL Loss: 1465.70026953125, Val Loss: 67475.734375, Time took: 0.3979346752166748\n",
      "Train loss Meta Info:  [1419.10565234   46.59462335]\n",
      "Val Loss Meta Info:  [56767.535, 10708.19875]\n",
      "\n",
      "Epoch: 30, NLL Loss: 1465.0837265625, Val Loss: 66812.3828125, Time took: 0.40299177169799805\n",
      "Train loss Meta Info:  [1419.00898047   46.07474744]\n",
      "Val Loss Meta Info:  [56768.69, 10043.695]\n",
      "\n",
      "Epoch: 31, NLL Loss: 1465.48165625, Val Loss: 65420.8671875, Time took: 0.3968467712402344\n",
      "Train loss Meta Info:  [1419.04104687   46.44060345]\n",
      "Val Loss Meta Info:  [56768.83, 8652.040625]\n",
      "\n",
      "Epoch: 32, NLL Loss: 1465.08251953125, Val Loss: 63780.70703125, Time took: 0.3963897228240967\n",
      "Train loss Meta Info:  [1419.04641406   46.03611786]\n",
      "Val Loss Meta Info:  [56766.0, 7014.7075]\n",
      "\n",
      "Epoch: 33, NLL Loss: 1464.709484375, Val Loss: 63007.4453125, Time took: 0.39771604537963867\n",
      "Train loss Meta Info:  [1418.96735156   45.74213635]\n",
      "Val Loss Meta Info:  [56762.975, 6244.47]\n",
      "\n",
      "Epoch: 34, NLL Loss: 1464.2290625, Val Loss: 63278.12890625, Time took: 0.39317750930786133\n",
      "Train loss Meta Info:  [1418.88377734   45.34528113]\n",
      "Val Loss Meta Info:  [56762.93, 6515.1975]\n",
      "\n",
      "Epoch: 35, NLL Loss: 1465.37912109375, Val Loss: 62243.8671875, Time took: 0.39172816276550293\n",
      "Train loss Meta Info:  [1418.86228906   46.51683038]\n",
      "Val Loss Meta Info:  [56761.435, 5482.43375]\n",
      "\n",
      "Epoch: 36, NLL Loss: 1464.263984375, Val Loss: 61374.64453125, Time took: 0.392167329788208\n",
      "Train loss Meta Info:  [1418.81742969   45.44655579]\n",
      "Val Loss Meta Info:  [56762.0, 4612.644375]\n",
      "\n",
      "Epoch: 37, NLL Loss: 1464.03858984375, Val Loss: 61245.77734375, Time took: 0.39736247062683105\n",
      "Train loss Meta Info:  [1418.84173828   45.19685205]\n",
      "Val Loss Meta Info:  [56763.72, 4482.0625]\n",
      "\n",
      "Epoch: 38, NLL Loss: 1464.40617578125, Val Loss: 60684.9921875, Time took: 0.3921852111816406\n",
      "Train loss Meta Info:  [1418.89675      45.50943213]\n",
      "Val Loss Meta Info:  [56761.78, 3923.21625]\n",
      "\n",
      "Epoch: 39, NLL Loss: 1464.2741953125, Val Loss: 60273.1484375, Time took: 0.39290595054626465\n",
      "Train loss Meta Info:  [1418.85855078   45.41563763]\n",
      "Val Loss Meta Info:  [56761.33, 3511.81875]\n",
      "\n",
      "Epoch: 40, NLL Loss: 1464.0354296875, Val Loss: 60502.546875, Time took: 0.3974297046661377\n",
      "Train loss Meta Info:  [1418.85482031   45.18060968]\n",
      "Val Loss Meta Info:  [56759.31, 3743.24125]\n",
      "\n",
      "Epoch: 41, NLL Loss: 1464.78904296875, Val Loss: 59672.66015625, Time took: 0.3955678939819336\n",
      "Train loss Meta Info:  [1418.79844141   45.99060559]\n",
      "Val Loss Meta Info:  [56758.28, 2914.3825]\n",
      "\n",
      "Epoch: 42, NLL Loss: 1463.9111015625, Val Loss: 59447.34375, Time took: 0.39221692085266113\n",
      "Train loss Meta Info:  [1418.79298828   45.11810846]\n",
      "Val Loss Meta Info:  [56758.99, 2688.355625]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, NLL Loss: 1464.01020703125, Val Loss: 59310.0546875, Time took: 0.39210081100463867\n",
      "Train loss Meta Info:  [1418.81104688   45.19917462]\n",
      "Val Loss Meta Info:  [56758.26, 2551.79453125]\n",
      "\n",
      "Epoch: 44, NLL Loss: 1463.31809375, Val Loss: 59423.22265625, Time took: 0.396686315536499\n",
      "Train loss Meta Info:  [1418.78383203   44.53426324]\n",
      "Val Loss Meta Info:  [56758.415, 2664.81125]\n",
      "\n",
      "Epoch: 45, NLL Loss: 1464.9036796875, Val Loss: 59143.26953125, Time took: 0.3937511444091797\n",
      "Train loss Meta Info:  [1418.76585156   46.13782446]\n",
      "Val Loss Meta Info:  [56759.995, 2383.2771875]\n",
      "\n",
      "Epoch: 46, NLL Loss: 1463.4636875, Val Loss: 59021.4453125, Time took: 0.3920786380767822\n",
      "Train loss Meta Info:  [1418.79946484   44.66423236]\n",
      "Val Loss Meta Info:  [56759.27, 2262.17359375]\n",
      "\n",
      "Epoch: 47, NLL Loss: 1463.66427734375, Val Loss: 58927.5390625, Time took: 0.4002261161804199\n",
      "Train loss Meta Info:  [1418.78257031   44.88170203]\n",
      "Val Loss Meta Info:  [56757.32, 2170.2184375]\n",
      "\n",
      "Epoch: 48, NLL Loss: 1463.4723046875, Val Loss: 58956.9921875, Time took: 0.39365053176879883\n",
      "Train loss Meta Info:  [1418.74046875   44.73184717]\n",
      "Val Loss Meta Info:  [56756.59, 2200.40625]\n",
      "\n",
      "Epoch: 49, NLL Loss: 1463.42638671875, Val Loss: 58891.3828125, Time took: 0.39129114151000977\n",
      "Train loss Meta Info:  [1418.73441016   44.69198499]\n",
      "Val Loss Meta Info:  [56755.815, 2135.57109375]\n",
      "\n",
      "Epoch: 50, NLL Loss: 1463.354390625, Val Loss: 58814.95703125, Time took: 0.39181971549987793\n",
      "Train loss Meta Info:  [1418.71349609   44.64090344]\n",
      "Val Loss Meta Info:  [56755.79, 2059.16828125]\n",
      "\n",
      "Epoch: 51, NLL Loss: 1462.9388515625, Val Loss: 58822.3203125, Time took: 0.39853715896606445\n",
      "Train loss Meta Info:  [1418.70171094   44.23714423]\n",
      "Val Loss Meta Info:  [56756.17, 2066.1521875]\n",
      "\n",
      "Epoch: 52, NLL Loss: 1463.20555078125, Val Loss: 58723.5234375, Time took: 0.3955109119415283\n",
      "Train loss Meta Info:  [1418.69689453   44.5086485 ]\n",
      "Val Loss Meta Info:  [56757.395, 1966.1278125]\n",
      "\n",
      "Epoch: 53, NLL Loss: 1463.30273046875, Val Loss: 58703.578125, Time took: 0.3979523181915283\n",
      "Train loss Meta Info:  [1418.73411328   44.56861658]\n",
      "Val Loss Meta Info:  [56756.9, 1946.6803125]\n",
      "\n",
      "Epoch: 54, NLL Loss: 1462.80905859375, Val Loss: 58665.20703125, Time took: 0.40106821060180664\n",
      "Train loss Meta Info:  [1418.70509375   44.10396753]\n",
      "Val Loss Meta Info:  [56755.695, 1909.5159375]\n",
      "\n",
      "Epoch: 55, NLL Loss: 1462.681546875, Val Loss: 58634.625, Time took: 0.39810919761657715\n",
      "Train loss Meta Info:  [1418.67539453   44.00615717]\n",
      "Val Loss Meta Info:  [56754.82, 1879.80484375]\n",
      "\n",
      "Epoch: 56, NLL Loss: 1462.6691171875, Val Loss: 58606.97265625, Time took: 0.40154147148132324\n",
      "Train loss Meta Info:  [1418.65892578   44.01018597]\n",
      "Val Loss Meta Info:  [56754.09, 1852.884375]\n",
      "\n",
      "Epoch: 57, NLL Loss: 1462.59233984375, Val Loss: 58591.09375, Time took: 0.392592191696167\n",
      "Train loss Meta Info:  [1418.64173047   43.95061444]\n",
      "Val Loss Meta Info:  [56754.835, 1836.25890625]\n",
      "\n",
      "Epoch: 58, NLL Loss: 1462.673171875, Val Loss: 58574.4921875, Time took: 0.3986046314239502\n",
      "Train loss Meta Info:  [1418.66371484   44.00945679]\n",
      "Val Loss Meta Info:  [56754.68, 1819.81671875]\n",
      "\n",
      "Epoch: 59, NLL Loss: 1462.583046875, Val Loss: 58554.5, Time took: 0.39279675483703613\n",
      "Train loss Meta Info:  [1418.66172656   43.92132025]\n",
      "Val Loss Meta Info:  [56754.62, 1799.8803125]\n",
      "\n",
      "Epoch: 60, NLL Loss: 1462.32611328125, Val Loss: 58543.5625, Time took: 0.3916361331939697\n",
      "Train loss Meta Info:  [1418.66104297   43.66506879]\n",
      "Val Loss Meta Info:  [56754.72, 1788.84640625]\n",
      "\n",
      "Epoch: 61, NLL Loss: 1462.31091796875, Val Loss: 58523.15234375, Time took: 0.39802026748657227\n",
      "Train loss Meta Info:  [1418.66225781   43.64866193]\n",
      "Val Loss Meta Info:  [56754.015, 1769.1421875]\n",
      "\n",
      "Epoch: 62, NLL Loss: 1462.1161640625, Val Loss: 58546.2734375, Time took: 0.39552927017211914\n",
      "Train loss Meta Info:  [1418.63949609   43.47667468]\n",
      "Val Loss Meta Info:  [56754.495, 1791.7821875]\n",
      "\n",
      "Epoch: 63, NLL Loss: 1462.99169921875, Val Loss: 58524.53515625, Time took: 0.39272642135620117\n",
      "Train loss Meta Info:  [1418.65289844   44.3387951 ]\n",
      "Val Loss Meta Info:  [56754.62, 1769.9165625]\n",
      "\n",
      "Epoch: 64, NLL Loss: 1462.49848828125, Val Loss: 58514.50390625, Time took: 0.3951270580291748\n",
      "Train loss Meta Info:  [1418.64540234   43.8530813 ]\n",
      "Val Loss Meta Info:  [56754.53, 1759.97578125]\n",
      "\n",
      "Epoch: 65, NLL Loss: 1462.29035546875, Val Loss: 58518.20703125, Time took: 0.39757800102233887\n",
      "Train loss Meta Info:  [1418.63819531   43.65215717]\n",
      "Val Loss Meta Info:  [56754.58, 1763.63234375]\n",
      "\n",
      "Epoch: 66, NLL Loss: 1462.429421875, Val Loss: 58502.26953125, Time took: 0.3947145938873291\n",
      "Train loss Meta Info:  [1418.6384375    43.79098895]\n",
      "Val Loss Meta Info:  [56753.63, 1748.6409375]\n",
      "\n",
      "Epoch: 67, NLL Loss: 1462.09063671875, Val Loss: 58500.4296875, Time took: 0.3922462463378906\n",
      "Train loss Meta Info:  [1418.61782812   43.47280194]\n",
      "Val Loss Meta Info:  [56753.3, 1747.130625]\n",
      "\n",
      "Epoch: 68, NLL Loss: 1462.0921328125, Val Loss: 58499.16796875, Time took: 0.39586782455444336\n",
      "Train loss Meta Info:  [1418.61667188   43.47545898]\n",
      "Val Loss Meta Info:  [56753.375, 1745.7959375]\n",
      "\n",
      "Epoch: 69, NLL Loss: 1462.125375, Val Loss: 58490.625, Time took: 0.3952968120574951\n",
      "Train loss Meta Info:  [1418.62597266   43.49941925]\n",
      "Val Loss Meta Info:  [56753.13, 1737.496875]\n",
      "\n",
      "Epoch: 70, NLL Loss: 1461.9726328125, Val Loss: 58488.60546875, Time took: 0.39241456985473633\n",
      "Train loss Meta Info:  [1418.62381641   43.34880579]\n",
      "Val Loss Meta Info:  [56753.07, 1735.5359375]\n",
      "\n",
      "Epoch: 71, NLL Loss: 1461.992765625, Val Loss: 58482.68359375, Time took: 0.3931891918182373\n",
      "Train loss Meta Info:  [1418.62262109   43.37014777]\n",
      "Val Loss Meta Info:  [56752.3, 1730.384375]\n",
      "\n",
      "Epoch: 72, NLL Loss: 1461.93234375, Val Loss: 58474.1171875, Time took: 0.3979976177215576\n",
      "Train loss Meta Info:  [1418.60133203   43.3310097 ]\n",
      "Val Loss Meta Info:  [56752.665, 1721.45484375]\n",
      "\n",
      "Epoch: 73, NLL Loss: 1461.797640625, Val Loss: 58470.515625, Time took: 0.3931412696838379\n",
      "Train loss Meta Info:  [1418.60866406   43.18896265]\n",
      "Val Loss Meta Info:  [56752.69, 1717.824375]\n",
      "\n",
      "Epoch: 74, NLL Loss: 1461.78408203125, Val Loss: 58470.3671875, Time took: 0.39530277252197266\n",
      "Train loss Meta Info:  [1418.60874219   43.17534247]\n",
      "Val Loss Meta Info:  [56752.84, 1717.5325]\n",
      "\n",
      "Epoch: 75, NLL Loss: 1461.8227109375, Val Loss: 58465.96484375, Time took: 0.39989542961120605\n",
      "Train loss Meta Info:  [1418.61110938   43.21160541]\n",
      "Val Loss Meta Info:  [56752.93, 1713.03296875]\n",
      "\n",
      "Epoch: 76, NLL Loss: 1461.74198046875, Val Loss: 58463.421875, Time took: 0.39725327491760254\n",
      "Train loss Meta Info:  [1418.61439844   43.12758441]\n",
      "Val Loss Meta Info:  [56752.41, 1711.0128125]\n",
      "\n",
      "Epoch: 77, NLL Loss: 1461.68836328125, Val Loss: 58461.921875, Time took: 0.39647769927978516\n",
      "Train loss Meta Info:  [1418.60355078   43.08481006]\n",
      "Val Loss Meta Info:  [56752.57, 1709.3553125]\n",
      "\n",
      "Epoch: 78, NLL Loss: 1461.66815234375, Val Loss: 58455.96875, Time took: 0.3958890438079834\n",
      "Train loss Meta Info:  [1418.60845313   43.05968884]\n",
      "Val Loss Meta Info:  [56752.36, 1703.61125]\n",
      "\n",
      "Epoch: 79, NLL Loss: 1461.5474140625, Val Loss: 58453.1484375, Time took: 0.4019794464111328\n",
      "Train loss Meta Info:  [1418.60117578   42.94623059]\n",
      "Val Loss Meta Info:  [56752.29, 1700.859375]\n",
      "\n",
      "Epoch: 80, NLL Loss: 1461.50653515625, Val Loss: 58451.2578125, Time took: 0.3953888416290283\n",
      "Train loss Meta Info:  [1418.59553125   42.91101624]\n",
      "Val Loss Meta Info:  [56752.46, 1698.8009375]\n",
      "\n",
      "Epoch: 81, NLL Loss: 1461.49954296875, Val Loss: 58447.8828125, Time took: 0.39646315574645996\n",
      "Train loss Meta Info:  [1418.59468359   42.9048504 ]\n",
      "Val Loss Meta Info:  [56752.42, 1695.46578125]\n",
      "\n",
      "Epoch: 82, NLL Loss: 1461.45165625, Val Loss: 58445.69921875, Time took: 0.40080833435058594\n",
      "Train loss Meta Info:  [1418.58926172   42.8623938 ]\n",
      "Val Loss Meta Info:  [56752.615, 1693.0825]\n",
      "\n",
      "Epoch: 83, NLL Loss: 1461.43604296875, Val Loss: 58442.828125, Time took: 0.3965306282043457\n",
      "Train loss Meta Info:  [1418.59185156   42.8441933 ]\n",
      "Val Loss Meta Info:  [56752.43, 1690.4021875]\n",
      "\n",
      "Epoch: 84, NLL Loss: 1461.39560546875, Val Loss: 58439.75, Time took: 0.3960878849029541\n",
      "Train loss Meta Info:  [1418.58673828   42.80887915]\n",
      "Val Loss Meta Info:  [56752.36, 1687.39]\n",
      "\n",
      "Epoch: 85, NLL Loss: 1461.3318984375, Val Loss: 58438.8046875, Time took: 0.3946843147277832\n",
      "Train loss Meta Info:  [1418.58676562   42.74513123]\n",
      "Val Loss Meta Info:  [56752.35, 1686.45734375]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86, NLL Loss: 1461.310375, Val Loss: 58438.03515625, Time took: 0.40007543563842773\n",
      "Train loss Meta Info:  [1418.58849609   42.7218855 ]\n",
      "Val Loss Meta Info:  [56752.24, 1685.79484375]\n",
      "\n",
      "Epoch: 87, NLL Loss: 1461.28348046875, Val Loss: 58436.671875, Time took: 0.3983619213104248\n",
      "Train loss Meta Info:  [1418.58635156   42.69713446]\n",
      "Val Loss Meta Info:  [56752.28, 1684.393125]\n",
      "\n",
      "Epoch: 88, NLL Loss: 1461.2494296875, Val Loss: 58435.02734375, Time took: 0.3967139720916748\n",
      "Train loss Meta Info:  [1418.58641406   42.66301318]\n",
      "Val Loss Meta Info:  [56752.27, 1682.7590625]\n",
      "\n",
      "Epoch: 89, NLL Loss: 1461.2265078125, Val Loss: 58431.68359375, Time took: 0.3997375965118408\n",
      "Train loss Meta Info:  [1418.58488672   42.64161725]\n",
      "Val Loss Meta Info:  [56752.26, 1679.4259375]\n",
      "\n",
      "Epoch: 90, NLL Loss: 1461.17796484375, Val Loss: 58428.51953125, Time took: 0.39623260498046875\n",
      "Train loss Meta Info:  [1418.58432812   42.59363403]\n",
      "Val Loss Meta Info:  [56752.12, 1676.3978125]\n",
      "\n",
      "Epoch: 91, NLL Loss: 1461.14030078125, Val Loss: 58426.45703125, Time took: 0.39499521255493164\n",
      "Train loss Meta Info:  [1418.58209766   42.55820367]\n",
      "Val Loss Meta Info:  [56752.02, 1674.44]\n",
      "\n",
      "Epoch: 92, NLL Loss: 1461.11953515625, Val Loss: 58424.28515625, Time took: 0.39652132987976074\n",
      "Train loss Meta Info:  [1418.58128516   42.53824664]\n",
      "Val Loss Meta Info:  [56751.99, 1672.296875]\n",
      "\n",
      "Epoch: 93, NLL Loss: 1461.08293359375, Val Loss: 58422.66796875, Time took: 0.40232419967651367\n",
      "Train loss Meta Info:  [1418.58194141   42.50099554]\n",
      "Val Loss Meta Info:  [56751.95, 1670.719375]\n",
      "\n",
      "Epoch: 94, NLL Loss: 1461.04928515625, Val Loss: 58420.796875, Time took: 0.4061446189880371\n",
      "Train loss Meta Info:  [1418.58101953   42.46826953]\n",
      "Val Loss Meta Info:  [56751.965, 1668.8359375]\n",
      "\n",
      "Epoch: 95, NLL Loss: 1461.00059765625, Val Loss: 58418.87890625, Time took: 0.41506195068359375\n",
      "Train loss Meta Info:  [1418.57967578   42.42092047]\n",
      "Val Loss Meta Info:  [56751.96, 1666.91921875]\n",
      "\n",
      "Epoch: 96, NLL Loss: 1460.95470703125, Val Loss: 58416.83203125, Time took: 0.404630184173584\n",
      "Train loss Meta Info:  [1418.57788672   42.37683258]\n",
      "Val Loss Meta Info:  [56752.39, 1664.443125]\n",
      "\n",
      "Epoch: 97, NLL Loss: 1460.91640625, Val Loss: 58415.1171875, Time took: 0.40478038787841797\n",
      "Train loss Meta Info:  [1418.58695313   42.32946509]\n",
      "Val Loss Meta Info:  [56752.555, 1662.565]\n",
      "\n",
      "Epoch: 98, NLL Loss: 1460.88243359375, Val Loss: 58412.3125, Time took: 0.40444111824035645\n",
      "Train loss Meta Info:  [1418.58755859   42.29488495]\n",
      "Val Loss Meta Info:  [56752.295, 1660.0203125]\n",
      "\n",
      "Epoch: 99, NLL Loss: 1460.81956640625, Val Loss: 58412.41015625, Time took: 0.4104957580566406\n",
      "Train loss Meta Info:  [1418.58078125   42.23878052]\n",
      "Val Loss Meta Info:  [56752.515, 1659.894375]\n",
      "\n",
      "Epoch: 100, NLL Loss: 1460.8334765625, Val Loss: 58421.61328125, Time took: 0.42272114753723145\n",
      "Train loss Meta Info:  [1418.59098828   42.24248566]\n",
      "Val Loss Meta Info:  [56753.005, 1668.6078125]\n",
      "\n",
      "Epoch: 101, NLL Loss: 1461.07827734375, Val Loss: 58419.390625, Time took: 0.4181101322174072\n",
      "Train loss Meta Info:  [1418.60899219   42.46928516]\n",
      "Val Loss Meta Info:  [56754.59, 1664.80046875]\n",
      "\n",
      "Epoch: 102, NLL Loss: 1460.98345703125, Val Loss: 58421.1796875, Time took: 0.40430355072021484\n",
      "Train loss Meta Info:  [1418.64621484   42.33723718]\n",
      "Val Loss Meta Info:  [56752.55, 1668.6321875]\n",
      "\n",
      "Epoch: 103, NLL Loss: 1461.00331640625, Val Loss: 58412.69921875, Time took: 0.4069507122039795\n",
      "Train loss Meta Info:  [1418.58941016   42.41389392]\n",
      "Val Loss Meta Info:  [56753.63, 1659.0696875]\n",
      "\n",
      "Epoch: 104, NLL Loss: 1460.80379296875, Val Loss: 58411.640625, Time took: 0.4055788516998291\n",
      "Train loss Meta Info:  [1418.60819531   42.19559503]\n",
      "Val Loss Meta Info:  [56754.76, 1656.880625]\n",
      "\n",
      "Epoch: 105, NLL Loss: 1460.78290625, Val Loss: 58412.96875, Time took: 0.4020378589630127\n",
      "Train loss Meta Info:  [1418.63382813   42.14908093]\n",
      "Val Loss Meta Info:  [56752.355, 1660.61578125]\n",
      "\n",
      "Epoch: 106, NLL Loss: 1460.85439453125, Val Loss: 58413.30859375, Time took: 0.403918981552124\n",
      "Train loss Meta Info:  [1418.58112891   42.2732652 ]\n",
      "Val Loss Meta Info:  [56754.84, 1658.46890625]\n",
      "\n",
      "Epoch: 107, NLL Loss: 1460.9165078125, Val Loss: 58410.32421875, Time took: 0.40774989128112793\n",
      "Train loss Meta Info:  [1418.64384766   42.27266772]\n",
      "Val Loss Meta Info:  [56753.215, 1657.1078125]\n",
      "\n",
      "Epoch: 108, NLL Loss: 1460.8354921875, Val Loss: 58410.98046875, Time took: 0.40358996391296387\n",
      "Train loss Meta Info:  [1418.5978125    42.23768121]\n",
      "Val Loss Meta Info:  [56753.43, 1657.5525]\n",
      "\n",
      "Epoch: 109, NLL Loss: 1460.83841015625, Val Loss: 58410.57421875, Time took: 0.4031541347503662\n",
      "Train loss Meta Info:  [1418.59556641   42.24283722]\n",
      "Val Loss Meta Info:  [56754.66, 1655.9153125]\n",
      "\n",
      "Epoch: 110, NLL Loss: 1460.8336796875, Val Loss: 58408.3203125, Time took: 0.40468645095825195\n",
      "Train loss Meta Info:  [1418.62390234   42.20977075]\n",
      "Val Loss Meta Info:  [56752.495, 1655.825]\n",
      "\n",
      "Epoch: 111, NLL Loss: 1460.7616015625, Val Loss: 58410.671875, Time took: 0.40350985527038574\n",
      "Train loss Meta Info:  [1418.57274219   42.18886865]\n",
      "Val Loss Meta Info:  [56754.07, 1656.60625]\n",
      "\n",
      "Epoch: 112, NLL Loss: 1460.79641015625, Val Loss: 58407.86328125, Time took: 0.40216755867004395\n",
      "Train loss Meta Info:  [1418.615375     42.18102325]\n",
      "Val Loss Meta Info:  [56752.61, 1655.2565625]\n",
      "\n",
      "Epoch: 113, NLL Loss: 1460.72962890625, Val Loss: 58407.171875, Time took: 0.40144848823547363\n",
      "Train loss Meta Info:  [1418.57866016   42.150974  ]\n",
      "Val Loss Meta Info:  [56753.27, 1653.9040625]\n",
      "\n",
      "Epoch: 114, NLL Loss: 1460.7323046875, Val Loss: 58407.359375, Time took: 0.40410876274108887\n",
      "Train loss Meta Info:  [1418.59287891   42.13942328]\n",
      "Val Loss Meta Info:  [56753.16, 1654.19859375]\n",
      "\n",
      "Epoch: 115, NLL Loss: 1460.72181640625, Val Loss: 58404.171875, Time took: 0.4007394313812256\n",
      "Train loss Meta Info:  [1418.58896484   42.13285242]\n",
      "Val Loss Meta Info:  [56752.37, 1651.80734375]\n",
      "\n",
      "Epoch: 116, NLL Loss: 1460.6610390625, Val Loss: 58404.87890625, Time took: 0.40949296951293945\n",
      "Train loss Meta Info:  [1418.56970703   42.09133789]\n",
      "Val Loss Meta Info:  [56753.32, 1651.560625]\n",
      "\n",
      "Epoch: 117, NLL Loss: 1460.687890625, Val Loss: 58408.1875, Time took: 0.40432095527648926\n",
      "Train loss Meta Info:  [1418.59180078   42.09608722]\n",
      "Val Loss Meta Info:  [56752.575, 1655.6153125]\n",
      "\n",
      "Epoch: 118, NLL Loss: 1460.71471875, Val Loss: 58403.96875, Time took: 0.4142324924468994\n",
      "Train loss Meta Info:  [1418.56689453   42.14780548]\n",
      "Val Loss Meta Info:  [56753.38, 1650.5896875]\n",
      "\n",
      "Epoch: 119, NLL Loss: 1460.61884375, Val Loss: 58403.3671875, Time took: 0.40454554557800293\n",
      "Train loss Meta Info:  [1418.58394531   42.03491516]\n",
      "Val Loss Meta Info:  [56752.87, 1650.499375]\n",
      "\n",
      "Epoch: 120, NLL Loss: 1460.60832421875, Val Loss: 58408.140625, Time took: 0.4045145511627197\n",
      "Train loss Meta Info:  [1418.57184766   42.03648145]\n",
      "Val Loss Meta Info:  [56752.695, 1655.446875]\n",
      "\n",
      "Epoch: 121, NLL Loss: 1460.70134765625, Val Loss: 58402.21875, Time took: 0.40561985969543457\n",
      "Train loss Meta Info:  [1418.56902344   42.13231769]\n",
      "Val Loss Meta Info:  [56753.1, 1649.1225]\n",
      "\n",
      "Epoch: 122, NLL Loss: 1460.5884921875, Val Loss: 58398.60546875, Time took: 0.4077904224395752\n",
      "Train loss Meta Info:  [1418.58067578   42.0078136 ]\n",
      "Val Loss Meta Info:  [56752.495, 1646.1096875]\n",
      "\n",
      "Epoch: 123, NLL Loss: 1460.49025390625, Val Loss: 58400.8828125, Time took: 0.402843713760376\n",
      "Train loss Meta Info:  [1418.56397266   41.92628455]\n",
      "Val Loss Meta Info:  [56753.16, 1647.726875]\n",
      "\n",
      "Epoch: 124, NLL Loss: 1460.53696484375, Val Loss: 58404.65234375, Time took: 0.40528059005737305\n",
      "Train loss Meta Info:  [1418.57882422   41.95812854]\n",
      "Val Loss Meta Info:  [56752.46, 1652.1965625]\n",
      "\n",
      "Epoch: 125, NLL Loss: 1460.65491796875, Val Loss: 58418.3828125, Time took: 0.4009718894958496\n",
      "Train loss Meta Info:  [1418.56242578   42.09249689]\n",
      "Val Loss Meta Info:  [56752.675, 1665.711875]\n",
      "\n",
      "Epoch: 126, NLL Loss: 1460.93514453125, Val Loss: 58403.7421875, Time took: 0.4007833003997803\n",
      "Train loss Meta Info:  [1418.56625781   42.36888751]\n",
      "Val Loss Meta Info:  [56752.765, 1650.9790625]\n",
      "\n",
      "Epoch: 127, NLL Loss: 1460.5693359375, Val Loss: 58410.96875, Time took: 0.4033222198486328\n",
      "Train loss Meta Info:  [1418.56608594   42.00324176]\n",
      "Val Loss Meta Info:  [56752.785, 1658.18328125]\n",
      "\n",
      "Epoch: 128, NLL Loss: 1460.7633359375, Val Loss: 58403.87890625, Time took: 0.40638065338134766\n",
      "Train loss Meta Info:  [1418.56483984   42.19849371]\n",
      "Val Loss Meta Info:  [56752.935, 1650.94421875]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129, NLL Loss: 1460.5615625, Val Loss: 58410.0546875, Time took: 0.4033043384552002\n",
      "Train loss Meta Info:  [1418.56865625   41.9929093 ]\n",
      "Val Loss Meta Info:  [56752.14, 1657.9140625]\n",
      "\n",
      "Epoch: 130, NLL Loss: 1460.70139453125, Val Loss: 58403.59765625, Time took: 0.4032909870147705\n",
      "Train loss Meta Info:  [1418.55162891   42.14977258]\n",
      "Val Loss Meta Info:  [56752.97, 1650.63078125]\n",
      "\n",
      "Epoch: 131, NLL Loss: 1460.5576328125, Val Loss: 58407.015625, Time took: 0.405057430267334\n",
      "Train loss Meta Info:  [1418.57099219   41.98663635]\n",
      "Val Loss Meta Info:  [56752.36, 1654.6565625]\n",
      "\n",
      "Epoch: 132, NLL Loss: 1460.6497578125, Val Loss: 58402.7578125, Time took: 0.39972686767578125\n",
      "Train loss Meta Info:  [1418.55222266   42.09753125]\n",
      "Val Loss Meta Info:  [56753.15, 1649.6115625]\n",
      "\n",
      "Epoch: 133, NLL Loss: 1460.50901953125, Val Loss: 58405.6328125, Time took: 0.40331006050109863\n",
      "Train loss Meta Info:  [1418.56961719   41.93940228]\n",
      "Val Loss Meta Info:  [56752.595, 1653.04]\n",
      "\n",
      "Epoch: 134, NLL Loss: 1460.56540234375, Val Loss: 58401.09375, Time took: 0.40266847610473633\n",
      "Train loss Meta Info:  [1418.55594922   42.00945685]\n",
      "Val Loss Meta Info:  [56753.07, 1648.02375]\n",
      "\n",
      "Epoch: 135, NLL Loss: 1460.45540234375, Val Loss: 58401.0703125, Time took: 0.40836191177368164\n",
      "Train loss Meta Info:  [1418.56699219   41.88840674]\n",
      "Val Loss Meta Info:  [56752.885, 1648.18625]\n",
      "\n",
      "Epoch: 136, NLL Loss: 1460.46312890625, Val Loss: 58399.41796875, Time took: 0.40254950523376465\n",
      "Train loss Meta Info:  [1418.56026953   41.90284943]\n",
      "Val Loss Meta Info:  [56753.02, 1646.4]\n",
      "\n",
      "Epoch: 137, NLL Loss: 1460.4122890625, Val Loss: 58396.0078125, Time took: 0.40294885635375977\n",
      "Train loss Meta Info:  [1418.56256641   41.84972418]\n",
      "Val Loss Meta Info:  [56752.675, 1643.33546875]\n",
      "\n",
      "Epoch: 138, NLL Loss: 1460.3553828125, Val Loss: 58393.97265625, Time took: 0.40476393699645996\n",
      "Train loss Meta Info:  [1418.55370313   41.80168152]\n",
      "Val Loss Meta Info:  [56752.48, 1641.49296875]\n",
      "\n",
      "Epoch: 139, NLL Loss: 1460.30448828125, Val Loss: 58397.46484375, Time took: 0.4011838436126709\n",
      "Train loss Meta Info:  [1418.55057812   41.75391699]\n",
      "Val Loss Meta Info:  [56752.61, 1644.8528125]\n",
      "\n",
      "Epoch: 140, NLL Loss: 1460.37402734375, Val Loss: 58401.9140625, Time took: 0.4002501964569092\n",
      "Train loss Meta Info:  [1418.55381641   41.82021069]\n",
      "Val Loss Meta Info:  [56752.49, 1649.4246875]\n",
      "\n",
      "Epoch: 141, NLL Loss: 1460.5041796875, Val Loss: 58397.4375, Time took: 0.40372419357299805\n",
      "Train loss Meta Info:  [1418.54562109   41.95855554]\n",
      "Val Loss Meta Info:  [56753.005, 1644.43390625]\n",
      "\n",
      "Epoch: 142, NLL Loss: 1460.34867578125, Val Loss: 58400.734375, Time took: 0.40667152404785156\n",
      "Train loss Meta Info:  [1418.55887891   41.78980444]\n",
      "Val Loss Meta Info:  [56752.56, 1648.17296875]\n",
      "\n",
      "Epoch: 143, NLL Loss: 1460.41152734375, Val Loss: 58396.97265625, Time took: 0.4036865234375\n",
      "Train loss Meta Info:  [1418.54686719   41.86465515]\n",
      "Val Loss Meta Info:  [56752.95, 1644.02375]\n",
      "\n",
      "Epoch: 144, NLL Loss: 1460.32786328125, Val Loss: 58392.59765625, Time took: 0.4036068916320801\n",
      "Train loss Meta Info:  [1418.55239453   41.77545984]\n",
      "Val Loss Meta Info:  [56752.74, 1639.8609375]\n",
      "\n",
      "Epoch: 145, NLL Loss: 1460.227796875, Val Loss: 58404.453125, Time took: 0.40596747398376465\n",
      "Train loss Meta Info:  [1418.54639453   41.68140631]\n",
      "Val Loss Meta Info:  [56752.66, 1651.7940625]\n",
      "\n",
      "Epoch: 146, NLL Loss: 1460.52856640625, Val Loss: 58395.64453125, Time took: 0.4132723808288574\n",
      "Train loss Meta Info:  [1418.54629688   41.98226611]\n",
      "Val Loss Meta Info:  [56752.695, 1642.9521875]\n",
      "\n",
      "Epoch: 147, NLL Loss: 1460.36787109375, Val Loss: 58392.1484375, Time took: 0.40642333030700684\n",
      "Train loss Meta Info:  [1418.54661328   41.8212818 ]\n",
      "Val Loss Meta Info:  [56752.425, 1639.72375]\n",
      "\n",
      "Epoch: 148, NLL Loss: 1460.25084765625, Val Loss: 58389.19921875, Time took: 0.40251827239990234\n",
      "Train loss Meta Info:  [1418.54200391   41.70884326]\n",
      "Val Loss Meta Info:  [56752.57, 1636.6290625]\n",
      "\n",
      "Epoch: 149, NLL Loss: 1460.16830859375, Val Loss: 58398.8671875, Time took: 0.4048182964324951\n",
      "Train loss Meta Info:  [1418.54555078   41.62275586]\n",
      "Val Loss Meta Info:  [56752.575, 1646.29640625]\n",
      "\n",
      "Epoch: 150, NLL Loss: 1460.4177109375, Val Loss: 58440.1171875, Time took: 0.40232372283935547\n",
      "Train loss Meta Info:  [1418.54386719   41.87384625]\n",
      "Val Loss Meta Info:  [56753.01, 1687.110625]\n",
      "\n",
      "Epoch: 151, NLL Loss: 1461.35738671875, Val Loss: 58398.6796875, Time took: 0.4052879810333252\n",
      "Train loss Meta Info:  [1418.55193359   42.80546027]\n",
      "Val Loss Meta Info:  [56753.095, 1645.58625]\n",
      "\n",
      "Epoch: 152, NLL Loss: 1460.31848828125, Val Loss: 58427.8828125, Time took: 0.41338253021240234\n",
      "Train loss Meta Info:  [1418.54632812   41.77215649]\n",
      "Val Loss Meta Info:  [56753.29, 1674.5946875]\n",
      "\n",
      "Epoch: 153, NLL Loss: 1461.07763671875, Val Loss: 58397.97265625, Time took: 0.4119391441345215\n",
      "Train loss Meta Info:  [1418.54913281   42.52849127]\n",
      "Val Loss Meta Info:  [56752.865, 1645.110625]\n",
      "\n",
      "Epoch: 154, NLL Loss: 1460.37694140625, Val Loss: 58419.1328125, Time took: 0.4065279960632324\n",
      "Train loss Meta Info:  [1418.54340234   41.83353589]\n",
      "Val Loss Meta Info:  [56752.515, 1666.61953125]\n",
      "\n",
      "Epoch: 155, NLL Loss: 1460.900265625, Val Loss: 58400.859375, Time took: 0.40824151039123535\n",
      "Train loss Meta Info:  [1418.53850781   42.36174402]\n",
      "Val Loss Meta Info:  [56752.84, 1648.0221875]\n",
      "\n",
      "Epoch: 156, NLL Loss: 1460.44975390625, Val Loss: 58410.37890625, Time took: 0.41169071197509766\n",
      "Train loss Meta Info:  [1418.54318359   41.90656213]\n",
      "Val Loss Meta Info:  [56752.68, 1657.70015625]\n",
      "\n",
      "Epoch: 157, NLL Loss: 1460.67987109375, Val Loss: 58405.15234375, Time took: 0.4087643623352051\n",
      "Train loss Meta Info:  [1418.53294922   42.14691626]\n",
      "Val Loss Meta Info:  [56753.14, 1652.0153125]\n",
      "\n",
      "Epoch: 158, NLL Loss: 1460.52284375, Val Loss: 58403.89453125, Time took: 0.39708399772644043\n",
      "Train loss Meta Info:  [1418.54103516   41.98181543]\n",
      "Val Loss Meta Info:  [56752.78, 1651.11484375]\n",
      "\n",
      "Epoch: 159, NLL Loss: 1460.47024609375, Val Loss: 58408.7578125, Time took: 0.40008997917175293\n",
      "Train loss Meta Info:  [1418.530375     41.93986725]\n",
      "Val Loss Meta Info:  [56753.2, 1655.5596875]\n",
      "\n",
      "Epoch: 160, NLL Loss: 1460.59883984375, Val Loss: 58398.796875, Time took: 0.39702677726745605\n",
      "Train loss Meta Info:  [1418.53646094   42.06237592]\n",
      "Val Loss Meta Info:  [56753.17, 1645.6309375]\n",
      "\n",
      "Epoch: 161, NLL Loss: 1460.36269921875, Val Loss: 58406.93359375, Time took: 0.3939859867095947\n",
      "Train loss Meta Info:  [1418.53028516   41.83239874]\n",
      "Val Loss Meta Info:  [56753.24, 1653.6940625]\n",
      "\n",
      "Epoch: 162, NLL Loss: 1460.56712109375, Val Loss: 58397.875, Time took: 0.3966693878173828\n",
      "Train loss Meta Info:  [1418.53060938   42.03650726]\n",
      "Val Loss Meta Info:  [56753.13, 1644.7434375]\n",
      "\n",
      "Epoch: 163, NLL Loss: 1460.3329140625, Val Loss: 58402.16015625, Time took: 0.401017427444458\n",
      "Train loss Meta Info:  [1418.52840625   41.80449683]\n",
      "Val Loss Meta Info:  [56752.91, 1649.251875]\n",
      "\n",
      "Epoch: 164, NLL Loss: 1460.424828125, Val Loss: 58401.015625, Time took: 0.39724063873291016\n",
      "Train loss Meta Info:  [1418.52490625   41.89992621]\n",
      "Val Loss Meta Info:  [56753.08, 1647.934375]\n",
      "\n",
      "Epoch: 165, NLL Loss: 1460.3860546875, Val Loss: 58398.55859375, Time took: 0.39714884757995605\n",
      "Train loss Meta Info:  [1418.52779297   41.8582699 ]\n",
      "Val Loss Meta Info:  [56753.04, 1645.5175]\n",
      "\n",
      "Epoch: 166, NLL Loss: 1460.3352109375, Val Loss: 58400.0390625, Time took: 0.3997180461883545\n",
      "Train loss Meta Info:  [1418.52186719   41.8133493 ]\n",
      "Val Loss Meta Info:  [56753.325, 1646.715]\n",
      "\n",
      "Epoch: 167, NLL Loss: 1460.37255859375, Val Loss: 58395.76953125, Time took: 0.3961482048034668\n",
      "Train loss Meta Info:  [1418.52455078   41.84800244]\n",
      "Val Loss Meta Info:  [56753.27, 1642.501875]\n",
      "\n",
      "Epoch: 168, NLL Loss: 1460.253734375, Val Loss: 58399.421875, Time took: 0.3966398239135742\n",
      "Train loss Meta Info:  [1418.51906641   41.73466479]\n",
      "Val Loss Meta Info:  [56753.59, 1645.835625]\n",
      "\n",
      "Epoch: 169, NLL Loss: 1460.3329296875, Val Loss: 58395.296875, Time took: 0.39650774002075195\n",
      "Train loss Meta Info:  [1418.52338672   41.8095293 ]\n",
      "Val Loss Meta Info:  [56753.56, 1641.73921875]\n",
      "\n",
      "Epoch: 170, NLL Loss: 1460.2166640625, Val Loss: 58398.69921875, Time took: 0.4009053707122803\n",
      "Train loss Meta Info:  [1418.51865625   41.6980036 ]\n",
      "Val Loss Meta Info:  [56753.74, 1644.9625]\n",
      "\n",
      "Epoch: 171, NLL Loss: 1460.2808828125, Val Loss: 58395.4453125, Time took: 0.3974423408508301\n",
      "Train loss Meta Info:  [1418.52244141   41.75843774]\n",
      "Val Loss Meta Info:  [56753.525, 1641.9203125]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172, NLL Loss: 1460.18748046875, Val Loss: 58396.890625, Time took: 0.3963608741760254\n",
      "Train loss Meta Info:  [1418.51701953   41.67045551]\n",
      "Val Loss Meta Info:  [56753.52, 1643.37125]\n",
      "\n",
      "Epoch: 173, NLL Loss: 1460.223515625, Val Loss: 58393.203125, Time took: 0.40113067626953125\n",
      "Train loss Meta Info:  [1418.51868359   41.70482874]\n",
      "Val Loss Meta Info:  [56753.305, 1639.90125]\n",
      "\n",
      "Epoch: 174, NLL Loss: 1460.143515625, Val Loss: 58394.35546875, Time took: 0.3968985080718994\n",
      "Train loss Meta Info:  [1418.51455469   41.62895648]\n",
      "Val Loss Meta Info:  [56753.42, 1640.93640625]\n",
      "\n",
      "Epoch: 175, NLL Loss: 1460.1832109375, Val Loss: 58391.859375, Time took: 0.3946223258972168\n",
      "Train loss Meta Info:  [1418.51785937   41.6653559 ]\n",
      "Val Loss Meta Info:  [56753.275, 1638.58484375]\n",
      "\n",
      "Epoch: 176, NLL Loss: 1460.120875, Val Loss: 58392.75, Time took: 0.39504551887512207\n",
      "Train loss Meta Info:  [1418.51363672   41.60724707]\n",
      "Val Loss Meta Info:  [56753.43, 1639.321875]\n",
      "\n",
      "Epoch: 177, NLL Loss: 1460.13308984375, Val Loss: 58391.97265625, Time took: 0.4017031192779541\n",
      "Train loss Meta Info:  [1418.51580078   41.61728497]\n",
      "Val Loss Meta Info:  [56753.5, 1638.4746875]\n",
      "\n",
      "Epoch: 178, NLL Loss: 1460.09940625, Val Loss: 58392.75, Time took: 0.40187692642211914\n",
      "Train loss Meta Info:  [1418.51429297   41.58510364]\n",
      "Val Loss Meta Info:  [56753.68, 1639.0678125]\n",
      "\n",
      "Epoch: 179, NLL Loss: 1460.09741015625, Val Loss: 58392.46484375, Time took: 0.39795899391174316\n",
      "Train loss Meta Info:  [1418.51485938   41.58253729]\n",
      "Val Loss Meta Info:  [56753.66, 1638.8053125]\n",
      "\n",
      "Epoch: 180, NLL Loss: 1460.075765625, Val Loss: 58391.85546875, Time took: 0.4036719799041748\n",
      "Train loss Meta Info:  [1418.51096875   41.56480402]\n",
      "Val Loss Meta Info:  [56753.83, 1638.023125]\n",
      "\n",
      "Epoch: 181, NLL Loss: 1460.06021875, Val Loss: 58391.21875, Time took: 0.3974785804748535\n",
      "Train loss Meta Info:  [1418.51257031   41.54764191]\n",
      "Val Loss Meta Info:  [56753.825, 1637.396875]\n",
      "\n",
      "Epoch: 182, NLL Loss: 1460.04762890625, Val Loss: 58389.046875, Time took: 0.3965017795562744\n",
      "Train loss Meta Info:  [1418.51051172   41.53710577]\n",
      "Val Loss Meta Info:  [56753.695, 1635.3534375]\n",
      "\n",
      "Epoch: 183, NLL Loss: 1460.00513671875, Val Loss: 58387.859375, Time took: 0.3957340717315674\n",
      "Train loss Meta Info:  [1418.50699219   41.49814972]\n",
      "Val Loss Meta Info:  [56753.645, 1634.214375]\n",
      "\n",
      "Epoch: 184, NLL Loss: 1459.9769296875, Val Loss: 58388.390625, Time took: 0.4004840850830078\n",
      "Train loss Meta Info:  [1418.50670703   41.47023364]\n",
      "Val Loss Meta Info:  [56753.75, 1634.6409375]\n",
      "\n",
      "Epoch: 185, NLL Loss: 1459.98711328125, Val Loss: 58387.55859375, Time took: 0.39745473861694336\n",
      "Train loss Meta Info:  [1418.50898047   41.47814014]\n",
      "Val Loss Meta Info:  [56753.81, 1633.7509375]\n",
      "\n",
      "Epoch: 186, NLL Loss: 1459.95878515625, Val Loss: 58386.109375, Time took: 0.39801526069641113\n",
      "Train loss Meta Info:  [1418.50831641   41.45045557]\n",
      "Val Loss Meta Info:  [56754.16, 1631.951875]\n",
      "\n",
      "Epoch: 187, NLL Loss: 1459.92348828125, Val Loss: 58394.5390625, Time took: 0.4013504981994629\n",
      "Train loss Meta Info:  [1418.51439453   41.40909729]\n",
      "Val Loss Meta Info:  [56754.345, 1640.19359375]\n",
      "\n",
      "Epoch: 188, NLL Loss: 1460.13721875, Val Loss: 58397.25, Time took: 0.39692020416259766\n",
      "Train loss Meta Info:  [1418.51761719   41.61959473]\n",
      "Val Loss Meta Info:  [56754.27, 1642.9775]\n",
      "\n",
      "Epoch: 189, NLL Loss: 1460.17548046875, Val Loss: 58390.390625, Time took: 0.3976247310638428\n",
      "Train loss Meta Info:  [1418.514875    41.6606015]\n",
      "Val Loss Meta Info:  [56754.7, 1635.68953125]\n",
      "\n",
      "Epoch: 190, NLL Loss: 1459.9942734375, Val Loss: 58397.51953125, Time took: 0.40145134925842285\n",
      "Train loss Meta Info:  [1418.52194922   41.47232703]\n",
      "Val Loss Meta Info:  [56754.38, 1643.139375]\n",
      "\n",
      "Epoch: 191, NLL Loss: 1460.1605234375, Val Loss: 58388.140625, Time took: 0.4036238193511963\n",
      "Train loss Meta Info:  [1418.50991797   41.65060669]\n",
      "Val Loss Meta Info:  [56754.275, 1633.865625]\n",
      "\n",
      "Epoch: 192, NLL Loss: 1459.93394140625, Val Loss: 58398.46484375, Time took: 0.3994593620300293\n",
      "Train loss Meta Info:  [1418.50892578   41.42500098]\n",
      "Val Loss Meta Info:  [56754.08, 1644.38484375]\n",
      "\n",
      "Epoch: 193, NLL Loss: 1460.20112109375, Val Loss: 58390.7578125, Time took: 0.3970651626586914\n",
      "Train loss Meta Info:  [1418.50413672   41.69698126]\n",
      "Val Loss Meta Info:  [56754.07, 1636.68875]\n",
      "\n",
      "Epoch: 194, NLL Loss: 1460.01498046875, Val Loss: 58388.0390625, Time took: 0.4002399444580078\n",
      "Train loss Meta Info:  [1418.50668359   41.50831018]\n",
      "Val Loss Meta Info:  [56754.45, 1633.58875]\n",
      "\n",
      "Epoch: 195, NLL Loss: 1459.932375, Val Loss: 58389.82421875, Time took: 0.3964884281158447\n",
      "Train loss Meta Info:  [1418.51226953   41.42009735]\n",
      "Val Loss Meta Info:  [56754.08, 1635.746875]\n",
      "\n",
      "Epoch: 196, NLL Loss: 1459.96583203125, Val Loss: 58394.609375, Time took: 0.39530348777770996\n",
      "Train loss Meta Info:  [1418.50029688   41.46553674]\n",
      "Val Loss Meta Info:  [56755.43, 1639.1815625]\n",
      "\n",
      "Epoch: 197, NLL Loss: 1460.0832734375, Val Loss: 58388.18359375, Time took: 0.3964664936065674\n",
      "Train loss Meta Info:  [1418.53062109   41.55265594]\n",
      "Val Loss Meta Info:  [56754.33, 1633.85453125]\n",
      "\n",
      "Epoch: 198, NLL Loss: 1459.91285546875, Val Loss: 58392.79296875, Time took: 0.403240442276001\n",
      "Train loss Meta Info:  [1418.49855469   41.41429987]\n",
      "Val Loss Meta Info:  [56755.29, 1637.5059375]\n",
      "\n",
      "Epoch: 199, NLL Loss: 1460.0166171875, Val Loss: 58393.18359375, Time took: 0.39882612228393555\n",
      "Train loss Meta Info:  [1418.518125     41.49848956]\n",
      "Val Loss Meta Info:  [56754.55, 1638.63625]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=RMTPP, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRMTPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([50, 8000, 2]), Val Data Shape: torch.Size([50, 2000, 2])\n",
      "Markers: Data Shape: torch.Size([50, 8000, 20]), Val Data Shape: torch.Size([50, 2000, 20])\n",
      "Epoch: 0, NLL Loss: 1601.81908203125, Val Loss: 65660.7734375, Time took: 0.7150976657867432\n",
      "Train loss Meta Info:  [1.50098243e+03 1.00836648e+02 1.12166088e+00]\n",
      "Val Loss Meta Info:  [59089.05, 5400.19125, 117.153671875]\n",
      "\n",
      "Epoch: 1, NLL Loss: 1613.85015625, Val Loss: 64006.0390625, Time took: 0.7133045196533203\n",
      "Train loss Meta Info:  [1477.14755469  136.67326685    2.93572713]\n",
      "Val Loss Meta Info:  [58174.6, 4771.4565625, 105.99826171875]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1574.10191015625, Val Loss: 63836.109375, Time took: 0.7147996425628662\n",
      "Train loss Meta Info:  [1453.75442969  120.29441895    2.65282704]\n",
      "Val Loss Meta Info:  [57909.82, 4607.50375, 131.87875]\n",
      "\n",
      "Epoch: 3, NLL Loss: 1563.68284375, Val Loss: 63628.61328125, Time took: 0.7186882495880127\n",
      "Train loss Meta Info:  [1447.41490234  116.16899927    3.29799633]\n",
      "Val Loss Meta Info:  [57267.0, 3744.015, 261.7599609375]\n",
      "\n",
      "Epoch: 4, NLL Loss: 1526.30233984375, Val Loss: 66482.09375, Time took: 0.7216272354125977\n",
      "Train loss Meta Info:  [1431.51901172   94.52150635    6.54597427]\n",
      "Val Loss Meta Info:  [57176.99, 3115.7353125, 618.937109375]\n",
      "\n",
      "Epoch: 5, NLL Loss: 1509.09766796875, Val Loss: 68738.453125, Time took: 0.7244253158569336\n",
      "Train loss Meta Info:  [1429.29794141   79.02594031   15.47602481]\n",
      "Val Loss Meta Info:  [57000.53, 3370.313125, 836.761015625]\n",
      "\n",
      "Epoch: 6, NLL Loss: 1511.67085546875, Val Loss: 66540.6171875, Time took: 0.7457931041717529\n",
      "Train loss Meta Info:  [1424.79978516   85.61534827   20.92855273]\n",
      "Val Loss Meta Info:  [56953.565, 3068.1096875, 651.894296875]\n",
      "\n",
      "Epoch: 7, NLL Loss: 1502.80141015625, Val Loss: 64566.0703125, Time took: 0.7401285171508789\n",
      "Train loss Meta Info:  [1423.65779297   78.00232678   16.30433636]\n",
      "Val Loss Meta Info:  [56933.1, 3034.5590625, 459.84078125]\n",
      "\n",
      "Epoch: 8, NLL Loss: 1501.1282109375, Val Loss: 63925.1875, Time took: 0.7245101928710938\n",
      "Train loss Meta Info:  [1423.15696094   77.05167773   11.49448331]\n",
      "Val Loss Meta Info:  [56933.665, 3091.776875, 389.974765625]\n",
      "\n",
      "Epoch: 9, NLL Loss: 1502.47015234375, Val Loss: 63160.125, Time took: 0.7179994583129883\n",
      "Train loss Meta Info:  [1423.18148438   78.41047571    9.75766377]\n",
      "Val Loss Meta Info:  [56914.235, 3066.72125, 317.91681640625]\n",
      "\n",
      "Epoch: 10, NLL Loss: 1501.22834375, Val Loss: 62772.78515625, Time took: 0.7178065776824951\n",
      "Train loss Meta Info:  [1422.65629687   77.77675171    7.95299397]\n",
      "Val Loss Meta Info:  [56886.025, 3006.236875, 288.0526953125]\n",
      "\n",
      "Epoch: 11, NLL Loss: 1499.0611484375, Val Loss: 62393.2734375, Time took: 0.727527379989624\n",
      "Train loss Meta Info:  [1421.93270312   76.33558557    7.20794305]\n",
      "Val Loss Meta Info:  [56866.83, 2948.3771875, 257.8069140625]\n",
      "\n",
      "Epoch: 12, NLL Loss: 1497.22724609375, Val Loss: 62033.01953125, Time took: 0.7160513401031494\n",
      "Train loss Meta Info:  [1421.50798437   74.94501428    6.45198601]\n",
      "Val Loss Meta Info:  [56855.53, 2933.29625, 224.4194140625]\n",
      "\n",
      "Epoch: 13, NLL Loss: 1496.46571875, Val Loss: 61680.203125, Time took: 0.728989839553833\n",
      "Train loss Meta Info:  [1421.17294531   74.56260657    5.61667973]\n",
      "Val Loss Meta Info:  [56841.41, 2942.553125, 189.62419921875]\n",
      "\n",
      "Epoch: 14, NLL Loss: 1496.30728515625, Val Loss: 61254.82421875, Time took: 0.7202248573303223\n",
      "Train loss Meta Info:  [1420.86807031   74.77483667    4.74558491]\n",
      "Val Loss Meta Info:  [56824.39, 2913.378125, 151.7054296875]\n",
      "\n",
      "Epoch: 15, NLL Loss: 1495.132984375, Val Loss: 60899.52734375, Time took: 0.7250328063964844\n",
      "Train loss Meta Info:  [1420.44099219   74.12253833    3.79624353]\n",
      "Val Loss Meta Info:  [56814.16, 2875.2840625, 121.00875]\n",
      "\n",
      "Epoch: 16, NLL Loss: 1493.8086796875, Val Loss: 60621.33984375, Time took: 0.7169766426086426\n",
      "Train loss Meta Info:  [1420.18041797   73.14384119    3.02762217]\n",
      "Val Loss Meta Info:  [56814.37, 2858.55375, 94.841337890625]\n",
      "\n",
      "Epoch: 17, NLL Loss: 1493.240625, Val Loss: 60421.9453125, Time took: 0.7246701717376709\n",
      "Train loss Meta Info:  [1420.17792188   72.65939587    2.37243484]\n",
      "Val Loss Meta Info:  [56816.775, 2850.3721875, 75.480078125]\n",
      "\n",
      "Epoch: 18, NLL Loss: 1492.92420703125, Val Loss: 60276.23828125, Time took: 0.7267963886260986\n",
      "Train loss Meta Info:  [1420.16356641   72.4208656     1.88768775]\n",
      "Val Loss Meta Info:  [56814.4, 2836.6928125, 62.514306640625]\n",
      "\n",
      "Epoch: 19, NLL Loss: 1492.4820390625, Val Loss: 60160.63671875, Time took: 0.7146949768066406\n",
      "Train loss Meta Info:  [1420.12994922   72.05508643    1.56315786]\n",
      "Val Loss Meta Info:  [56807.375, 2812.3859375, 54.08798828125]\n",
      "\n",
      "Epoch: 20, NLL Loss: 1491.80055078125, Val Loss: 60072.3125, Time took: 0.7266414165496826\n",
      "Train loss Meta Info:  [1.42002431e+03 7.15057603e+01 1.35228551e+00]\n",
      "Val Loss Meta Info:  [56802.34, 2788.8715625, 48.1106640625]\n",
      "\n",
      "Epoch: 21, NLL Loss: 1491.0087421875, Val Loss: 59998.19921875, Time took: 0.7151949405670166\n",
      "Train loss Meta Info:  [1.41987584e+03 7.08803517e+01 1.20262576e+00]\n",
      "Val Loss Meta Info:  [56795.91, 2769.69375, 43.2592822265625]\n",
      "\n",
      "Epoch: 22, NLL Loss: 1490.379875, Val Loss: 59945.8203125, Time took: 0.717585563659668\n",
      "Train loss Meta Info:  [1.41969464e+03 7.04474238e+01 1.08105550e+00]\n",
      "Val Loss Meta Info:  [56790.53, 2762.4084375, 39.288154296875]\n",
      "\n",
      "Epoch: 23, NLL Loss: 1490.10319921875, Val Loss: 59865.54296875, Time took: 0.7455699443817139\n",
      "Train loss Meta Info:  [1.41957899e+03 7.02984761e+01 9.81457146e-01]\n",
      "Val Loss Meta Info:  [56789.115, 2734.659375, 34.1767626953125]\n",
      "\n",
      "Epoch: 24, NLL Loss: 1489.317890625, Val Loss: 59808.30859375, Time took: 0.7770767211914062\n",
      "Train loss Meta Info:  [1.41955635e+03 6.95566823e+01 8.53587185e-01]\n",
      "Val Loss Meta Info:  [56787.725, 2719.3575, 30.1230908203125]\n",
      "\n",
      "Epoch: 25, NLL Loss: 1488.83733203125, Val Loss: 59756.5390625, Time took: 0.7668428421020508\n",
      "Train loss Meta Info:  [1.41951182e+03 6.91374767e+01 7.52100973e-01]\n",
      "Val Loss Meta Info:  [56787.32, 2701.9959375, 26.72261962890625]\n",
      "\n",
      "Epoch: 26, NLL Loss: 1488.36310546875, Val Loss: 59704.15234375, Time took: 0.7442185878753662\n",
      "Train loss Meta Info:  [1.41947285e+03 6.87168451e+01 6.66997726e-01]\n",
      "Val Loss Meta Info:  [56782.4, 2685.236875, 23.65205322265625]\n",
      "\n",
      "Epoch: 27, NLL Loss: 1487.8245234375, Val Loss: 59651.35546875, Time took: 0.7417206764221191\n",
      "Train loss Meta Info:  [1.41937951e+03 6.82856746e+01 5.90145679e-01]\n",
      "Val Loss Meta Info:  [56776.86, 2666.131875, 20.83638671875]\n",
      "\n",
      "Epoch: 28, NLL Loss: 1487.20146875, Val Loss: 59608.796875, Time took: 0.744483232498169\n",
      "Train loss Meta Info:  [1.41924494e+03 6.78110177e+01 5.19667144e-01]\n",
      "Val Loss Meta Info:  [56776.81, 2651.32125, 18.066861572265626]\n",
      "\n",
      "Epoch: 29, NLL Loss: 1486.777265625, Val Loss: 59568.6171875, Time took: 0.7503302097320557\n",
      "Train loss Meta Info:  [1.41921009e+03 6.74365829e+01 4.50312957e-01]\n",
      "Val Loss Meta Info:  [56772.575, 2634.6796875, 16.1363720703125]\n",
      "\n",
      "Epoch: 30, NLL Loss: 1486.22605859375, Val Loss: 59532.10546875, Time took: 0.7345705032348633\n",
      "Train loss Meta Info:  [1.41909330e+03 6.70121176e+01 4.02092196e-01]\n",
      "Val Loss Meta Info:  [56772.56, 2618.626875, 14.09184814453125]\n",
      "\n",
      "Epoch: 31, NLL Loss: 1485.8629296875, Val Loss: 59496.79296875, Time took: 0.7342796325683594\n",
      "Train loss Meta Info:  [1.41914729e+03 6.66068715e+01 3.50931678e-01]\n",
      "Val Loss Meta Info:  [56773.23, 2601.6475, 12.191365966796875]\n",
      "\n",
      "Epoch: 32, NLL Loss: 1485.4343125, Val Loss: 59463.80859375, Time took: 0.7618343830108643\n",
      "Train loss Meta Info:  [1.41913479e+03 6.62024546e+01 3.03386936e-01]\n",
      "Val Loss Meta Info:  [56773.02, 2586.06609375, 10.472550048828126]\n",
      "\n",
      "Epoch: 33, NLL Loss: 1485.01791015625, Val Loss: 59430.37890625, Time took: 0.7468478679656982\n",
      "Train loss Meta Info:  [1.41912680e+03 6.58051957e+01 2.60373888e-01]\n",
      "Val Loss Meta Info:  [56772.265, 2568.4021875, 8.9716162109375]\n",
      "\n",
      "Epoch: 34, NLL Loss: 1484.590828125, Val Loss: 59413.54296875, Time took: 0.7433037757873535\n",
      "Train loss Meta Info:  [1.41911684e+03 6.53982166e+01 2.22824783e-01]\n",
      "Val Loss Meta Info:  [56772.15, 2566.660625, 7.473404541015625]\n",
      "\n",
      "Epoch: 35, NLL Loss: 1484.51375390625, Val Loss: 59384.578125, Time took: 0.7547447681427002\n",
      "Train loss Meta Info:  [1.41907673e+03 6.53721833e+01 1.85253324e-01]\n",
      "Val Loss Meta Info:  [56770.655, 2547.86234375, 6.606524658203125]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, NLL Loss: 1483.97135546875, Val Loss: 59359.9921875, Time took: 0.7569100856781006\n",
      "Train loss Meta Info:  [1.41903935e+03 6.48731423e+01 1.63507867e-01]\n",
      "Val Loss Meta Info:  [56768.84, 2532.1459375, 5.901016845703125]\n",
      "\n",
      "Epoch: 37, NLL Loss: 1483.5619921875, Val Loss: 59339.078125, Time took: 0.7597320079803467\n",
      "Train loss Meta Info:  [1.41904129e+03 6.44667440e+01 1.45860201e-01]\n",
      "Val Loss Meta Info:  [56765.74, 2519.2709375, 5.407215576171875]\n",
      "\n",
      "Epoch: 38, NLL Loss: 1483.1693828125, Val Loss: 59321.5625, Time took: 0.7438199520111084\n",
      "Train loss Meta Info:  [1.41898652e+03 6.41320876e+01 1.33566773e-01]\n",
      "Val Loss Meta Info:  [56766.64, 2504.28, 5.064647216796875]\n",
      "\n",
      "Epoch: 39, NLL Loss: 1482.76603125, Val Loss: 59303.96875, Time took: 0.7451727390289307\n",
      "Train loss Meta Info:  [1.41896883e+03 6.37483879e+01 1.25161936e-01]\n",
      "Val Loss Meta Info:  [56766.505, 2489.6221875, 4.784716491699219]\n",
      "\n",
      "Epoch: 40, NLL Loss: 1482.3961328125, Val Loss: 59287.19921875, Time took: 0.7389070987701416\n",
      "Train loss Meta Info:  [1.41897361e+03 6.33752048e+01 1.18276150e-01]\n",
      "Val Loss Meta Info:  [56765.1, 2476.854375, 4.5246337890625]\n",
      "\n",
      "Epoch: 41, NLL Loss: 1482.03224609375, Val Loss: 59269.98046875, Time took: 0.7400531768798828\n",
      "Train loss Meta Info:  [1.41894224e+03 6.30441968e+01 1.11710398e-01]\n",
      "Val Loss Meta Info:  [56764.94, 2462.4178125, 4.262141723632812]\n",
      "\n",
      "Epoch: 42, NLL Loss: 1481.656890625, Val Loss: 59255.6171875, Time took: 0.7347960472106934\n",
      "Train loss Meta Info:  [1.41891964e+03 6.26930844e+01 1.05142400e-01]\n",
      "Val Loss Meta Info:  [56765.24, 2448.80296875, 4.15771240234375]\n",
      "\n",
      "Epoch: 43, NLL Loss: 1481.3086953125, Val Loss: 59233.171875, Time took: 0.777130126953125\n",
      "Train loss Meta Info:  [1.41890523e+03 6.23593599e+01 1.02544338e-01]\n",
      "Val Loss Meta Info:  [56763.205, 2431.39625, 3.8575128173828124]\n",
      "\n",
      "Epoch: 44, NLL Loss: 1480.8736640625, Val Loss: 59219.5625, Time took: 0.7562921047210693\n",
      "Train loss Meta Info:  [1.41888705e+03 6.19448041e+01 9.50330856e-02]\n",
      "Val Loss Meta Info:  [56763.09, 2420.47328125, 3.60017822265625]\n",
      "\n",
      "Epoch: 45, NLL Loss: 1480.5836015625, Val Loss: 59210.53515625, Time took: 0.7492341995239258\n",
      "Train loss Meta Info:  [1.41889431e+03 6.16494032e+01 8.86798515e-02]\n",
      "Val Loss Meta Info:  [56762.88, 2413.10328125, 3.4550717163085936]\n",
      "\n",
      "Epoch: 46, NLL Loss: 1480.3658046875, Val Loss: 59195.46875, Time took: 0.7604258060455322\n",
      "Train loss Meta Info:  [1.41886487e+03 6.14618110e+01 8.50326604e-02]\n",
      "Val Loss Meta Info:  [56761.3, 2400.085, 3.4083621215820314]\n",
      "\n",
      "Epoch: 47, NLL Loss: 1479.9950546875, Val Loss: 59177.3984375, Time took: 0.7623240947723389\n",
      "Train loss Meta Info:  [1.41882955e+03 6.11260908e+01 8.38407488e-02]\n",
      "Val Loss Meta Info:  [56760.23, 2383.6275, 3.35375]\n",
      "\n",
      "Epoch: 48, NLL Loss: 1479.560296875, Val Loss: 59164.1484375, Time took: 0.796290397644043\n",
      "Train loss Meta Info:  [1.41881740e+03 6.07032905e+01 8.25386622e-02]\n",
      "Val Loss Meta Info:  [56760.83, 2370.9975, 3.2321771240234374]\n",
      "\n",
      "Epoch: 49, NLL Loss: 1479.24848828125, Val Loss: 59149.0703125, Time took: 0.763012170791626\n",
      "Train loss Meta Info:  [1.41882681e+03 6.03827043e+01 7.95472554e-02]\n",
      "Val Loss Meta Info:  [56759.51, 2359.36953125, 3.019089660644531]\n",
      "\n",
      "Epoch: 50, NLL Loss: 1478.94518359375, Val Loss: 59130.90234375, Time took: 0.7306842803955078\n",
      "Train loss Meta Info:  [1.41880945e+03 6.00985789e+01 7.42737178e-02]\n",
      "Val Loss Meta Info:  [56760.04, 2343.7696875, 2.709254150390625]\n",
      "\n",
      "Epoch: 51, NLL Loss: 1478.5785234375, Val Loss: 59110.59765625, Time took: 0.7377355098724365\n",
      "Train loss Meta Info:  [1.41883187e+03 5.97126892e+01 6.66075118e-02]\n",
      "Val Loss Meta Info:  [56759.4, 2327.659375, 2.3540910339355468]\n",
      "\n",
      "Epoch: 52, NLL Loss: 1478.12872265625, Val Loss: 59094.65234375, Time took: 0.7375137805938721\n",
      "Train loss Meta Info:  [1.41878564e+03 5.93129888e+01 5.78252591e-02]\n",
      "Val Loss Meta Info:  [56758.495, 2316.17125, 1.9990579223632812]\n",
      "\n",
      "Epoch: 53, NLL Loss: 1477.79601171875, Val Loss: 59083.76953125, Time took: 0.7526519298553467\n",
      "Train loss Meta Info:  [1.41877141e+03 5.89986378e+01 4.90119545e-02]\n",
      "Val Loss Meta Info:  [56759.42, 2306.884375, 1.7462846374511718]\n",
      "\n",
      "Epoch: 54, NLL Loss: 1477.58583203125, Val Loss: 59068.16015625, Time took: 0.7446503639221191\n",
      "Train loss Meta Info:  [1.41878918e+03 5.87735691e+01 4.27405321e-02]\n",
      "Val Loss Meta Info:  [56759.11, 2292.5628125, 1.648448486328125]\n",
      "\n",
      "Epoch: 55, NLL Loss: 1477.24349609375, Val Loss: 59051.796875, Time took: 0.7531116008758545\n",
      "Train loss Meta Info:  [1.41878848e+03 5.84328169e+01 4.03555393e-02]\n",
      "Val Loss Meta Info:  [56758.43, 2277.24625, 1.6122561645507814]\n",
      "\n",
      "Epoch: 56, NLL Loss: 1476.82437109375, Val Loss: 59042.61328125, Time took: 0.7560069561004639\n",
      "Train loss Meta Info:  [1.41875505e+03 5.80471821e+01 3.95075930e-02]\n",
      "Val Loss Meta Info:  [56758.54, 2266.24765625, 1.7823226928710938]\n",
      "\n",
      "Epoch: 57, NLL Loss: 1476.589484375, Val Loss: 59033.39453125, Time took: 0.746513843536377\n",
      "Train loss Meta Info:  [1.41877783e+03 5.77866162e+01 4.39276587e-02]\n",
      "Val Loss Meta Info:  [56759.415, 2260.4928125, 1.3486148071289064]\n",
      "\n",
      "Epoch: 58, NLL Loss: 1476.40001953125, Val Loss: 59020.83984375, Time took: 0.7445952892303467\n",
      "Train loss Meta Info:  [1.41879176e+03 5.75891077e+01 3.29906746e-02]\n",
      "Val Loss Meta Info:  [56757.67, 2250.64765625, 1.2517969512939453]\n",
      "\n",
      "Epoch: 59, NLL Loss: 1476.1037734375, Val Loss: 59008.3203125, Time took: 0.7733914852142334\n",
      "Train loss Meta Info:  [1.41874376e+03 5.73419784e+01 3.05730658e-02]\n",
      "Val Loss Meta Info:  [56759.425, 2236.933125, 1.1958931732177733]\n",
      "\n",
      "Epoch: 60, NLL Loss: 1475.79456640625, Val Loss: 58989.875, Time took: 0.7398777008056641\n",
      "Train loss Meta Info:  [1.41878605e+03 5.69910203e+01 2.91587462e-02]\n",
      "Val Loss Meta Info:  [56756.58, 2221.1990625, 1.2095045471191406]\n",
      "\n",
      "Epoch: 61, NLL Loss: 1475.3641640625, Val Loss: 58986.30859375, Time took: 0.7342269420623779\n",
      "Train loss Meta Info:  [1.41872275e+03 5.66233502e+01 2.96052551e-02]\n",
      "Val Loss Meta Info:  [56759.4, 2212.76359375, 1.4146133422851563]\n",
      "\n",
      "Epoch: 62, NLL Loss: 1475.23384375, Val Loss: 58964.1875, Time took: 0.7599520683288574\n",
      "Train loss Meta Info:  [1.41879553e+03 5.64168118e+01 3.46950371e-02]\n",
      "Val Loss Meta Info:  [56755.88, 2197.51375, 1.0795801544189454]\n",
      "\n",
      "Epoch: 63, NLL Loss: 1474.73880859375, Val Loss: 58957.60546875, Time took: 0.7379205226898193\n",
      "Train loss Meta Info:  [1.41871327e+03 5.60089727e+01 2.62830180e-02]\n",
      "Val Loss Meta Info:  [56756.94, 2190.4828125, 1.018071060180664]\n",
      "\n",
      "Epoch: 64, NLL Loss: 1474.6062421875, Val Loss: 58944.5, Time took: 0.7318735122680664\n",
      "Train loss Meta Info:  [1.41875562e+03 5.58347926e+01 2.47329676e-02]\n",
      "Val Loss Meta Info:  [56755.73, 2178.9965625, 0.9775811767578125]\n",
      "\n",
      "Epoch: 65, NLL Loss: 1474.2699140625, Val Loss: 58929.78515625, Time took: 0.7489213943481445\n",
      "Train loss Meta Info:  [1.41871115e+03 5.55433284e+01 2.37514561e-02]\n",
      "Val Loss Meta Info:  [56756.04, 2164.23671875, 0.9508495330810547]\n",
      "\n",
      "Epoch: 66, NLL Loss: 1473.8985546875, Val Loss: 58921.359375, Time took: 0.7423994541168213\n",
      "Train loss Meta Info:  [1.41870138e+03 5.51818667e+01 2.31988995e-02]\n",
      "Val Loss Meta Info:  [56756.595, 2155.0734375, 0.9691997528076172]\n",
      "\n",
      "Epoch: 67, NLL Loss: 1473.7128046875, Val Loss: 58906.19921875, Time took: 0.7332763671875\n",
      "Train loss Meta Info:  [1.41871866e+03 5.49782606e+01 2.37002373e-02]\n",
      "Val Loss Meta Info:  [56755.915, 2141.95765625, 0.8325148773193359]\n",
      "\n",
      "Epoch: 68, NLL Loss: 1473.31199609375, Val Loss: 58896.1796875, Time took: 0.7510247230529785\n",
      "Train loss Meta Info:  [1.41870239e+03 5.45957697e+01 2.03356727e-02]\n",
      "Val Loss Meta Info:  [56755.56, 2133.0915625, 0.7529987335205078]\n",
      "\n",
      "Epoch: 69, NLL Loss: 1473.07340234375, Val Loss: 58888.4375, Time took: 0.7421455383300781\n",
      "Train loss Meta Info:  [1.41869320e+03 5.43675771e+01 1.82945962e-02]\n",
      "Val Loss Meta Info:  [56757.28, 2122.9309375, 0.8228854370117188]\n",
      "\n",
      "Epoch: 70, NLL Loss: 1472.87182421875, Val Loss: 58879.94921875, Time took: 0.7479214668273926\n",
      "Train loss Meta Info:  [1.41872437e+03 5.41333842e+01 2.00868699e-02]\n",
      "Val Loss Meta Info:  [56756.83, 2116.84421875, 0.6275577545166016]\n",
      "\n",
      "Epoch: 71, NLL Loss: 1472.689984375, Val Loss: 58862.96484375, Time took: 0.7491638660430908\n",
      "Train loss Meta Info:  [1.41873953e+03 5.39396449e+01 1.52239737e-02]\n",
      "Val Loss Meta Info:  [56755.215, 2101.71203125, 0.6041399383544922]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, NLL Loss: 1472.2817890625, Val Loss: 58857.9296875, Time took: 0.7538714408874512\n",
      "Train loss Meta Info:  [1.41868885e+03 5.35823617e+01 1.46895776e-02]\n",
      "Val Loss Meta Info:  [56755.83, 2095.5475, 0.6551890563964844]\n",
      "\n",
      "Epoch: 73, NLL Loss: 1472.161171875, Val Loss: 58847.69921875, Time took: 0.7594311237335205\n",
      "Train loss Meta Info:  [1.41869821e+03 5.34512360e+01 1.60661631e-02]\n",
      "Val Loss Meta Info:  [56755.175, 2085.93875, 0.6585354614257812]\n",
      "\n",
      "Epoch: 74, NLL Loss: 1471.910546875, Val Loss: 58835.9453125, Time took: 0.7491292953491211\n",
      "Train loss Meta Info:  [1.41868139e+03 5.32170966e+01 1.62826793e-02]\n",
      "Val Loss Meta Info:  [56755.17, 2074.06046875, 0.6716293334960938]\n",
      "\n",
      "Epoch: 75, NLL Loss: 1471.61283984375, Val Loss: 58821.7421875, Time took: 0.7422051429748535\n",
      "Train loss Meta Info:  [1.41868419e+03 5.29161710e+01 1.66402432e-02]\n",
      "Val Loss Meta Info:  [56756.175, 2059.5253125, 0.6045537567138672]\n",
      "\n",
      "Epoch: 76, NLL Loss: 1471.24565234375, Val Loss: 58812.2421875, Time took: 0.7386794090270996\n",
      "Train loss Meta Info:  [1.41870703e+03 5.25272339e+01 1.50029940e-02]\n",
      "Val Loss Meta Info:  [56754.32, 2052.35875, 0.5566693878173828]\n",
      "\n",
      "Epoch: 77, NLL Loss: 1471.000953125, Val Loss: 58802.55859375, Time took: 0.7427654266357422\n",
      "Train loss Meta Info:  [1.41866488e+03 5.23254585e+01 1.37754367e-02]\n",
      "Val Loss Meta Info:  [56756.8, 2039.61484375, 0.61465087890625]\n",
      "\n",
      "Epoch: 78, NLL Loss: 1470.75818359375, Val Loss: 58798.46484375, Time took: 0.7499294281005859\n",
      "Train loss Meta Info:  [1.41872893e+03 5.20174917e+01 1.51033521e-02]\n",
      "Val Loss Meta Info:  [56755.7, 2035.28875, 0.7476428985595703]\n",
      "\n",
      "Epoch: 79, NLL Loss: 1470.64690625, Val Loss: 58787.27734375, Time took: 0.7427034378051758\n",
      "Train loss Meta Info:  [1.41869277e+03 5.19394377e+01 1.86075014e-02]\n",
      "Val Loss Meta Info:  [56756.59, 2025.540625, 0.5149746322631836]\n",
      "\n",
      "Epoch: 80, NLL Loss: 1470.3801171875, Val Loss: 58778.6171875, Time took: 0.7397270202636719\n",
      "Train loss Meta Info:  [1.41872493e+03 5.16450752e+01 1.26575979e-02]\n",
      "Val Loss Meta Info:  [56754.75, 2019.335625, 0.4532563018798828]\n",
      "\n",
      "Epoch: 81, NLL Loss: 1470.15415625, Val Loss: 58763.69921875, Time took: 0.7394225597381592\n",
      "Train loss Meta Info:  [1.41866247e+03 5.14826829e+01 1.11345367e-02]\n",
      "Val Loss Meta Info:  [56755.385, 2004.1484375, 0.4164215087890625]\n",
      "\n",
      "Epoch: 82, NLL Loss: 1469.8223125, Val Loss: 58763.0625, Time took: 0.7432754039764404\n",
      "Train loss Meta Info:  [1.41869986e+03 5.11140167e+01 1.02782187e-02]\n",
      "Val Loss Meta Info:  [56755.03, 2002.2, 0.5836638259887695]\n",
      "\n",
      "Epoch: 83, NLL Loss: 1469.7718515625, Val Loss: 58744.73046875, Time took: 0.7407453060150146\n",
      "Train loss Meta Info:  [1.41866530e+03 5.10945200e+01 1.44894469e-02]\n",
      "Val Loss Meta Info:  [56753.51, 1986.99515625, 0.4222884750366211]\n",
      "\n",
      "Epoch: 84, NLL Loss: 1469.35171484375, Val Loss: 58740.83203125, Time took: 0.7364678382873535\n",
      "Train loss Meta Info:  [1.41865835e+03 5.06845605e+01 1.04843757e-02]\n",
      "Val Loss Meta Info:  [56755.015, 1981.08375, 0.4732526779174805]\n",
      "\n",
      "Epoch: 85, NLL Loss: 1469.22801171875, Val Loss: 58727.2734375, Time took: 0.7386176586151123\n",
      "Train loss Meta Info:  [1.41868562e+03 5.05324407e+01 1.16873963e-02]\n",
      "Val Loss Meta Info:  [56754.225, 1969.8021875, 0.32508651733398436]\n",
      "\n",
      "Epoch: 86, NLL Loss: 1468.9219453125, Val Loss: 58719.23828125, Time took: 0.7330296039581299\n",
      "Train loss Meta Info:  [1.41865001e+03 5.02648654e+01 8.22004823e-03]\n",
      "Val Loss Meta Info:  [56754.135, 1962.74734375, 0.2362202835083008]\n",
      "\n",
      "Epoch: 87, NLL Loss: 1468.7567109375, Val Loss: 58710.15234375, Time took: 0.7316544055938721\n",
      "Train loss Meta Info:  [1.41865645e+03 5.00950547e+01 5.97764695e-03]\n",
      "Val Loss Meta Info:  [56754.41, 1952.968125, 0.27773193359375]\n",
      "\n",
      "Epoch: 88, NLL Loss: 1468.50027734375, Val Loss: 58703.3203125, Time took: 0.7357418537139893\n",
      "Train loss Meta Info:  [1.41865695e+03 4.98370924e+01 7.06245248e-03]\n",
      "Val Loss Meta Info:  [56753.88, 1946.2040625, 0.3235179901123047]\n",
      "\n",
      "Epoch: 89, NLL Loss: 1468.29475, Val Loss: 58695.35546875, Time took: 0.7387585639953613\n",
      "Train loss Meta Info:  [1.41864385e+03 4.96437662e+01 8.01827733e-03]\n",
      "Val Loss Meta Info:  [56754.34, 1938.153125, 0.28605167388916014]\n",
      "\n",
      "Epoch: 90, NLL Loss: 1468.10459765625, Val Loss: 58683.48828125, Time took: 0.7299118041992188\n",
      "Train loss Meta Info:  [1.41865489e+03 4.94433336e+01 7.09989658e-03]\n",
      "Val Loss Meta Info:  [56753.35, 1927.7484375, 0.23893112182617188]\n",
      "\n",
      "Epoch: 91, NLL Loss: 1467.84900390625, Val Loss: 58677.59375, Time took: 0.7410662174224854\n",
      "Train loss Meta Info:  [1.41864038e+03 4.92031064e+01 6.06035617e-03]\n",
      "Val Loss Meta Info:  [56754.18, 1920.78734375, 0.262916316986084]\n",
      "\n",
      "Epoch: 92, NLL Loss: 1467.69712890625, Val Loss: 58668.04296875, Time took: 0.7335712909698486\n",
      "Train loss Meta Info:  [1.41865346e+03 4.90375481e+01 6.65043049e-03]\n",
      "Val Loss Meta Info:  [56753.52, 1911.7996875, 0.27232070922851564]\n",
      "\n",
      "Epoch: 93, NLL Loss: 1467.44615625, Val Loss: 58661.41015625, Time took: 0.7421450614929199\n",
      "Train loss Meta Info:  [1.41863436e+03 4.88054047e+01 6.88973907e-03]\n",
      "Val Loss Meta Info:  [56753.69, 1905.18171875, 0.25415002822875976]\n",
      "\n",
      "Epoch: 94, NLL Loss: 1467.27528515625, Val Loss: 58652.8203125, Time took: 0.7372386455535889\n",
      "Train loss Meta Info:  [1.41863906e+03 4.86301400e+01 6.46238899e-03]\n",
      "Val Loss Meta Info:  [56753.63, 1896.62515625, 0.25636341094970705]\n",
      "\n",
      "Epoch: 95, NLL Loss: 1467.05823046875, Val Loss: 58645.3046875, Time took: 0.7378771305084229\n",
      "Train loss Meta Info:  [1.41863409e+03 4.84179197e+01 6.52268991e-03]\n",
      "Val Loss Meta Info:  [56753.93, 1888.42375, 0.29511735916137694]\n",
      "\n",
      "Epoch: 96, NLL Loss: 1466.86323828125, Val Loss: 58638.09765625, Time took: 0.7369349002838135\n",
      "Train loss Meta Info:  [1.41863437e+03 4.82217502e+01 7.41072069e-03]\n",
      "Val Loss Meta Info:  [56754.31, 1881.09203125, 0.2701819610595703]\n",
      "\n",
      "Epoch: 97, NLL Loss: 1466.67769140625, Val Loss: 58629.41796875, Time took: 0.7369205951690674\n",
      "Train loss Meta Info:  [1.41863424e+03 4.80368605e+01 6.78555103e-03]\n",
      "Val Loss Meta Info:  [56754.09, 1873.1890625, 0.21402708053588868]\n",
      "\n",
      "Epoch: 98, NLL Loss: 1466.470234375, Val Loss: 58622.7421875, Time took: 0.729011058807373\n",
      "Train loss Meta Info:  [1.41863493e+03 4.78299919e+01 5.40924351e-03]\n",
      "Val Loss Meta Info:  [56753.795, 1866.5421875, 0.24108734130859374]\n",
      "\n",
      "Epoch: 99, NLL Loss: 1466.31673046875, Val Loss: 58616.6796875, Time took: 0.7222409248352051\n",
      "Train loss Meta Info:  [1.41865114e+03 4.76595363e+01 6.09924614e-03]\n",
      "Val Loss Meta Info:  [56753.97, 1860.74953125, 0.19583412170410155]\n",
      "\n",
      "Epoch: 100, NLL Loss: 1466.155046875, Val Loss: 58608.70703125, Time took: 0.733088493347168\n",
      "Train loss Meta Info:  [1.41864665e+03 4.75034252e+01 4.96133222e-03]\n",
      "Val Loss Meta Info:  [56753.31, 1853.6559375, 0.1742890930175781]\n",
      "\n",
      "Epoch: 101, NLL Loss: 1465.9634921875, Val Loss: 58600.6484375, Time took: 0.7314798831939697\n",
      "Train loss Meta Info:  [1.41862891e+03 4.73301255e+01 4.41525063e-03]\n",
      "Val Loss Meta Info:  [56753.61, 1845.2328125, 0.18046873092651367]\n",
      "\n",
      "Epoch: 102, NLL Loss: 1465.765375, Val Loss: 58595.625, Time took: 0.7276597023010254\n",
      "Train loss Meta Info:  [1.41864250e+03 4.71182340e+01 4.55682676e-03]\n",
      "Val Loss Meta Info:  [56753.9, 1838.9025, 0.2824064636230469]\n",
      "\n",
      "Epoch: 103, NLL Loss: 1465.60082421875, Val Loss: 58593.76953125, Time took: 0.7319746017456055\n",
      "Train loss Meta Info:  [1.41863445e+03 4.69591799e+01 6.98423371e-03]\n",
      "Val Loss Meta Info:  [56754.065, 1837.29015625, 0.24173492431640625]\n",
      "\n",
      "Epoch: 104, NLL Loss: 1465.54051171875, Val Loss: 58580.734375, Time took: 0.7387025356292725\n",
      "Train loss Meta Info:  [1.41864439e+03 4.68899121e+01 5.97218391e-03]\n",
      "Val Loss Meta Info:  [56753.44, 1825.38578125, 0.19091388702392578]\n",
      "\n",
      "Epoch: 105, NLL Loss: 1465.257578125, Val Loss: 58578.00390625, Time took: 0.7378942966461182\n",
      "Train loss Meta Info:  [1.41863561e+03 4.66169366e+01 4.79646220e-03]\n",
      "Val Loss Meta Info:  [56754.46, 1821.574375, 0.19686206817626953]\n",
      "\n",
      "Epoch: 106, NLL Loss: 1465.1862734375, Val Loss: 58567.890625, Time took: 0.7521941661834717\n",
      "Train loss Meta Info:  [1.41863811e+03 4.65428853e+01 4.98240503e-03]\n",
      "Val Loss Meta Info:  [56753.545, 1812.3721875, 0.19753419876098632]\n",
      "\n",
      "Epoch: 107, NLL Loss: 1464.9275, Val Loss: 58562.91015625, Time took: 0.737738847732544\n",
      "Train loss Meta Info:  [1.41863565e+03 4.62865461e+01 4.96296271e-03]\n",
      "Val Loss Meta Info:  [56753.025, 1807.63671875, 0.225164794921875]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, NLL Loss: 1464.798515625, Val Loss: 58561.1796875, Time took: 0.7426764965057373\n",
      "Train loss Meta Info:  [1.41862432e+03 4.61681857e+01 5.57211579e-03]\n",
      "Val Loss Meta Info:  [56753.95, 1803.32, 0.39119041442871094]\n",
      "\n",
      "Epoch: 109, NLL Loss: 1464.74552734375, Val Loss: 58552.5234375, Time took: 0.7535536289215088\n",
      "Train loss Meta Info:  [1.41864985e+03 4.60849615e+01 9.82255645e-03]\n",
      "Val Loss Meta Info:  [56753.285, 1796.3440625, 0.2893510437011719]\n",
      "\n",
      "Epoch: 110, NLL Loss: 1464.525140625, Val Loss: 58547.203125, Time took: 0.7432377338409424\n",
      "Train loss Meta Info:  [1.41862531e+03 4.58917554e+01 7.33092272e-03]\n",
      "Val Loss Meta Info:  [56753.51, 1791.9084375, 0.17855804443359374]\n",
      "\n",
      "Epoch: 111, NLL Loss: 1464.41723828125, Val Loss: 58541.796875, Time took: 0.745527982711792\n",
      "Train loss Meta Info:  [1.41863562e+03 4.57765696e+01 4.55262494e-03]\n",
      "Val Loss Meta Info:  [56753.78, 1786.2309375, 0.17918380737304687]\n",
      "\n",
      "Epoch: 112, NLL Loss: 1464.2936171875, Val Loss: 58534.76953125, Time took: 0.7570030689239502\n",
      "Train loss Meta Info:  [1.41864560e+03 4.56428977e+01 4.57985424e-03]\n",
      "Val Loss Meta Info:  [56753.32, 1779.16953125, 0.22784076690673827]\n",
      "\n",
      "Epoch: 113, NLL Loss: 1464.0971796875, Val Loss: 58532.19921875, Time took: 0.7628257274627686\n",
      "Train loss Meta Info:  [1.41863188e+03 4.54587623e+01 5.78777735e-03]\n",
      "Val Loss Meta Info:  [56753.88, 1775.835, 0.24856937408447266]\n",
      "\n",
      "Epoch: 114, NLL Loss: 1463.999375, Val Loss: 58524.71484375, Time took: 0.7405014038085938\n",
      "Train loss Meta Info:  [1.41863389e+03 4.53583235e+01 6.28217448e-03]\n",
      "Val Loss Meta Info:  [56753.2, 1768.8965625, 0.26184099197387695]\n",
      "\n",
      "Epoch: 115, NLL Loss: 1463.84023828125, Val Loss: 58518.921875, Time took: 0.7415757179260254\n",
      "Train loss Meta Info:  [1.41862922e+03 4.52034390e+01 6.60752404e-03]\n",
      "Val Loss Meta Info:  [56753.61, 1761.68921875, 0.3626763153076172]\n",
      "\n",
      "Epoch: 116, NLL Loss: 1463.6665234375, Val Loss: 58518.5234375, Time took: 0.744964599609375\n",
      "Train loss Meta Info:  [1.41863154e+03 4.50245405e+01 9.00671045e-03]\n",
      "Val Loss Meta Info:  [56753.085, 1759.39890625, 0.6037593841552734]\n",
      "\n",
      "Epoch: 117, NLL Loss: 1463.59139453125, Val Loss: 58559.5078125, Time took: 0.75201416015625\n",
      "Train loss Meta Info:  [1.41862766e+03 4.49458517e+01 1.52790157e-02]\n",
      "Val Loss Meta Info:  [56753.44, 1799.08671875, 0.6986830139160156]\n",
      "\n",
      "Epoch: 118, NLL Loss: 1464.738234375, Val Loss: 58566.68359375, Time took: 0.7456035614013672\n",
      "Train loss Meta Info:  [1.41863513e+03 4.60825493e+01 1.74377374e-02]\n",
      "Val Loss Meta Info:  [56754.235, 1808.0534375, 0.4396085357666016]\n",
      "\n",
      "Epoch: 119, NLL Loss: 1464.78794140625, Val Loss: 58535.96875, Time took: 0.7485268115997314\n",
      "Train loss Meta Info:  [1.41864660e+03 4.61283807e+01 1.08973407e-02]\n",
      "Val Loss Meta Info:  [56753.415, 1778.1975, 0.43585479736328125]\n",
      "\n",
      "Epoch: 120, NLL Loss: 1464.0535390625, Val Loss: 58519.6328125, Time took: 0.7408325672149658\n",
      "Train loss Meta Info:  [1.41862277e+03 4.54177195e+01 1.08855634e-02]\n",
      "Val Loss Meta Info:  [56754.695, 1762.643125, 0.22933204650878905]\n",
      "\n",
      "Epoch: 121, NLL Loss: 1463.7185, Val Loss: 58518.57421875, Time took: 0.745368242263794\n",
      "Train loss Meta Info:  [1.41865253e+03 4.50590825e+01 5.68761399e-03]\n",
      "Val Loss Meta Info:  [56753.45, 1763.53578125, 0.15903396606445314]\n",
      "\n",
      "Epoch: 122, NLL Loss: 1463.7398203125, Val Loss: 58508.62890625, Time took: 0.7443673610687256\n",
      "Train loss Meta Info:  [1.41862270e+03 4.51122852e+01 3.96588848e-03]\n",
      "Val Loss Meta Info:  [56754.57, 1751.61703125, 0.24463384628295898]\n",
      "\n",
      "Epoch: 123, NLL Loss: 1463.45651171875, Val Loss: 58502.75, Time took: 0.7456686496734619\n",
      "Train loss Meta Info:  [1.41864504e+03 4.48038680e+01 6.17369424e-03]\n",
      "Val Loss Meta Info:  [56752.76, 1746.4653125, 0.35274566650390626]\n",
      "\n",
      "Epoch: 124, NLL Loss: 1463.2684921875, Val Loss: 58503.75390625, Time took: 0.7426838874816895\n",
      "Train loss Meta Info:  [1.41862011e+03 4.46375955e+01 8.69529866e-03]\n",
      "Val Loss Meta Info:  [56754.675, 1746.28484375, 0.27930870056152346]\n",
      "\n",
      "Epoch: 125, NLL Loss: 1463.29541015625, Val Loss: 58506.1796875, Time took: 0.7497251033782959\n",
      "Train loss Meta Info:  [1.41865016e+03 4.46366368e+01 6.88236673e-03]\n",
      "Val Loss Meta Info:  [56753.41, 1750.810625, 0.19619598388671874]\n",
      "\n",
      "Epoch: 126, NLL Loss: 1463.48635546875, Val Loss: 58502.015625, Time took: 0.7594172954559326\n",
      "Train loss Meta Info:  [1.41863111e+03 4.48491169e+01 4.85789321e-03]\n",
      "Val Loss Meta Info:  [56754.92, 1744.9746875, 0.2120479393005371]\n",
      "\n",
      "Epoch: 127, NLL Loss: 1463.34213671875, Val Loss: 58495.08203125, Time took: 0.7599115371704102\n",
      "Train loss Meta Info:  [1.41865102e+03 4.46844500e+01 5.25189762e-03]\n",
      "Val Loss Meta Info:  [56753.565, 1739.66609375, 0.18567340850830077]\n",
      "\n",
      "Epoch: 128, NLL Loss: 1463.13828125, Val Loss: 58492.0703125, Time took: 0.7666313648223877\n",
      "Train loss Meta Info:  [1.41862215e+03 4.45102766e+01 4.57840537e-03]\n",
      "Val Loss Meta Info:  [56754.205, 1736.39421875, 0.14713897705078124]\n",
      "\n",
      "Epoch: 129, NLL Loss: 1463.02739453125, Val Loss: 58488.3046875, Time took: 0.7467489242553711\n",
      "Train loss Meta Info:  [1.41863819e+03 4.43845190e+01 3.62271460e-03]\n",
      "Val Loss Meta Info:  [56753.495, 1733.415, 0.1396963882446289]\n",
      "\n",
      "Epoch: 130, NLL Loss: 1462.91671484375, Val Loss: 58485.23828125, Time took: 0.7394790649414062\n",
      "Train loss Meta Info:  [1.41862551e+03 4.42866482e+01 3.50817022e-03]\n",
      "Val Loss Meta Info:  [56754.245, 1729.27484375, 0.1717696189880371]\n",
      "\n",
      "Epoch: 131, NLL Loss: 1462.8211015625, Val Loss: 58478.796875, Time took: 0.7434890270233154\n",
      "Train loss Meta Info:  [1.41862175e+03 4.41937109e+01 4.30562171e-03]\n",
      "Val Loss Meta Info:  [56754.05, 1722.604375, 0.21426643371582033]\n",
      "\n",
      "Epoch: 132, NLL Loss: 1462.6796015625, Val Loss: 58473.91015625, Time took: 0.7457146644592285\n",
      "Train loss Meta Info:  [1.41863005e+03 4.40424456e+01 5.38317422e-03]\n",
      "Val Loss Meta Info:  [56753.18, 1718.2875, 0.24394256591796876]\n",
      "\n",
      "Epoch: 133, NLL Loss: 1462.590140625, Val Loss: 58471.8828125, Time took: 0.7427237033843994\n",
      "Train loss Meta Info:  [1.41861835e+03 4.39638007e+01 6.01369834e-03]\n",
      "Val Loss Meta Info:  [56753.35, 1716.5190625, 0.2012582778930664]\n",
      "\n",
      "Epoch: 134, NLL Loss: 1462.56275390625, Val Loss: 58468.86328125, Time took: 0.7483534812927246\n",
      "Train loss Meta Info:  [1.41862562e+03 4.39304741e+01 4.97811347e-03]\n",
      "Val Loss Meta Info:  [56752.815, 1714.14265625, 0.19043859481811523]\n",
      "\n",
      "Epoch: 135, NLL Loss: 1462.4844609375, Val Loss: 58466.52734375, Time took: 0.7198927402496338\n",
      "Train loss Meta Info:  [1.41860500e+03 4.38730383e+01 4.74451821e-03]\n",
      "Val Loss Meta Info:  [56753.415, 1710.81109375, 0.23027469635009765]\n",
      "\n",
      "Epoch: 136, NLL Loss: 1462.39521875, Val Loss: 58461.1953125, Time took: 0.7425365447998047\n",
      "Train loss Meta Info:  [1.41861212e+03 4.37753617e+01 5.67840225e-03]\n",
      "Val Loss Meta Info:  [56752.845, 1705.95390625, 0.23944091796875]\n",
      "\n",
      "Epoch: 137, NLL Loss: 1462.27254296875, Val Loss: 58461.7578125, Time took: 0.7564537525177002\n",
      "Train loss Meta Info:  [1.41860994e+03 4.36546209e+01 5.84182203e-03]\n",
      "Val Loss Meta Info:  [56753.64, 1705.86921875, 0.22497058868408204]\n",
      "\n",
      "Epoch: 138, NLL Loss: 1462.27499609375, Val Loss: 58459.046875, Time took: 0.740027904510498\n",
      "Train loss Meta Info:  [1.41862461e+03 4.36428876e+01 5.45005137e-03]\n",
      "Val Loss Meta Info:  [56753.11, 1703.81359375, 0.2125435256958008]\n",
      "\n",
      "Epoch: 139, NLL Loss: 1462.1808359375, Val Loss: 58456.5625, Time took: 0.7431132793426514\n",
      "Train loss Meta Info:  [1.41860978e+03 4.35639435e+01 5.11471952e-03]\n",
      "Val Loss Meta Info:  [56753.62, 1700.910625, 0.20349445343017578]\n",
      "\n",
      "Epoch: 140, NLL Loss: 1462.0975546875, Val Loss: 58452.375, Time took: 0.7468843460083008\n",
      "Train loss Meta Info:  [1.41862251e+03 4.34681963e+01 4.88853829e-03]\n",
      "Val Loss Meta Info:  [56752.72, 1697.7340625, 0.19204212188720704]\n",
      "\n",
      "Epoch: 141, NLL Loss: 1462.00694140625, Val Loss: 58447.36328125, Time took: 0.7486860752105713\n",
      "Train loss Meta Info:  [1.41860845e+03 4.33919528e+01 4.63763652e-03]\n",
      "Val Loss Meta Info:  [56753.055, 1692.260625, 0.204803466796875]\n",
      "\n",
      "Epoch: 142, NLL Loss: 1461.9138125, Val Loss: 58446.4140625, Time took: 0.7509562969207764\n",
      "Train loss Meta Info:  [1.41861702e+03 4.32897053e+01 4.98510342e-03]\n",
      "Val Loss Meta Info:  [56753.06, 1690.869375, 0.24843570709228516]\n",
      "\n",
      "Epoch: 143, NLL Loss: 1461.8802109375, Val Loss: 58442.8984375, Time took: 0.7533574104309082\n",
      "Train loss Meta Info:  [1.41860692e+03 4.32646035e+01 6.07258126e-03]\n",
      "Val Loss Meta Info:  [56752.73, 1687.8915625, 0.22806961059570313]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144, NLL Loss: 1461.79541796875, Val Loss: 58438.93359375, Time took: 0.743781566619873\n",
      "Train loss Meta Info:  [1.41861286e+03 4.31745219e+01 5.56858321e-03]\n",
      "Val Loss Meta Info:  [56752.645, 1684.3475, 0.19470390319824218]\n",
      "\n",
      "Epoch: 145, NLL Loss: 1461.68980078125, Val Loss: 58438.25, Time took: 0.7449524402618408\n",
      "Train loss Meta Info:  [1.41860843e+03 4.30744684e+01 4.75681464e-03]\n",
      "Val Loss Meta Info:  [56754.11, 1682.0065625, 0.2132670211791992]\n",
      "\n",
      "Epoch: 146, NLL Loss: 1461.67071484375, Val Loss: 58437.40234375, Time took: 0.7397582530975342\n",
      "Train loss Meta Info:  [1.41864138e+03 4.30217408e+01 5.20458040e-03]\n",
      "Val Loss Meta Info:  [56754.19, 1681.0175, 0.21931499481201172]\n",
      "\n",
      "Epoch: 147, NLL Loss: 1461.61662890625, Val Loss: 58432.29296875, Time took: 0.7387700080871582\n",
      "Train loss Meta Info:  [1.41863033e+03 4.29783585e+01 5.40261221e-03]\n",
      "Val Loss Meta Info:  [56752.85, 1677.411875, 0.20341194152832032]\n",
      "\n",
      "Epoch: 148, NLL Loss: 1461.5138046875, Val Loss: 58431.375, Time took: 0.7426249980926514\n",
      "Train loss Meta Info:  [1.41860715e+03 4.28992306e+01 5.01260856e-03]\n",
      "Val Loss Meta Info:  [56753.785, 1675.66375, 0.19240798950195312]\n",
      "\n",
      "Epoch: 149, NLL Loss: 1461.5045703125, Val Loss: 58436.6953125, Time took: 0.7296648025512695\n",
      "Train loss Meta Info:  [1.41863106e+03 4.28664892e+01 4.72621839e-03]\n",
      "Val Loss Meta Info:  [56752.895, 1682.00734375, 0.17932773590087892]\n",
      "\n",
      "Epoch: 150, NLL Loss: 1461.59792578125, Val Loss: 58433.515625, Time took: 0.7331328392028809\n",
      "Train loss Meta Info:  [1.41861197e+03 4.29792795e+01 4.44552558e-03]\n",
      "Val Loss Meta Info:  [56752.67, 1679.0265625, 0.1820547103881836]\n",
      "\n",
      "Epoch: 151, NLL Loss: 1461.509265625, Val Loss: 58431.33984375, Time took: 0.7944447994232178\n",
      "Train loss Meta Info:  [1.41860275e+03 4.28996858e+01 4.52750707e-03]\n",
      "Val Loss Meta Info:  [56753.575, 1675.2009375, 0.25658426284790037]\n",
      "\n",
      "Epoch: 152, NLL Loss: 1461.47048828125, Val Loss: 58426.9921875, Time took: 0.7555141448974609\n",
      "Train loss Meta Info:  [1.41862153e+03 4.28393356e+01 6.33715764e-03]\n",
      "Val Loss Meta Info:  [56752.905, 1671.795, 0.22957273483276366]\n",
      "\n",
      "Epoch: 153, NLL Loss: 1461.36705859375, Val Loss: 58428.4140625, Time took: 0.7455379962921143\n",
      "Train loss Meta Info:  [1.41860549e+03 4.27529376e+01 5.64928725e-03]\n",
      "Val Loss Meta Info:  [56753.73, 1672.4859375, 0.2201181411743164]\n",
      "\n",
      "Epoch: 154, NLL Loss: 1461.387109375, Val Loss: 58423.3046875, Time took: 0.7646102905273438\n",
      "Train loss Meta Info:  [1.41862586e+03 4.27528722e+01 5.43313009e-03]\n",
      "Val Loss Meta Info:  [56753.835, 1667.2253125, 0.22445423126220704]\n",
      "\n",
      "Epoch: 155, NLL Loss: 1461.246609375, Val Loss: 58422.73828125, Time took: 0.7637178897857666\n",
      "Train loss Meta Info:  [1.41860259e+03 4.26354834e+01 5.50617899e-03]\n",
      "Val Loss Meta Info:  [56753.17, 1667.3940625, 0.217640380859375]\n",
      "\n",
      "Epoch: 156, NLL Loss: 1461.28304296875, Val Loss: 58429.09765625, Time took: 0.7740435600280762\n",
      "Train loss Meta Info:  [1.41861999e+03 4.26547653e+01 5.31984494e-03]\n",
      "Val Loss Meta Info:  [56753.595, 1673.385, 0.21198110580444335]\n",
      "\n",
      "Epoch: 157, NLL Loss: 1461.37116796875, Val Loss: 58419.65234375, Time took: 0.766852617263794\n",
      "Train loss Meta Info:  [1.41861556e+03 4.27473061e+01 5.29248497e-03]\n",
      "Val Loss Meta Info:  [56754.12, 1663.550625, 0.19825477600097657]\n",
      "\n",
      "Epoch: 158, NLL Loss: 1461.14665234375, Val Loss: 58430.265625, Time took: 0.77309250831604\n",
      "Train loss Meta Info:  [1.41862150e+03 4.25173876e+01 4.91969597e-03]\n",
      "Val Loss Meta Info:  [56753.86, 1673.2915625, 0.3116931915283203]\n",
      "\n",
      "Epoch: 159, NLL Loss: 1461.453734375, Val Loss: 58444.6953125, Time took: 0.7593526840209961\n",
      "Train loss Meta Info:  [1.41863109e+03 4.28103544e+01 7.73919466e-03]\n",
      "Val Loss Meta Info:  [56754.44, 1687.50796875, 0.2742897033691406]\n",
      "\n",
      "Epoch: 160, NLL Loss: 1461.71278125, Val Loss: 58431.23046875, Time took: 0.758352518081665\n",
      "Train loss Meta Info:  [1.41863841e+03 4.30634539e+01 6.81427561e-03]\n",
      "Val Loss Meta Info:  [56753.975, 1675.2721875, 0.19842079162597656]\n",
      "\n",
      "Epoch: 161, NLL Loss: 1461.4175546875, Val Loss: 58429.97265625, Time took: 0.7620766162872314\n",
      "Train loss Meta Info:  [1.41862918e+03 4.27803189e+01 5.01209874e-03]\n",
      "Val Loss Meta Info:  [56753.62, 1674.81234375, 0.1542711639404297]\n",
      "\n",
      "Epoch: 162, NLL Loss: 1461.44963671875, Val Loss: 58432.61328125, Time took: 0.7338895797729492\n",
      "Train loss Meta Info:  [1.41861336e+03 4.28300170e+01 3.85486203e-03]\n",
      "Val Loss Meta Info:  [56753.655, 1677.2375, 0.1727074432373047]\n",
      "\n",
      "Epoch: 163, NLL Loss: 1461.5499453125, Val Loss: 58419.55859375, Time took: 0.757382869720459\n",
      "Train loss Meta Info:  [1.41861476e+03 4.29281551e+01 4.31943877e-03]\n",
      "Val Loss Meta Info:  [56753.455, 1664.75515625, 0.13475678443908692]\n",
      "\n",
      "Epoch: 164, NLL Loss: 1461.1620234375, Val Loss: 58434.57421875, Time took: 0.763016939163208\n",
      "Train loss Meta Info:  [1.41861764e+03 4.25387619e+01 3.43642417e-03]\n",
      "Val Loss Meta Info:  [56752.745, 1680.0746875, 0.17556257247924806]\n",
      "\n",
      "Epoch: 165, NLL Loss: 1461.53104296875, Val Loss: 58418.9453125, Time took: 0.7498419284820557\n",
      "Train loss Meta Info:  [1.41860673e+03 4.29168444e+01 4.51674090e-03]\n",
      "Val Loss Meta Info:  [56753.52, 1664.1590625, 0.12648675918579103]\n",
      "\n",
      "Epoch: 166, NLL Loss: 1461.143109375, Val Loss: 58425.66796875, Time took: 0.7329323291778564\n",
      "Train loss Meta Info:  [1.41860223e+03 4.25355717e+01 3.20386457e-03]\n",
      "Val Loss Meta Info:  [56752.815, 1671.3128125, 0.15421286582946778]\n",
      "\n",
      "Epoch: 167, NLL Loss: 1461.36263671875, Val Loss: 58421.703125, Time took: 0.729050874710083\n",
      "Train loss Meta Info:  [1.41860255e+03 4.27536341e+01 3.86029362e-03]\n",
      "Val Loss Meta Info:  [56753.11, 1667.22921875, 0.1364384651184082]\n",
      "\n",
      "Epoch: 168, NLL Loss: 1461.23437890625, Val Loss: 58420.34765625, Time took: 0.7262792587280273\n",
      "Train loss Meta Info:  [1.41860558e+03 4.26230928e+01 3.39503499e-03]\n",
      "Val Loss Meta Info:  [56753.01, 1666.20890625, 0.11314119338989258]\n",
      "\n",
      "Epoch: 169, NLL Loss: 1461.15833984375, Val Loss: 58424.609375, Time took: 0.7264506816864014\n",
      "Train loss Meta Info:  [1.41860288e+03 4.25507208e+01 2.81059540e-03]\n",
      "Val Loss Meta Info:  [56752.85, 1670.5196875, 0.12382095336914062]\n",
      "\n",
      "Epoch: 170, NLL Loss: 1461.24120703125, Val Loss: 58416.3984375, Time took: 0.7261159420013428\n",
      "Train loss Meta Info:  [1.41859346e+03 4.26424780e+01 3.09158602e-03]\n",
      "Val Loss Meta Info:  [56753.28, 1661.88203125, 0.12399091720581054]\n",
      "\n",
      "Epoch: 171, NLL Loss: 1461.0536015625, Val Loss: 58421.3828125, Time took: 0.7246484756469727\n",
      "Train loss Meta Info:  [1.41860614e+03 4.24422798e+01 3.02765590e-03]\n",
      "Val Loss Meta Info:  [56753.51, 1666.65140625, 0.12256025314331055]\n",
      "\n",
      "Epoch: 172, NLL Loss: 1461.2022890625, Val Loss: 58415.75, Time took: 0.7312932014465332\n",
      "Train loss Meta Info:  [1.41860507e+03 4.25920734e+01 2.99512473e-03]\n",
      "Val Loss Meta Info:  [56753.39, 1661.215625, 0.11428427696228027]\n",
      "\n",
      "Epoch: 173, NLL Loss: 1461.03790234375, Val Loss: 58418.140625, Time took: 0.7316222190856934\n",
      "Train loss Meta Info:  [1.41860310e+03 4.24299631e+01 2.80048072e-03]\n",
      "Val Loss Meta Info:  [56752.77, 1664.016875, 0.13545627593994142]\n",
      "\n",
      "Epoch: 174, NLL Loss: 1461.0690859375, Val Loss: 58416.1875, Time took: 0.7361023426055908\n",
      "Train loss Meta Info:  [1.41859787e+03 4.24653694e+01 3.35116666e-03]\n",
      "Val Loss Meta Info:  [56753.33, 1661.461875, 0.14021257400512696]\n",
      "\n",
      "Epoch: 175, NLL Loss: 1461.01825390625, Val Loss: 58414.11328125, Time took: 0.7304656505584717\n",
      "Train loss Meta Info:  [1.41860849e+03 4.24037227e+01 3.45560997e-03]\n",
      "Val Loss Meta Info:  [56752.985, 1659.7103125, 0.1421877098083496]\n",
      "\n",
      "Epoch: 176, NLL Loss: 1461.0133984375, Val Loss: 58414.03515625, Time took: 0.7390012741088867\n",
      "Train loss Meta Info:  [1.41859531e+03 4.24120869e+01 3.40645902e-03]\n",
      "Val Loss Meta Info:  [56753.76, 1658.8696875, 0.14060006141662598]\n",
      "\n",
      "Epoch: 177, NLL Loss: 1460.9866015625, Val Loss: 58414.46875, Time took: 0.7277867794036865\n",
      "Train loss Meta Info:  [1.41861775e+03 4.23629242e+01 3.34778383e-03]\n",
      "Val Loss Meta Info:  [56753.13, 1659.7565625, 0.1585407543182373]\n",
      "\n",
      "Epoch: 178, NLL Loss: 1460.94724609375, Val Loss: 58414.09765625, Time took: 0.7262475490570068\n",
      "Train loss Meta Info:  [1.41859193e+03 4.23485011e+01 3.82220557e-03]\n",
      "Val Loss Meta Info:  [56753.435, 1659.13546875, 0.15307491302490234]\n",
      "\n",
      "Epoch: 179, NLL Loss: 1460.94548828125, Val Loss: 58410.140625, Time took: 0.7492187023162842\n",
      "Train loss Meta Info:  [1.41861547e+03 4.23234193e+01 3.68442566e-03]\n",
      "Val Loss Meta Info:  [56753.0, 1655.84515625, 0.12927553176879883]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, NLL Loss: 1460.8832265625, Val Loss: 58409.515625, Time took: 0.7450413703918457\n",
      "Train loss Meta Info:  [1.41859200e+03 4.22856729e+01 3.07962089e-03]\n",
      "Val Loss Meta Info:  [56753.69, 1654.5390625, 0.12841489791870117]\n",
      "\n",
      "Epoch: 181, NLL Loss: 1460.8628359375, Val Loss: 58411.5625, Time took: 0.7387077808380127\n",
      "Train loss Meta Info:  [1.41861630e+03 4.22409369e+01 3.09599959e-03]\n",
      "Val Loss Meta Info:  [56752.47, 1657.52953125, 0.15657829284667968]\n",
      "\n",
      "Epoch: 182, NLL Loss: 1460.87019140625, Val Loss: 58408.25390625, Time took: 0.738818883895874\n",
      "Train loss Meta Info:  [1.41858611e+03 4.22769916e+01 3.89910845e-03]\n",
      "Val Loss Meta Info:  [56754.35, 1652.65953125, 0.12470794677734375]\n",
      "\n",
      "Epoch: 183, NLL Loss: 1460.81618359375, Val Loss: 58405.25390625, Time took: 0.742990255355835\n",
      "Train loss Meta Info:  [1.41863239e+03 4.21782543e+01 3.03084622e-03]\n",
      "Val Loss Meta Info:  [56753.19, 1650.906875, 0.11609197616577148]\n",
      "\n",
      "Epoch: 184, NLL Loss: 1460.72501171875, Val Loss: 58410.29296875, Time took: 0.7283854484558105\n",
      "Train loss Meta Info:  [1.41859673e+03 4.21230104e+01 2.85697790e-03]\n",
      "Val Loss Meta Info:  [56754.41, 1654.41546875, 0.14712679862976075]\n",
      "\n",
      "Epoch: 185, NLL Loss: 1460.82515625, Val Loss: 58409.79296875, Time took: 0.7325539588928223\n",
      "Train loss Meta Info:  [1.41862991e+03 4.21883785e+01 3.71873467e-03]\n",
      "Val Loss Meta Info:  [56753.66, 1655.0225, 0.11164529800415039]\n",
      "\n",
      "Epoch: 186, NLL Loss: 1460.8671875, Val Loss: 58407.97265625, Time took: 0.7358188629150391\n",
      "Train loss Meta Info:  [1.41860870e+03 4.22533612e+01 2.75250883e-03]\n",
      "Val Loss Meta Info:  [56753.66, 1653.20453125, 0.11115240097045899]\n",
      "\n",
      "Epoch: 187, NLL Loss: 1460.79428515625, Val Loss: 58410.73828125, Time took: 0.738516092300415\n",
      "Train loss Meta Info:  [1.41859640e+03 4.21927884e+01 2.73160571e-03]\n",
      "Val Loss Meta Info:  [56754.07, 1655.57234375, 0.11013874053955078]\n",
      "\n",
      "Epoch: 188, NLL Loss: 1460.83530078125, Val Loss: 58405.015625, Time took: 0.746776819229126\n",
      "Train loss Meta Info:  [1.41860795e+03 4.22222446e+01 2.71748187e-03]\n",
      "Val Loss Meta Info:  [56753.42, 1650.46125, 0.11348217964172364]\n",
      "\n",
      "Epoch: 189, NLL Loss: 1460.71186328125, Val Loss: 58404.75390625, Time took: 0.7370123863220215\n",
      "Train loss Meta Info:  [1.41860281e+03 4.21038199e+01 2.76045175e-03]\n",
      "Val Loss Meta Info:  [56753.355, 1650.0625, 0.13327927589416505]\n",
      "\n",
      "Epoch: 190, NLL Loss: 1460.6941328125, Val Loss: 58406.234375, Time took: 0.7445995807647705\n",
      "Train loss Meta Info:  [1.41860352e+03 4.20842913e+01 3.32649174e-03]\n",
      "Val Loss Meta Info:  [56753.55, 1651.271875, 0.1416368865966797]\n",
      "\n",
      "Epoch: 191, NLL Loss: 1460.7424140625, Val Loss: 58403.59765625, Time took: 0.7328681945800781\n",
      "Train loss Meta Info:  [1.41860302e+03 4.21327196e+01 3.49194878e-03]\n",
      "Val Loss Meta Info:  [56753.45, 1648.705625, 0.14450040817260743]\n",
      "\n",
      "Epoch: 192, NLL Loss: 1460.6459375, Val Loss: 58405.58203125, Time took: 0.7398066520690918\n",
      "Train loss Meta Info:  [1.41859826e+03 4.20408318e+01 3.57413423e-03]\n",
      "Val Loss Meta Info:  [56753.46, 1650.18296875, 0.19378856658935548]\n",
      "\n",
      "Epoch: 193, NLL Loss: 1460.7296953125, Val Loss: 58408.59375, Time took: 0.7470917701721191\n",
      "Train loss Meta Info:  [1.41860240e+03 4.21182194e+01 4.70459943e-03]\n",
      "Val Loss Meta Info:  [56753.21, 1653.94296875, 0.14420437812805176]\n",
      "\n",
      "Epoch: 194, NLL Loss: 1460.780890625, Val Loss: 58403.46484375, Time took: 0.730583906173706\n",
      "Train loss Meta Info:  [1.41859645e+03 4.21776497e+01 3.49743903e-03]\n",
      "Val Loss Meta Info:  [56753.49, 1648.825, 0.11504945755004883]\n",
      "\n",
      "Epoch: 195, NLL Loss: 1460.670296875, Val Loss: 58404.15234375, Time took: 0.7174382209777832\n",
      "Train loss Meta Info:  [1.41859511e+03 4.20698473e+01 2.74614747e-03]\n",
      "Val Loss Meta Info:  [56752.98, 1649.61375, 0.15607494354248047]\n",
      "\n",
      "Epoch: 196, NLL Loss: 1460.70102734375, Val Loss: 58406.54296875, Time took: 0.7316741943359375\n",
      "Train loss Meta Info:  [1.41858405e+03 4.21097157e+01 3.70404599e-03]\n",
      "Val Loss Meta Info:  [56753.62, 1651.540625, 0.13858823776245116]\n",
      "\n",
      "Epoch: 197, NLL Loss: 1460.6991640625, Val Loss: 58400.87890625, Time took: 0.7329573631286621\n",
      "Train loss Meta Info:  [1.41858742e+03 4.21052103e+01 3.31101993e-03]\n",
      "Val Loss Meta Info:  [56753.86, 1645.69171875, 0.13279641151428223]\n",
      "\n",
      "Epoch: 198, NLL Loss: 1460.57511328125, Val Loss: 58404.97265625, Time took: 0.7304985523223877\n",
      "Train loss Meta Info:  [1.41861141e+03 4.19574407e+01 3.15934116e-03]\n",
      "Val Loss Meta Info:  [56755.055, 1648.2603125, 0.1658051300048828]\n",
      "\n",
      "Epoch: 199, NLL Loss: 1460.71477734375, Val Loss: 58438.0234375, Time took: 0.7243568897247314\n",
      "Train loss Meta Info:  [1.41863435e+03 4.20723639e+01 4.04967348e-03]\n",
      "Val Loss Meta Info:  [56757.57, 1678.2465625, 0.2209773063659668]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=HRMTPP, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rmtpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([50, 8000, 2]), Val Data Shape: torch.Size([50, 2000, 2])\n",
      "Markers: Data Shape: torch.Size([50, 8000, 20]), Val Data Shape: torch.Size([50, 2000, 20])\n",
      "Epoch: 0, NLL Loss: 1519.8495, Val Loss: 57723.35546875, Time took: 0.44893574714660645\n",
      "Train loss Meta Info:  [1444.00798437   75.84150208]\n",
      "Val Loss Meta Info:  [57307.535, 415.824921875]\n",
      "\n",
      "Epoch: 1, NLL Loss: 1442.43723046875, Val Loss: 59497.359375, Time took: 0.42549681663513184\n",
      "Train loss Meta Info:  [1432.83265625    9.6045724 ]\n",
      "Val Loss Meta Info:  [57215.04, 2282.32]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1487.3058203125, Val Loss: 59576.58203125, Time took: 0.42228198051452637\n",
      "Train loss Meta Info:  [1430.13851953   57.16730798]\n",
      "Val Loss Meta Info:  [57271.32, 2305.2621875]\n",
      "\n",
      "Epoch: 3, NLL Loss: 1488.50864453125, Val Loss: 59348.046875, Time took: 0.4171335697174072\n",
      "Train loss Meta Info:  [1431.61246484   56.89618091]\n",
      "Val Loss Meta Info:  [56879.19, 2468.86203125]\n",
      "\n",
      "Epoch: 4, NLL Loss: 1480.43335546875, Val Loss: 59564.28515625, Time took: 0.4159080982208252\n",
      "Train loss Meta Info:  [1421.85295703   58.58037756]\n",
      "Val Loss Meta Info:  [56916.98, 2647.31]\n",
      "\n",
      "Epoch: 5, NLL Loss: 1481.60885546875, Val Loss: 59742.1171875, Time took: 0.41136717796325684\n",
      "Train loss Meta Info:  [1422.78140625   58.82745068]\n",
      "Val Loss Meta Info:  [56889.51, 2852.613125]\n",
      "\n",
      "Epoch: 6, NLL Loss: 1479.91617578125, Val Loss: 60133.5390625, Time took: 0.41780638694763184\n",
      "Train loss Meta Info:  [1422.07905469   57.83714075]\n",
      "Val Loss Meta Info:  [56896.97, 3236.573125]\n",
      "\n",
      "Epoch: 7, NLL Loss: 1479.26191796875, Val Loss: 60737.58203125, Time took: 0.4157226085662842\n",
      "Train loss Meta Info:  [1422.22219922   57.03973633]\n",
      "Val Loss Meta Info:  [56875.405, 3862.1784375]\n",
      "\n",
      "Epoch: 8, NLL Loss: 1478.38769140625, Val Loss: 61934.41015625, Time took: 0.41791605949401855\n",
      "Train loss Meta Info:  [1421.68260547   56.70510657]\n",
      "Val Loss Meta Info:  [56864.97, 5069.4425]\n",
      "\n",
      "Epoch: 9, NLL Loss: 1478.0093046875, Val Loss: 62906.5625, Time took: 0.41391491889953613\n",
      "Train loss Meta Info:  [1421.38740625   56.62190698]\n",
      "Val Loss Meta Info:  [56923.68, 5982.88375]\n",
      "\n",
      "Epoch: 10, NLL Loss: 1477.17690625, Val Loss: 65664.5078125, Time took: 0.41918110847473145\n",
      "Train loss Meta Info:  [1422.80213672   54.37478772]\n",
      "Val Loss Meta Info:  [56880.24, 8784.268125]\n",
      "\n",
      "Epoch: 11, NLL Loss: 1476.39378125, Val Loss: 67668.171875, Time took: 0.42072272300720215\n",
      "Train loss Meta Info:  [1421.72912109   54.66466077]\n",
      "Val Loss Meta Info:  [56861.62, 10806.5525]\n",
      "\n",
      "Epoch: 12, NLL Loss: 1474.58971875, Val Loss: 69975.296875, Time took: 0.40937376022338867\n",
      "Train loss Meta Info:  [1421.26007422   53.32964392]\n",
      "Val Loss Meta Info:  [56862.615, 13112.6875]\n",
      "\n",
      "Epoch: 13, NLL Loss: 1473.085625, Val Loss: 73534.3671875, Time took: 0.41402673721313477\n",
      "Train loss Meta Info:  [1421.29323438   51.79238611]\n",
      "Val Loss Meta Info:  [56865.0, 16669.365]\n",
      "\n",
      "Epoch: 14, NLL Loss: 1470.9181328125, Val Loss: 77775.3203125, Time took: 0.41307711601257324\n",
      "Train loss Meta Info:  [1421.36450391   49.55364441]\n",
      "Val Loss Meta Info:  [56829.76, 20945.5575]\n",
      "\n",
      "Epoch: 15, NLL Loss: 1469.53771484375, Val Loss: 83804.6171875, Time took: 0.4177722930908203\n",
      "Train loss Meta Info:  [1420.45978906   49.07794348]\n",
      "Val Loss Meta Info:  [56828.14, 26976.48]\n",
      "\n",
      "Epoch: 16, NLL Loss: 1468.60696875, Val Loss: 87890.796875, Time took: 0.410656213760376\n",
      "Train loss Meta Info:  [1420.45132422   48.15566235]\n",
      "Val Loss Meta Info:  [56839.775, 31051.03]\n",
      "\n",
      "Epoch: 17, NLL Loss: 1467.72583203125, Val Loss: 97549.234375, Time took: 0.4115133285522461\n",
      "Train loss Meta Info:  [1420.76839844   46.95741418]\n",
      "Val Loss Meta Info:  [56834.74, 40714.5075]\n",
      "\n",
      "Epoch: 18, NLL Loss: 1468.094109375, Val Loss: 95868.9375, Time took: 0.41054439544677734\n",
      "Train loss Meta Info:  [1420.65401953   47.44012769]\n",
      "Val Loss Meta Info:  [56827.185, 39041.765]\n",
      "\n",
      "Epoch: 19, NLL Loss: 1468.12868359375, Val Loss: 102150.640625, Time took: 0.4064624309539795\n",
      "Train loss Meta Info:  [1420.49937109   47.62932825]\n",
      "Val Loss Meta Info:  [56849.505, 45301.13]\n",
      "\n",
      "Epoch: 20, NLL Loss: 1467.70885546875, Val Loss: 115432.2578125, Time took: 0.4130516052246094\n",
      "Train loss Meta Info:  [1421.04031641   46.66853375]\n",
      "Val Loss Meta Info:  [56811.905, 58620.34]\n",
      "\n",
      "Epoch: 21, NLL Loss: 1467.08380078125, Val Loss: 126133.796875, Time took: 0.4158010482788086\n",
      "Train loss Meta Info:  [1420.13324609   46.95055969]\n",
      "Val Loss Meta Info:  [56810.53, 69323.27]\n",
      "\n",
      "Epoch: 22, NLL Loss: 1466.93016015625, Val Loss: 123684.2734375, Time took: 0.4168221950531006\n",
      "Train loss Meta Info:  [1420.13342969   46.79675861]\n",
      "Val Loss Meta Info:  [56805.04, 66879.245]\n",
      "\n",
      "Epoch: 23, NLL Loss: 1466.6190234375, Val Loss: 129910.5, Time took: 0.4105854034423828\n",
      "Train loss Meta Info:  [1419.99033594   46.62866858]\n",
      "Val Loss Meta Info:  [56803.015, 73107.485]\n",
      "\n",
      "Epoch: 24, NLL Loss: 1466.28729296875, Val Loss: 144573.734375, Time took: 0.41371870040893555\n",
      "Train loss Meta Info:  [1419.92149609   46.36580481]\n",
      "Val Loss Meta Info:  [56794.92, 87778.82]\n",
      "\n",
      "Epoch: 25, NLL Loss: 1465.97241015625, Val Loss: 135559.75, Time took: 0.411074161529541\n",
      "Train loss Meta Info:  [1419.69135938   46.28105267]\n",
      "Val Loss Meta Info:  [56781.405, 78778.365]\n",
      "\n",
      "Epoch: 26, NLL Loss: 1465.90295703125, Val Loss: 134271.03125, Time took: 0.40786147117614746\n",
      "Train loss Meta Info:  [1419.35854688   46.54440948]\n",
      "Val Loss Meta Info:  [56783.83, 77487.18]\n",
      "\n",
      "Epoch: 27, NLL Loss: 1465.31003515625, Val Loss: 142199.453125, Time took: 0.4116325378417969\n",
      "Train loss Meta Info:  [1419.39345703   45.9165838 ]\n",
      "Val Loss Meta Info:  [56795.13, 85404.34]\n",
      "\n",
      "Epoch: 28, NLL Loss: 1465.54011328125, Val Loss: 137232.953125, Time took: 0.41339707374572754\n",
      "Train loss Meta Info:  [1419.61499609   45.92509882]\n",
      "Val Loss Meta Info:  [56780.365, 80452.625]\n",
      "\n",
      "Epoch: 29, NLL Loss: 1464.482015625, Val Loss: 155662.78125, Time took: 0.41359734535217285\n",
      "Train loss Meta Info:  [1419.283375    45.1986618]\n",
      "Val Loss Meta Info:  [56772.075, 98890.7]\n",
      "\n",
      "Epoch: 30, NLL Loss: 1464.53901171875, Val Loss: 166663.0625, Time took: 0.41095924377441406\n",
      "Train loss Meta Info:  [1419.09032813   45.44868091]\n",
      "Val Loss Meta Info:  [56770.65, 109892.43]\n",
      "\n",
      "Epoch: 31, NLL Loss: 1464.01630859375, Val Loss: 151916.203125, Time took: 0.41404271125793457\n",
      "Train loss Meta Info:  [1419.05391797   44.96238672]\n",
      "Val Loss Meta Info:  [56772.205, 95144.0]\n",
      "\n",
      "Epoch: 32, NLL Loss: 1464.2857578125, Val Loss: 173861.921875, Time took: 0.41362428665161133\n",
      "Train loss Meta Info:  [1419.08619141   45.19958759]\n",
      "Val Loss Meta Info:  [56770.07, 117091.87]\n",
      "\n",
      "Epoch: 33, NLL Loss: 1464.55262109375, Val Loss: 160405.25, Time took: 0.41100430488586426\n",
      "Train loss Meta Info:  [1419.02883203   45.52377893]\n",
      "Val Loss Meta Info:  [56765.78, 103639.49]\n",
      "\n",
      "Epoch: 34, NLL Loss: 1463.5560859375, Val Loss: 141968.140625, Time took: 0.41534900665283203\n",
      "Train loss Meta Info:  [1418.92661719   44.62946014]\n",
      "Val Loss Meta Info:  [56767.49, 85200.63]\n",
      "\n",
      "Epoch: 35, NLL Loss: 1464.1100859375, Val Loss: 150839.109375, Time took: 0.4128696918487549\n",
      "Train loss Meta Info:  [1418.97338281   45.13672784]\n",
      "Val Loss Meta Info:  [56764.98, 94074.12]\n",
      "\n",
      "Epoch: 36, NLL Loss: 1464.508609375, Val Loss: 134626.5625, Time took: 0.4153413772583008\n",
      "Train loss Meta Info:  [1418.92513672   45.58346729]\n",
      "Val Loss Meta Info:  [56770.335, 77856.235]\n",
      "\n",
      "Epoch: 37, NLL Loss: 1464.483265625, Val Loss: 142205.578125, Time took: 0.4109935760498047\n",
      "Train loss Meta Info:  [1419.04737891   45.43586652]\n",
      "Val Loss Meta Info:  [56765.605, 85439.96]\n",
      "\n",
      "Epoch: 38, NLL Loss: 1463.1928046875, Val Loss: 156036.21875, Time took: 0.4120304584503174\n",
      "Train loss Meta Info:  [1418.92818359   44.26465967]\n",
      "Val Loss Meta Info:  [56762.745, 99273.49]\n",
      "\n",
      "Epoch: 39, NLL Loss: 1464.5405390625, Val Loss: 141728.84375, Time took: 0.4113929271697998\n",
      "Train loss Meta Info:  [1418.86103516   45.6794845 ]\n",
      "Val Loss Meta Info:  [56762.36, 84966.48]\n",
      "\n",
      "Epoch: 40, NLL Loss: 1463.449, Val Loss: 140939.140625, Time took: 0.4087858200073242\n",
      "Train loss Meta Info:  [1418.84727344   44.60170605]\n",
      "Val Loss Meta Info:  [56761.405, 84177.74]\n",
      "\n",
      "Epoch: 41, NLL Loss: 1463.52671875, Val Loss: 151999.3125, Time took: 0.41461992263793945\n",
      "Train loss Meta Info:  [1418.82574219   44.70098914]\n",
      "Val Loss Meta Info:  [56761.46, 95237.84]\n",
      "\n",
      "Epoch: 42, NLL Loss: 1463.41023828125, Val Loss: 147042.609375, Time took: 0.4134507179260254\n",
      "Train loss Meta Info:  [1418.82355469   44.58671643]\n",
      "Val Loss Meta Info:  [56759.88, 90282.75]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, NLL Loss: 1462.82735546875, Val Loss: 134957.5625, Time took: 0.41729021072387695\n",
      "Train loss Meta Info:  [1418.78383594   44.04353467]\n",
      "Val Loss Meta Info:  [56759.12, 78198.45]\n",
      "\n",
      "Epoch: 44, NLL Loss: 1463.2329609375, Val Loss: 135050.203125, Time took: 0.4096224308013916\n",
      "Train loss Meta Info:  [1418.770875     44.46210297]\n",
      "Val Loss Meta Info:  [56758.64, 78291.57]\n",
      "\n",
      "Epoch: 45, NLL Loss: 1462.3774765625, Val Loss: 144228.609375, Time took: 0.41159939765930176\n",
      "Train loss Meta Info:  [1418.76211719   43.61536249]\n",
      "Val Loss Meta Info:  [56759.435, 87469.14]\n",
      "\n",
      "Epoch: 46, NLL Loss: 1463.23995703125, Val Loss: 124219.4296875, Time took: 0.4104886054992676\n",
      "Train loss Meta Info:  [1418.77313281   44.4668443 ]\n",
      "Val Loss Meta Info:  [56758.155, 67461.28]\n",
      "\n",
      "Epoch: 47, NLL Loss: 1462.88539453125, Val Loss: 125056.6953125, Time took: 0.41052818298339844\n",
      "Train loss Meta Info:  [1418.75455469   44.13084631]\n",
      "Val Loss Meta Info:  [56759.415, 68297.29]\n",
      "\n",
      "Epoch: 48, NLL Loss: 1462.38334765625, Val Loss: 134212.859375, Time took: 0.41336536407470703\n",
      "Train loss Meta Info:  [1418.78344531   43.59989941]\n",
      "Val Loss Meta Info:  [56761.93, 77450.91]\n",
      "\n",
      "Epoch: 49, NLL Loss: 1464.11140625, Val Loss: 119353.609375, Time took: 0.41258883476257324\n",
      "Train loss Meta Info:  [1418.836625     45.27480298]\n",
      "Val Loss Meta Info:  [56758.485, 62595.125]\n",
      "\n",
      "Epoch: 50, NLL Loss: 1463.99696484375, Val Loss: 126157.1640625, Time took: 0.4142439365386963\n",
      "Train loss Meta Info:  [1418.75895703   45.23800238]\n",
      "Val Loss Meta Info:  [56757.865, 69399.29]\n",
      "\n",
      "Epoch: 51, NLL Loss: 1463.3198828125, Val Loss: 143352.328125, Time took: 0.4094240665435791\n",
      "Train loss Meta Info:  [1418.73759766   44.58227136]\n",
      "Val Loss Meta Info:  [56759.58, 86592.74]\n",
      "\n",
      "Epoch: 52, NLL Loss: 1463.309734375, Val Loss: 153145.5, Time took: 0.4115746021270752\n",
      "Train loss Meta Info:  [1418.77887891   44.53083722]\n",
      "Val Loss Meta Info:  [56762.51, 96382.99]\n",
      "\n",
      "Epoch: 53, NLL Loss: 1463.30923828125, Val Loss: 150166.828125, Time took: 0.4122774600982666\n",
      "Train loss Meta Info:  [1418.84695313   44.4622962 ]\n",
      "Val Loss Meta Info:  [56762.115, 93404.71]\n",
      "\n",
      "Epoch: 54, NLL Loss: 1462.7750859375, Val Loss: 148156.8125, Time took: 0.40891098976135254\n",
      "Train loss Meta Info:  [1418.83548828   43.93955792]\n",
      "Val Loss Meta Info:  [56761.875, 91394.98]\n",
      "\n",
      "Epoch: 55, NLL Loss: 1463.1830078125, Val Loss: 159528.96875, Time took: 0.4150266647338867\n",
      "Train loss Meta Info:  [1418.82477344   44.3582276 ]\n",
      "Val Loss Meta Info:  [56761.5, 102767.48]\n",
      "\n",
      "Epoch: 56, NLL Loss: 1462.79983984375, Val Loss: 158896.0, Time took: 0.4147505760192871\n",
      "Train loss Meta Info:  [1418.80526172   43.99456079]\n",
      "Val Loss Meta Info:  [56761.995, 102133.97]\n",
      "\n",
      "Epoch: 57, NLL Loss: 1462.9637890625, Val Loss: 158213.0, Time took: 0.4138326644897461\n",
      "Train loss Meta Info:  [1418.80678516   44.15698981]\n",
      "Val Loss Meta Info:  [56761.945, 101451.04]\n",
      "\n",
      "Epoch: 58, NLL Loss: 1462.5771484375, Val Loss: 154319.953125, Time took: 0.4276309013366699\n",
      "Train loss Meta Info:  [1418.79493359   43.78222748]\n",
      "Val Loss Meta Info:  [56760.34, 97559.62]\n",
      "\n",
      "Epoch: 59, NLL Loss: 1462.46811328125, Val Loss: 152349.09375, Time took: 0.43019890785217285\n",
      "Train loss Meta Info:  [1418.75513672   43.71297876]\n",
      "Val Loss Meta Info:  [56758.455, 95590.65]\n",
      "\n",
      "Epoch: 60, NLL Loss: 1462.4941796875, Val Loss: 158800.140625, Time took: 0.4205772876739502\n",
      "Train loss Meta Info:  [1418.71333203   43.78082788]\n",
      "Val Loss Meta Info:  [56757.3, 102042.83]\n",
      "\n",
      "Epoch: 61, NLL Loss: 1462.42883984375, Val Loss: 160137.078125, Time took: 0.42511558532714844\n",
      "Train loss Meta Info:  [1418.69491406   43.73393237]\n",
      "Val Loss Meta Info:  [56756.65, 103380.44]\n",
      "\n",
      "Epoch: 62, NLL Loss: 1462.3636796875, Val Loss: 141308.3125, Time took: 0.4199671745300293\n",
      "Train loss Meta Info:  [1418.67544141   43.68824084]\n",
      "Val Loss Meta Info:  [56756.36, 84551.97]\n",
      "\n",
      "Epoch: 63, NLL Loss: 1462.11799609375, Val Loss: 132207.359375, Time took: 0.41559314727783203\n",
      "Train loss Meta Info:  [1418.66173047   43.4562608 ]\n",
      "Val Loss Meta Info:  [56756.83, 75450.555]\n",
      "\n",
      "Epoch: 64, NLL Loss: 1461.999109375, Val Loss: 127707.59375, Time took: 0.42535400390625\n",
      "Train loss Meta Info:  [1418.66557812   43.33354309]\n",
      "Val Loss Meta Info:  [56757.09, 70950.505]\n",
      "\n",
      "Epoch: 65, NLL Loss: 1461.89847265625, Val Loss: 123755.109375, Time took: 0.4171762466430664\n",
      "Train loss Meta Info:  [1418.66974219   43.22874091]\n",
      "Val Loss Meta Info:  [56757.235, 66997.875]\n",
      "\n",
      "Epoch: 66, NLL Loss: 1462.01243359375, Val Loss: 115746.1796875, Time took: 0.41430091857910156\n",
      "Train loss Meta Info:  [1418.67453906   43.33788812]\n",
      "Val Loss Meta Info:  [56756.17, 58990.01]\n",
      "\n",
      "Epoch: 67, NLL Loss: 1461.74604296875, Val Loss: 110779.859375, Time took: 0.4111299514770508\n",
      "Train loss Meta Info:  [1418.65090234   43.09514337]\n",
      "Val Loss Meta Info:  [56755.765, 54024.11]\n",
      "\n",
      "Epoch: 68, NLL Loss: 1461.5637578125, Val Loss: 107827.015625, Time took: 0.4104502201080322\n",
      "Train loss Meta Info:  [1418.64543359   42.91832507]\n",
      "Val Loss Meta Info:  [56756.405, 51070.63]\n",
      "\n",
      "Epoch: 69, NLL Loss: 1461.74089453125, Val Loss: 102242.7890625, Time took: 0.41467761993408203\n",
      "Train loss Meta Info:  [1418.66280078   43.07809375]\n",
      "Val Loss Meta Info:  [56756.03, 45486.75]\n",
      "\n",
      "Epoch: 70, NLL Loss: 1461.72973046875, Val Loss: 100354.5546875, Time took: 0.41362714767456055\n",
      "Train loss Meta Info:  [1418.65865234   43.07108215]\n",
      "Val Loss Meta Info:  [56759.285, 43595.28]\n",
      "\n",
      "Epoch: 71, NLL Loss: 1461.562375, Val Loss: 100627.03125, Time took: 0.4139740467071533\n",
      "Train loss Meta Info:  [1418.74103906   42.82136334]\n",
      "Val Loss Meta Info:  [56757.68, 43869.36]\n",
      "\n",
      "Epoch: 72, NLL Loss: 1461.5593515625, Val Loss: 95327.5, Time took: 0.4106905460357666\n",
      "Train loss Meta Info:  [1418.70083594   42.85852167]\n",
      "Val Loss Meta Info:  [56757.26, 38570.245]\n",
      "\n",
      "Epoch: 73, NLL Loss: 1462.011796875, Val Loss: 102670.796875, Time took: 0.41571807861328125\n",
      "Train loss Meta Info:  [1418.68388281   43.32792822]\n",
      "Val Loss Meta Info:  [56756.31, 45914.515]\n",
      "\n",
      "Epoch: 74, NLL Loss: 1462.16974609375, Val Loss: 96343.046875, Time took: 0.41077160835266113\n",
      "Train loss Meta Info:  [1418.65829297   43.51145398]\n",
      "Val Loss Meta Info:  [56756.705, 39586.335]\n",
      "\n",
      "Epoch: 75, NLL Loss: 1461.974328125, Val Loss: 98592.359375, Time took: 0.40742945671081543\n",
      "Train loss Meta Info:  [1418.66939844   43.30492786]\n",
      "Val Loss Meta Info:  [56757.71, 41834.645]\n",
      "\n",
      "Epoch: 76, NLL Loss: 1461.494875, Val Loss: 100069.75, Time took: 0.4139120578765869\n",
      "Train loss Meta Info:  [1418.69767187   42.79719208]\n",
      "Val Loss Meta Info:  [56755.95, 43313.79]\n",
      "\n",
      "Epoch: 77, NLL Loss: 1461.48314453125, Val Loss: 96228.3359375, Time took: 0.41384077072143555\n",
      "Train loss Meta Info:  [1418.65676953   42.8263783 ]\n",
      "Val Loss Meta Info:  [56754.89, 39473.455]\n",
      "\n",
      "Epoch: 78, NLL Loss: 1461.85259375, Val Loss: 106752.046875, Time took: 0.41396594047546387\n",
      "Train loss Meta Info:  [1418.62785938   43.22473938]\n",
      "Val Loss Meta Info:  [56755.52, 49996.53]\n",
      "\n",
      "Epoch: 79, NLL Loss: 1461.41130859375, Val Loss: 108293.234375, Time took: 0.41033482551574707\n",
      "Train loss Meta Info:  [1418.64885156   42.76245575]\n",
      "Val Loss Meta Info:  [56755.24, 51538.0]\n",
      "\n",
      "Epoch: 80, NLL Loss: 1461.68148828125, Val Loss: 96159.1796875, Time took: 0.412111759185791\n",
      "Train loss Meta Info:  [1418.64159766   43.03988416]\n",
      "Val Loss Meta Info:  [56754.99, 39404.1825]\n",
      "\n",
      "Epoch: 81, NLL Loss: 1461.8464765625, Val Loss: 103234.8359375, Time took: 0.41029930114746094\n",
      "Train loss Meta Info:  [1418.62319531   43.22325751]\n",
      "Val Loss Meta Info:  [56754.81, 46480.045]\n",
      "\n",
      "Epoch: 82, NLL Loss: 1461.23337109375, Val Loss: 103898.0, Time took: 0.4089655876159668\n",
      "Train loss Meta Info:  [1418.611375     42.62198376]\n",
      "Val Loss Meta Info:  [56754.34, 47143.665]\n",
      "\n",
      "Epoch: 83, NLL Loss: 1461.7104609375, Val Loss: 92082.28125, Time took: 0.4158146381378174\n",
      "Train loss Meta Info:  [1418.59892969   43.11154736]\n",
      "Val Loss Meta Info:  [56754.92, 35327.3625]\n",
      "\n",
      "Epoch: 84, NLL Loss: 1462.2248203125, Val Loss: 97346.296875, Time took: 0.41734862327575684\n",
      "Train loss Meta Info:  [1418.61948047   43.60531305]\n",
      "Val Loss Meta Info:  [56754.85, 40591.44]\n",
      "\n",
      "Epoch: 85, NLL Loss: 1461.1971015625, Val Loss: 102520.2109375, Time took: 0.4201853275299072\n",
      "Train loss Meta Info:  [1418.62458594   42.57249274]\n",
      "Val Loss Meta Info:  [56753.99, 45766.24]\n",
      "\n",
      "Epoch: 86, NLL Loss: 1462.28691015625, Val Loss: 95832.0859375, Time took: 0.41391992568969727\n",
      "Train loss Meta Info:  [1418.60534375   43.68157996]\n",
      "Val Loss Meta Info:  [56754.76, 39077.3225]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, NLL Loss: 1461.8253203125, Val Loss: 97263.9140625, Time took: 0.4161362648010254\n",
      "Train loss Meta Info:  [1418.61060547   43.21470374]\n",
      "Val Loss Meta Info:  [56755.32, 40508.6]\n",
      "\n",
      "Epoch: 88, NLL Loss: 1461.902234375, Val Loss: 110024.8984375, Time took: 0.41614675521850586\n",
      "Train loss Meta Info:  [1418.61696484   43.28526318]\n",
      "Val Loss Meta Info:  [56754.54, 53270.365]\n",
      "\n",
      "Epoch: 89, NLL Loss: 1461.44580859375, Val Loss: 106974.078125, Time took: 0.4220263957977295\n",
      "Train loss Meta Info:  [1418.60521484   42.84059485]\n",
      "Val Loss Meta Info:  [56754.555, 50219.525]\n",
      "\n",
      "Epoch: 90, NLL Loss: 1461.7337265625, Val Loss: 101962.234375, Time took: 0.4188528060913086\n",
      "Train loss Meta Info:  [1418.61328125   43.12045563]\n",
      "Val Loss Meta Info:  [56754.65, 45207.595]\n",
      "\n",
      "Epoch: 91, NLL Loss: 1461.4495625, Val Loss: 98897.9296875, Time took: 0.42453598976135254\n",
      "Train loss Meta Info:  [1418.61021094   42.83934485]\n",
      "Val Loss Meta Info:  [56754.57, 42143.365]\n",
      "\n",
      "Epoch: 92, NLL Loss: 1461.61555859375, Val Loss: 103998.6796875, Time took: 0.42008209228515625\n",
      "Train loss Meta Info:  [1418.6009375    43.01460156]\n",
      "Val Loss Meta Info:  [56754.82, 47243.85]\n",
      "\n",
      "Epoch: 93, NLL Loss: 1461.36631640625, Val Loss: 108871.2265625, Time took: 0.43023037910461426\n",
      "Train loss Meta Info:  [1418.60101172   42.76530377]\n",
      "Val Loss Meta Info:  [56753.82, 52117.41]\n",
      "\n",
      "Epoch: 94, NLL Loss: 1461.37237109375, Val Loss: 99839.6171875, Time took: 0.41692471504211426\n",
      "Train loss Meta Info:  [1418.58055078   42.79181989]\n",
      "Val Loss Meta Info:  [56753.775, 43085.845]\n",
      "\n",
      "Epoch: 95, NLL Loss: 1461.32421484375, Val Loss: 97310.03125, Time took: 0.42940521240234375\n",
      "Train loss Meta Info:  [1418.57949219   42.74471667]\n",
      "Val Loss Meta Info:  [56754.19, 40555.84]\n",
      "\n",
      "Epoch: 96, NLL Loss: 1461.2460859375, Val Loss: 98238.9296875, Time took: 0.4239473342895508\n",
      "Train loss Meta Info:  [1418.57993359   42.66615125]\n",
      "Val Loss Meta Info:  [56754.375, 41484.5525]\n",
      "\n",
      "Epoch: 97, NLL Loss: 1461.14065234375, Val Loss: 98339.3984375, Time took: 0.4329984188079834\n",
      "Train loss Meta Info:  [1418.57615625   42.56451373]\n",
      "Val Loss Meta Info:  [56753.635, 41585.7625]\n",
      "\n",
      "Epoch: 98, NLL Loss: 1461.01428125, Val Loss: 93158.78125, Time took: 0.42795610427856445\n",
      "Train loss Meta Info:  [1418.56547266   42.44880945]\n",
      "Val Loss Meta Info:  [56753.22, 36405.5525]\n",
      "\n",
      "Epoch: 99, NLL Loss: 1461.05263671875, Val Loss: 95253.7890625, Time took: 0.4286930561065674\n",
      "Train loss Meta Info:  [1418.56476953   42.48785706]\n",
      "Val Loss Meta Info:  [56753.39, 38500.4]\n",
      "\n",
      "Epoch: 100, NLL Loss: 1460.92266015625, Val Loss: 93657.1171875, Time took: 0.44003963470458984\n",
      "Train loss Meta Info:  [1418.57230859   42.35033057]\n",
      "Val Loss Meta Info:  [56753.805, 36903.3125]\n",
      "\n",
      "Epoch: 101, NLL Loss: 1460.75131640625, Val Loss: 87756.8984375, Time took: 0.4273860454559326\n",
      "Train loss Meta Info:  [1418.56989844   42.18140503]\n",
      "Val Loss Meta Info:  [56754.455, 31002.4525]\n",
      "\n",
      "Epoch: 102, NLL Loss: 1460.99183984375, Val Loss: 91880.4140625, Time took: 0.44605517387390137\n",
      "Train loss Meta Info:  [1418.57377344   42.41806213]\n",
      "Val Loss Meta Info:  [56754.485, 35125.9425]\n",
      "\n",
      "Epoch: 103, NLL Loss: 1460.8642578125, Val Loss: 87323.125, Time took: 0.4460570812225342\n",
      "Train loss Meta Info:  [1418.57425391   42.2900094 ]\n",
      "Val Loss Meta Info:  [56753.85, 30569.2875]\n",
      "\n",
      "Epoch: 104, NLL Loss: 1460.98487109375, Val Loss: 92347.234375, Time took: 0.4377419948577881\n",
      "Train loss Meta Info:  [1418.56658984   42.41829333]\n",
      "Val Loss Meta Info:  [56753.81, 35593.4225]\n",
      "\n",
      "Epoch: 105, NLL Loss: 1460.97765625, Val Loss: 84838.9765625, Time took: 0.4239010810852051\n",
      "Train loss Meta Info:  [1418.56644922   42.41116663]\n",
      "Val Loss Meta Info:  [56753.94, 28085.0275]\n",
      "\n",
      "Epoch: 106, NLL Loss: 1461.3325625, Val Loss: 91237.1875, Time took: 0.4275214672088623\n",
      "Train loss Meta Info:  [1418.56026953   42.77228625]\n",
      "Val Loss Meta Info:  [56754.385, 34482.8]\n",
      "\n",
      "Epoch: 107, NLL Loss: 1461.2303984375, Val Loss: 88017.8671875, Time took: 0.42418551445007324\n",
      "Train loss Meta Info:  [1418.56966797   42.66071942]\n",
      "Val Loss Meta Info:  [56753.965, 31263.91]\n",
      "\n",
      "Epoch: 108, NLL Loss: 1461.05091015625, Val Loss: 90447.890625, Time took: 0.4251394271850586\n",
      "Train loss Meta Info:  [1418.55964453   42.49126294]\n",
      "Val Loss Meta Info:  [56753.94, 33693.9525]\n",
      "\n",
      "Epoch: 109, NLL Loss: 1460.7375, Val Loss: 93462.765625, Time took: 0.4289224147796631\n",
      "Train loss Meta Info:  [1418.55895313   42.17853601]\n",
      "Val Loss Meta Info:  [56753.87, 36708.8925]\n",
      "\n",
      "Epoch: 110, NLL Loss: 1461.27018359375, Val Loss: 89197.140625, Time took: 0.42760705947875977\n",
      "Train loss Meta Info:  [1418.55128125   42.71889044]\n",
      "Val Loss Meta Info:  [56754.545, 32442.5925]\n",
      "\n",
      "Epoch: 111, NLL Loss: 1461.1540078125, Val Loss: 90440.875, Time took: 0.41991472244262695\n",
      "Train loss Meta Info:  [1418.55646484   42.59754242]\n",
      "Val Loss Meta Info:  [56754.43, 33686.445]\n",
      "\n",
      "Epoch: 112, NLL Loss: 1460.9895859375, Val Loss: 101895.1875, Time took: 0.41359853744506836\n",
      "Train loss Meta Info:  [1418.5525       42.43708234]\n",
      "Val Loss Meta Info:  [56753.79, 45141.4]\n",
      "\n",
      "Epoch: 113, NLL Loss: 1461.088609375, Val Loss: 100658.5, Time took: 0.4171109199523926\n",
      "Train loss Meta Info:  [1418.54580859   42.54279938]\n",
      "Val Loss Meta Info:  [56753.775, 43904.725]\n",
      "\n",
      "Epoch: 114, NLL Loss: 1460.8086796875, Val Loss: 92740.9296875, Time took: 0.4119584560394287\n",
      "Train loss Meta Info:  [1418.55162109   42.25705762]\n",
      "Val Loss Meta Info:  [56753.715, 35987.215]\n",
      "\n",
      "Epoch: 115, NLL Loss: 1460.92574609375, Val Loss: 91958.4609375, Time took: 0.41407251358032227\n",
      "Train loss Meta Info:  [1418.5443125    42.38141235]\n",
      "Val Loss Meta Info:  [56753.845, 35204.6125]\n",
      "\n",
      "Epoch: 116, NLL Loss: 1460.68559375, Val Loss: 91248.6484375, Time took: 0.41764068603515625\n",
      "Train loss Meta Info:  [1418.54183984   42.14373798]\n",
      "Val Loss Meta Info:  [56754.405, 34494.25]\n",
      "\n",
      "Epoch: 117, NLL Loss: 1460.91372265625, Val Loss: 86829.4609375, Time took: 0.42107677459716797\n",
      "Train loss Meta Info:  [1418.55053125   42.36318103]\n",
      "Val Loss Meta Info:  [56753.845, 30075.6125]\n",
      "\n",
      "Epoch: 118, NLL Loss: 1460.9054453125, Val Loss: 90411.234375, Time took: 0.4199864864349365\n",
      "Train loss Meta Info:  [1418.53259766   42.37284021]\n",
      "Val Loss Meta Info:  [56753.74, 33657.49]\n",
      "\n",
      "Epoch: 119, NLL Loss: 1460.60848828125, Val Loss: 90818.734375, Time took: 0.43132638931274414\n",
      "Train loss Meta Info:  [1418.53520703   42.0733186 ]\n",
      "Val Loss Meta Info:  [56753.71, 34065.035]\n",
      "\n",
      "Epoch: 120, NLL Loss: 1460.8446328125, Val Loss: 85791.5078125, Time took: 0.4389057159423828\n",
      "Train loss Meta Info:  [1418.53474219   42.30986975]\n",
      "Val Loss Meta Info:  [56753.895, 29037.6175]\n",
      "\n",
      "Epoch: 121, NLL Loss: 1461.1591328125, Val Loss: 88136.78125, Time took: 0.44814157485961914\n",
      "Train loss Meta Info:  [1418.52692578   42.6322074 ]\n",
      "Val Loss Meta Info:  [56753.99, 31382.79]\n",
      "\n",
      "Epoch: 122, NLL Loss: 1460.49093359375, Val Loss: 91024.9609375, Time took: 0.4365503787994385\n",
      "Train loss Meta Info:  [1418.52714844   41.96376123]\n",
      "Val Loss Meta Info:  [56753.77, 34271.195]\n",
      "\n",
      "Epoch: 123, NLL Loss: 1460.781390625, Val Loss: 86676.1796875, Time took: 0.44056224822998047\n",
      "Train loss Meta Info:  [1418.5253125    42.25610712]\n",
      "Val Loss Meta Info:  [56754.17, 29922.005]\n",
      "\n",
      "Epoch: 124, NLL Loss: 1461.28101171875, Val Loss: 88940.6015625, Time took: 0.4226713180541992\n",
      "Train loss Meta Info:  [1418.52779687   42.75320996]\n",
      "Val Loss Meta Info:  [56754.105, 32186.4975]\n",
      "\n",
      "Epoch: 125, NLL Loss: 1460.4314609375, Val Loss: 99669.234375, Time took: 0.42603445053100586\n",
      "Train loss Meta Info:  [1418.52210547   41.90936285]\n",
      "Val Loss Meta Info:  [56754.475, 42914.76]\n",
      "\n",
      "Epoch: 126, NLL Loss: 1461.56483203125, Val Loss: 87134.65625, Time took: 0.42374539375305176\n",
      "Train loss Meta Info:  [1418.52801563   43.03681763]\n",
      "Val Loss Meta Info:  [56754.31, 30380.3575]\n",
      "\n",
      "Epoch: 127, NLL Loss: 1461.34137890625, Val Loss: 93483.21875, Time took: 0.42602086067199707\n",
      "Train loss Meta Info:  [1418.52375391   42.81763031]\n",
      "Val Loss Meta Info:  [56754.03, 36729.1825]\n",
      "\n",
      "Epoch: 128, NLL Loss: 1461.0631484375, Val Loss: 98524.1796875, Time took: 0.424854040145874\n",
      "Train loss Meta Info:  [1418.51965625   42.54349188]\n",
      "Val Loss Meta Info:  [56754.31, 41769.865]\n",
      "\n",
      "Epoch: 129, NLL Loss: 1461.3811484375, Val Loss: 96600.5390625, Time took: 0.4276161193847656\n",
      "Train loss Meta Info:  [1418.52406641   42.85708081]\n",
      "Val Loss Meta Info:  [56754.31, 39846.225]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, NLL Loss: 1460.6780625, Val Loss: 93300.9140625, Time took: 0.42639994621276855\n",
      "Train loss Meta Info:  [1418.51830469   42.15975555]\n",
      "Val Loss Meta Info:  [56754.23, 36546.685]\n",
      "\n",
      "Epoch: 131, NLL Loss: 1461.11359765625, Val Loss: 95401.4609375, Time took: 0.41133594512939453\n",
      "Train loss Meta Info:  [1418.51592578   42.59768646]\n",
      "Val Loss Meta Info:  [56754.4, 38647.065]\n",
      "\n",
      "Epoch: 132, NLL Loss: 1460.64925, Val Loss: 99029.0390625, Time took: 0.41181230545043945\n",
      "Train loss Meta Info:  [1418.51773047   42.13153912]\n",
      "Val Loss Meta Info:  [56754.72, 42274.31]\n",
      "\n",
      "Epoch: 133, NLL Loss: 1460.97366796875, Val Loss: 97087.125, Time took: 0.41220974922180176\n",
      "Train loss Meta Info:  [1418.524        42.44965088]\n",
      "Val Loss Meta Info:  [56754.545, 40332.585]\n",
      "\n",
      "Epoch: 134, NLL Loss: 1460.47495703125, Val Loss: 87549.6015625, Time took: 0.4136812686920166\n",
      "Train loss Meta Info:  [1418.52108203   41.95388385]\n",
      "Val Loss Meta Info:  [56754.425, 30795.17]\n",
      "\n",
      "Epoch: 135, NLL Loss: 1460.8127421875, Val Loss: 92859.6953125, Time took: 0.40969395637512207\n",
      "Train loss Meta Info:  [1418.51798828   42.29474689]\n",
      "Val Loss Meta Info:  [56754.635, 36105.06]\n",
      "\n",
      "Epoch: 136, NLL Loss: 1460.39928125, Val Loss: 97242.8203125, Time took: 0.41201066970825195\n",
      "Train loss Meta Info:  [1418.51533594   41.88396484]\n",
      "Val Loss Meta Info:  [56754.9, 40487.9125]\n",
      "\n",
      "Epoch: 137, NLL Loss: 1460.6278828125, Val Loss: 85986.9765625, Time took: 0.4090137481689453\n",
      "Train loss Meta Info:  [1418.51252344   42.11535406]\n",
      "Val Loss Meta Info:  [56754.87, 29232.12]\n",
      "\n",
      "Epoch: 138, NLL Loss: 1460.63127734375, Val Loss: 87680.9765625, Time took: 0.4061434268951416\n",
      "Train loss Meta Info:  [1418.50797656   42.12330084]\n",
      "Val Loss Meta Info:  [56754.96, 30926.03]\n",
      "\n",
      "Epoch: 139, NLL Loss: 1460.37812890625, Val Loss: 97234.1015625, Time took: 0.4146456718444824\n",
      "Train loss Meta Info:  [1418.50685937   41.87127612]\n",
      "Val Loss Meta Info:  [56755.01, 40479.085]\n",
      "\n",
      "Epoch: 140, NLL Loss: 1460.640515625, Val Loss: 89006.7109375, Time took: 0.4127364158630371\n",
      "Train loss Meta Info:  [1418.50769531   42.13281122]\n",
      "Val Loss Meta Info:  [56755.21, 32251.495]\n",
      "\n",
      "Epoch: 141, NLL Loss: 1460.27454296875, Val Loss: 84875.296875, Time took: 0.41510534286499023\n",
      "Train loss Meta Info:  [1418.5079375    41.76661365]\n",
      "Val Loss Meta Info:  [56755.49, 28119.805]\n",
      "\n",
      "Epoch: 142, NLL Loss: 1460.48176953125, Val Loss: 93127.1171875, Time took: 0.41129541397094727\n",
      "Train loss Meta Info:  [1418.50958203   41.97220367]\n",
      "Val Loss Meta Info:  [56755.45, 36371.665]\n",
      "\n",
      "Epoch: 143, NLL Loss: 1460.523546875, Val Loss: 91808.75, Time took: 0.4140763282775879\n",
      "Train loss Meta Info:  [1418.50869922   42.0148808 ]\n",
      "Val Loss Meta Info:  [56755.32, 35053.435]\n",
      "\n",
      "Epoch: 144, NLL Loss: 1460.2463125, Val Loss: 90679.015625, Time took: 0.41826891899108887\n",
      "Train loss Meta Info:  [1418.50182422   41.74447211]\n",
      "Val Loss Meta Info:  [56755.245, 33923.79]\n",
      "\n",
      "Epoch: 145, NLL Loss: 1460.4093515625, Val Loss: 95623.9609375, Time took: 0.41095709800720215\n",
      "Train loss Meta Info:  [1418.49723438   41.91212628]\n",
      "Val Loss Meta Info:  [56755.22, 38868.7375]\n",
      "\n",
      "Epoch: 146, NLL Loss: 1460.25841015625, Val Loss: 95916.3046875, Time took: 0.43090128898620605\n",
      "Train loss Meta Info:  [1418.49451563   41.76388666]\n",
      "Val Loss Meta Info:  [56755.11, 39161.1925]\n",
      "\n",
      "Epoch: 147, NLL Loss: 1460.14496484375, Val Loss: 86759.8359375, Time took: 0.41976380348205566\n",
      "Train loss Meta Info:  [1418.49227734   41.65270575]\n",
      "Val Loss Meta Info:  [56755.03, 30004.805]\n",
      "\n",
      "Epoch: 148, NLL Loss: 1460.41650390625, Val Loss: 93430.859375, Time took: 0.41935300827026367\n",
      "Train loss Meta Info:  [1418.49017969   41.92631873]\n",
      "Val Loss Meta Info:  [56755.36, 36675.4975]\n",
      "\n",
      "Epoch: 149, NLL Loss: 1460.33362109375, Val Loss: 88768.234375, Time took: 0.4139225482940674\n",
      "Train loss Meta Info:  [1418.4930625    41.84056567]\n",
      "Val Loss Meta Info:  [56755.51, 32012.73]\n",
      "\n",
      "Epoch: 150, NLL Loss: 1460.11978125, Val Loss: 88074.28125, Time took: 0.41544532775878906\n",
      "Train loss Meta Info:  [1418.48861719   41.63116077]\n",
      "Val Loss Meta Info:  [56755.565, 31318.7125]\n",
      "\n",
      "Epoch: 151, NLL Loss: 1460.1677265625, Val Loss: 96595.4296875, Time took: 0.415851354598999\n",
      "Train loss Meta Info:  [1418.48657031   41.68110919]\n",
      "Val Loss Meta Info:  [56755.55, 39839.8725]\n",
      "\n",
      "Epoch: 152, NLL Loss: 1460.21728515625, Val Loss: 88487.234375, Time took: 0.4101722240447998\n",
      "Train loss Meta Info:  [1418.48744922   41.72981635]\n",
      "Val Loss Meta Info:  [56755.37, 31731.8675]\n",
      "\n",
      "Epoch: 153, NLL Loss: 1460.068625, Val Loss: 91302.8203125, Time took: 0.4148104190826416\n",
      "Train loss Meta Info:  [1418.48359375   41.58503491]\n",
      "Val Loss Meta Info:  [56755.395, 34547.4275]\n",
      "\n",
      "Epoch: 154, NLL Loss: 1460.0128359375, Val Loss: 93065.875, Time took: 0.4151725769042969\n",
      "Train loss Meta Info:  [1418.48170703   41.5311156 ]\n",
      "Val Loss Meta Info:  [56755.59, 36310.295]\n",
      "\n",
      "Epoch: 155, NLL Loss: 1460.09842578125, Val Loss: 90076.9375, Time took: 0.4192826747894287\n",
      "Train loss Meta Info:  [1418.48078906   41.61765546]\n",
      "Val Loss Meta Info:  [56755.55, 33321.3975]\n",
      "\n",
      "Epoch: 156, NLL Loss: 1460.1372109375, Val Loss: 92531.6796875, Time took: 0.42438459396362305\n",
      "Train loss Meta Info:  [1418.47665625   41.66055231]\n",
      "Val Loss Meta Info:  [56755.73, 35775.9425]\n",
      "\n",
      "Epoch: 157, NLL Loss: 1460.10028515625, Val Loss: 91516.4375, Time took: 0.41454195976257324\n",
      "Train loss Meta Info:  [1418.47711328   41.62314581]\n",
      "Val Loss Meta Info:  [56755.73, 34760.7075]\n",
      "\n",
      "Epoch: 158, NLL Loss: 1459.9784453125, Val Loss: 90464.90625, Time took: 0.41573309898376465\n",
      "Train loss Meta Info:  [1418.47461719   41.50381604]\n",
      "Val Loss Meta Info:  [56755.635, 33709.2775]\n",
      "\n",
      "Epoch: 159, NLL Loss: 1460.00598828125, Val Loss: 92723.578125, Time took: 0.40987157821655273\n",
      "Train loss Meta Info:  [1418.47189453   41.53409119]\n",
      "Val Loss Meta Info:  [56755.555, 35968.0275]\n",
      "\n",
      "Epoch: 160, NLL Loss: 1460.154984375, Val Loss: 83575.515625, Time took: 0.4246797561645508\n",
      "Train loss Meta Info:  [1418.47298828   41.6820061 ]\n",
      "Val Loss Meta Info:  [56755.46, 26820.0575]\n",
      "\n",
      "Epoch: 161, NLL Loss: 1460.4231171875, Val Loss: 94641.359375, Time took: 0.41554808616638184\n",
      "Train loss Meta Info:  [1418.46786719   41.95525311]\n",
      "Val Loss Meta Info:  [56755.76, 37885.6]\n",
      "\n",
      "Epoch: 162, NLL Loss: 1460.5749453125, Val Loss: 87083.78125, Time took: 0.41562891006469727\n",
      "Train loss Meta Info:  [1418.46914453   42.1058374 ]\n",
      "Val Loss Meta Info:  [56755.91, 30327.8725]\n",
      "\n",
      "Epoch: 163, NLL Loss: 1460.0918125, Val Loss: 92720.9609375, Time took: 0.4161381721496582\n",
      "Train loss Meta Info:  [1418.46432422   41.62745856]\n",
      "Val Loss Meta Info:  [56756.09, 35964.8725]\n",
      "\n",
      "Epoch: 164, NLL Loss: 1460.031234375, Val Loss: 93237.515625, Time took: 0.4311213493347168\n",
      "Train loss Meta Info:  [1418.46359766   41.56764465]\n",
      "Val Loss Meta Info:  [56756.02, 36481.505]\n",
      "\n",
      "Epoch: 165, NLL Loss: 1460.03530859375, Val Loss: 90988.71875, Time took: 0.42060303688049316\n",
      "Train loss Meta Info:  [1418.46147266   41.5738241 ]\n",
      "Val Loss Meta Info:  [56755.9, 34232.8225]\n",
      "\n",
      "Epoch: 166, NLL Loss: 1460.04634765625, Val Loss: 93743.96875, Time took: 0.4158318042755127\n",
      "Train loss Meta Info:  [1418.46230078   41.58405792]\n",
      "Val Loss Meta Info:  [56755.99, 36987.9625]\n",
      "\n",
      "Epoch: 167, NLL Loss: 1460.0964453125, Val Loss: 92570.4140625, Time took: 0.41722846031188965\n",
      "Train loss Meta Info:  [1418.46148438   41.63494183]\n",
      "Val Loss Meta Info:  [56756.15, 35814.2775]\n",
      "\n",
      "Epoch: 168, NLL Loss: 1459.91612109375, Val Loss: 95593.296875, Time took: 0.41686105728149414\n",
      "Train loss Meta Info:  [1418.45689844   41.45923145]\n",
      "Val Loss Meta Info:  [56756.575, 38836.72]\n",
      "\n",
      "Epoch: 169, NLL Loss: 1459.9411796875, Val Loss: 92686.15625, Time took: 0.4208683967590332\n",
      "Train loss Meta Info:  [1418.45778125   41.48338446]\n",
      "Val Loss Meta Info:  [56756.565, 35929.5975]\n",
      "\n",
      "Epoch: 170, NLL Loss: 1460.1424296875, Val Loss: 84138.015625, Time took: 0.4145958423614502\n",
      "Train loss Meta Info:  [1418.45616016   41.68628052]\n",
      "Val Loss Meta Info:  [56756.41, 27381.6225]\n",
      "\n",
      "Epoch: 171, NLL Loss: 1460.20059765625, Val Loss: 91831.4140625, Time took: 0.41847753524780273\n",
      "Train loss Meta Info:  [1418.45287891   41.7476925 ]\n",
      "Val Loss Meta Info:  [56756.575, 35074.845]\n",
      "\n",
      "Epoch: 172, NLL Loss: 1460.0968046875, Val Loss: 90442.21875, Time took: 0.41732192039489746\n",
      "Train loss Meta Info:  [1418.45333203   41.64346973]\n",
      "Val Loss Meta Info:  [56756.495, 33685.7375]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173, NLL Loss: 1459.9007578125, Val Loss: 87331.2265625, Time took: 0.42354869842529297\n",
      "Train loss Meta Info:  [1418.44944141   41.45131122]\n",
      "Val Loss Meta Info:  [56756.355, 30574.875]\n",
      "\n",
      "Epoch: 174, NLL Loss: 1460.0692265625, Val Loss: 102931.359375, Time took: 0.4225592613220215\n",
      "Train loss Meta Info:  [1418.44421875   41.62498981]\n",
      "Val Loss Meta Info:  [56756.73, 46174.61]\n",
      "\n",
      "Epoch: 175, NLL Loss: 1460.17372265625, Val Loss: 88596.546875, Time took: 0.42085766792297363\n",
      "Train loss Meta Info:  [1418.44694922   41.72678265]\n",
      "Val Loss Meta Info:  [56756.83, 31839.7225]\n",
      "\n",
      "Epoch: 176, NLL Loss: 1460.03976171875, Val Loss: 92093.109375, Time took: 0.41774749755859375\n",
      "Train loss Meta Info:  [1418.44430469   41.59547321]\n",
      "Val Loss Meta Info:  [56756.75, 35336.35]\n",
      "\n",
      "Epoch: 177, NLL Loss: 1460.0770546875, Val Loss: 91416.609375, Time took: 0.4291188716888428\n",
      "Train loss Meta Info:  [1418.44056641   41.63649988]\n",
      "Val Loss Meta Info:  [56756.66, 34659.9475]\n",
      "\n",
      "Epoch: 178, NLL Loss: 1459.87686328125, Val Loss: 88110.796875, Time took: 0.41982531547546387\n",
      "Train loss Meta Info:  [1418.43685547   41.43997607]\n",
      "Val Loss Meta Info:  [56756.82, 31353.975]\n",
      "\n",
      "Epoch: 179, NLL Loss: 1459.89571484375, Val Loss: 93770.359375, Time took: 0.4225020408630371\n",
      "Train loss Meta Info:  [1418.43626953   41.45944446]\n",
      "Val Loss Meta Info:  [56756.955, 37013.405]\n",
      "\n",
      "Epoch: 180, NLL Loss: 1460.0265078125, Val Loss: 88201.6171875, Time took: 0.41698598861694336\n",
      "Train loss Meta Info:  [1418.43511328   41.59140137]\n",
      "Val Loss Meta Info:  [56756.84, 31444.785]\n",
      "\n",
      "Epoch: 181, NLL Loss: 1459.85509375, Val Loss: 93233.140625, Time took: 0.43335652351379395\n",
      "Train loss Meta Info:  [1418.43295313   41.42212506]\n",
      "Val Loss Meta Info:  [56757.145, 36476.005]\n",
      "\n",
      "Epoch: 182, NLL Loss: 1459.8398515625, Val Loss: 92869.4140625, Time took: 0.44271016120910645\n",
      "Train loss Meta Info:  [1418.43116797   41.40866608]\n",
      "Val Loss Meta Info:  [56757.275, 36112.135]\n",
      "\n",
      "Epoch: 183, NLL Loss: 1459.7564453125, Val Loss: 90093.5390625, Time took: 0.44548559188842773\n",
      "Train loss Meta Info:  [1418.42737109   41.32905115]\n",
      "Val Loss Meta Info:  [56756.995, 33336.5475]\n",
      "\n",
      "Epoch: 184, NLL Loss: 1459.7034296875, Val Loss: 94446.359375, Time took: 0.4232761859893799\n",
      "Train loss Meta Info:  [1418.42494141   41.27848242]\n",
      "Val Loss Meta Info:  [56757.13, 37689.23]\n",
      "\n",
      "Epoch: 185, NLL Loss: 1459.80601171875, Val Loss: 83859.3125, Time took: 0.4251229763031006\n",
      "Train loss Meta Info:  [1418.42497266   41.38104865]\n",
      "Val Loss Meta Info:  [56757.43, 27101.875]\n",
      "\n",
      "Epoch: 186, NLL Loss: 1459.83037109375, Val Loss: 94120.828125, Time took: 0.42349767684936523\n",
      "Train loss Meta Info:  [1418.41846094   41.41191284]\n",
      "Val Loss Meta Info:  [56757.875, 37362.95]\n",
      "\n",
      "Epoch: 187, NLL Loss: 1459.95621875, Val Loss: 88199.7109375, Time took: 0.43034958839416504\n",
      "Train loss Meta Info:  [1418.42007812   41.5361546 ]\n",
      "Val Loss Meta Info:  [56757.45, 31442.2675]\n",
      "\n",
      "Epoch: 188, NLL Loss: 1460.0700234375, Val Loss: 93150.359375, Time took: 0.4200165271759033\n",
      "Train loss Meta Info:  [1418.41812109   41.65190411]\n",
      "Val Loss Meta Info:  [56757.74, 36392.62]\n",
      "\n",
      "Epoch: 189, NLL Loss: 1460.05569140625, Val Loss: 90748.3203125, Time took: 0.4254319667816162\n",
      "Train loss Meta Info:  [1418.41405859   41.64164764]\n",
      "Val Loss Meta Info:  [56757.63, 33990.6925]\n",
      "\n",
      "Epoch: 190, NLL Loss: 1459.7743515625, Val Loss: 89821.6015625, Time took: 0.4114243984222412\n",
      "Train loss Meta Info:  [1418.40931641   41.3650307 ]\n",
      "Val Loss Meta Info:  [56757.73, 33063.8725]\n",
      "\n",
      "Epoch: 191, NLL Loss: 1459.88161328125, Val Loss: 91398.4609375, Time took: 0.40863728523254395\n",
      "Train loss Meta Info:  [1418.40786328   41.47373499]\n",
      "Val Loss Meta Info:  [56758.07, 34640.3825]\n",
      "\n",
      "Epoch: 192, NLL Loss: 1459.88907421875, Val Loss: 90409.65625, Time took: 0.40871739387512207\n",
      "Train loss Meta Info:  [1418.4086875    41.48040649]\n",
      "Val Loss Meta Info:  [56757.81, 33651.8525]\n",
      "\n",
      "Epoch: 193, NLL Loss: 1459.68583984375, Val Loss: 99960.640625, Time took: 0.40888476371765137\n",
      "Train loss Meta Info:  [1418.40367578   41.28214313]\n",
      "Val Loss Meta Info:  [56758.305, 43202.345]\n",
      "\n",
      "Epoch: 194, NLL Loss: 1459.7375859375, Val Loss: 90505.65625, Time took: 0.4051792621612549\n",
      "Train loss Meta Info:  [1418.40520703   41.33234796]\n",
      "Val Loss Meta Info:  [56758.545, 33747.1075]\n",
      "\n",
      "Epoch: 195, NLL Loss: 1459.74098828125, Val Loss: 88671.6796875, Time took: 0.42629551887512207\n",
      "Train loss Meta Info:  [1418.40205859   41.33893768]\n",
      "Val Loss Meta Info:  [56757.9, 31913.77]\n",
      "\n",
      "Epoch: 196, NLL Loss: 1459.7580390625, Val Loss: 93163.4140625, Time took: 0.4184272289276123\n",
      "Train loss Meta Info:  [1418.39582812   41.36220105]\n",
      "Val Loss Meta Info:  [56758.245, 36405.1775]\n",
      "\n",
      "Epoch: 197, NLL Loss: 1459.91928125, Val Loss: 82565.9453125, Time took: 0.4203176498413086\n",
      "Train loss Meta Info:  [1418.39688672   41.52239093]\n",
      "Val Loss Meta Info:  [56758.38, 25807.5625]\n",
      "\n",
      "Epoch: 198, NLL Loss: 1459.86726171875, Val Loss: 105005.8203125, Time took: 0.41614508628845215\n",
      "Train loss Meta Info:  [1418.39048047   41.47677612]\n",
      "Val Loss Meta Info:  [56758.68, 48247.155]\n",
      "\n",
      "Epoch: 199, NLL Loss: 1460.09020703125, Val Loss: 90299.140625, Time took: 0.418689489364624\n",
      "Train loss Meta Info:  [1418.39019141   41.70000916]\n",
      "Val Loss Meta Info:  [56758.35, 33540.7925]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=rmtpp, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hrmtpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times: Data Shape: torch.Size([50, 8000, 2]), Val Data Shape: torch.Size([50, 2000, 2])\n",
      "Markers: Data Shape: torch.Size([50, 8000, 20]), Val Data Shape: torch.Size([50, 2000, 20])\n",
      "Epoch: 0, NLL Loss: 1516.4166796875, Val Loss: 62809.91015625, Time took: 0.8191773891448975\n",
      "Train loss Meta Info:  [1.45660838e+03 5.97120386e+01 9.62728846e-02]\n",
      "Val Loss Meta Info:  [61924.735, 865.41125, 19.767064208984376]\n",
      "\n",
      "Epoch: 1, NLL Loss: 1570.9606171875, Val Loss: 63048.6171875, Time took: 0.7823503017425537\n",
      "Train loss Meta Info:  [1.54753283e+03 2.29328391e+01 4.94971273e-01]\n",
      "Val Loss Meta Info:  [60706.565, 2333.8765625, 8.181640625]\n",
      "\n",
      "Epoch: 2, NLL Loss: 1576.44079296875, Val Loss: 61415.35546875, Time took: 0.7858977317810059\n",
      "Train loss Meta Info:  [1.51797221e+03 5.82640049e+01 2.04570010e-01]\n",
      "Val Loss Meta Info:  [59194.1, 2190.0465625, 31.204609375]\n",
      "\n",
      "Epoch: 3, NLL Loss: 1534.813140625, Val Loss: 60538.9140625, Time took: 0.7918968200683594\n",
      "Train loss Meta Info:  [1.47959564e+03 5.44361400e+01 7.81387877e-01]\n",
      "Val Loss Meta Info:  [58346.8, 2166.5675, 25.54728759765625]\n",
      "\n",
      "Epoch: 4, NLL Loss: 1512.20421875, Val Loss: 60177.98828125, Time took: 0.7998480796813965\n",
      "Train loss Meta Info:  [1.45878285e+03 5.27813524e+01 6.40012155e-01]\n",
      "Val Loss Meta Info:  [57814.75, 2242.7240625, 120.52111328125]\n",
      "\n",
      "Epoch: 5, NLL Loss: 1501.31430078125, Val Loss: 60066.828125, Time took: 0.8103859424591064\n",
      "Train loss Meta Info:  [1445.45726172   52.82947961    3.02753273]\n",
      "Val Loss Meta Info:  [57547.33, 2453.203125, 66.2983447265625]\n",
      "\n",
      "Epoch: 6, NLL Loss: 1492.2239140625, Val Loss: 60100.046875, Time took: 0.812122106552124\n",
      "Train loss Meta Info:  [1438.38381641   52.17683679    1.66325678]\n",
      "Val Loss Meta Info:  [57310.09, 2710.699375, 79.266796875]\n",
      "\n",
      "Epoch: 7, NLL Loss: 1485.96901953125, Val Loss: 60177.7734375, Time took: 0.8179738521575928\n",
      "Train loss Meta Info:  [1432.45715234   51.52494177    1.98695046]\n",
      "Val Loss Meta Info:  [57283.77, 2865.0453125, 28.96021484375]\n",
      "\n",
      "Epoch: 8, NLL Loss: 1484.107875, Val Loss: 61052.73046875, Time took: 0.8185110092163086\n",
      "Train loss Meta Info:  [1.43171233e+03 5.16693143e+01 7.26210817e-01]\n",
      "Val Loss Meta Info:  [57104.325, 3938.2734375, 10.13126708984375]\n",
      "\n",
      "Epoch: 9, NLL Loss: 1478.46903125, Val Loss: 62400.6953125, Time took: 0.8184552192687988\n",
      "Train loss Meta Info:  [1.42742392e+03 5.07900522e+01 2.55070221e-01]\n",
      "Val Loss Meta Info:  [57125.255, 5255.5075, 19.93552490234375]\n",
      "\n",
      "Epoch: 10, NLL Loss: 1479.15621875, Val Loss: 62916.953125, Time took: 0.8059558868408203\n",
      "Train loss Meta Info:  [1.42800490e+03 5.06509310e+01 5.00375326e-01]\n",
      "Val Loss Meta Info:  [57064.715, 5796.745625, 55.494296875]\n",
      "\n",
      "Epoch: 11, NLL Loss: 1478.003296875, Val Loss: 65251.171875, Time took: 0.8071916103363037\n",
      "Train loss Meta Info:  [1.42641159e+03 5.02010927e+01 1.39064282e+00]\n",
      "Val Loss Meta Info:  [57024.8, 8179.270625, 47.1054052734375]\n",
      "\n",
      "Epoch: 12, NLL Loss: 1476.01816796875, Val Loss: 70177.890625, Time took: 0.8086025714874268\n",
      "Train loss Meta Info:  [1.42543187e+03 4.94085715e+01 1.17773133e+00]\n",
      "Val Loss Meta Info:  [57110.645, 13039.96, 27.2801220703125]\n",
      "\n",
      "Epoch: 13, NLL Loss: 1477.54044921875, Val Loss: 68447.5703125, Time took: 0.7971000671386719\n",
      "Train loss Meta Info:  [1.42751956e+03 4.93417041e+01 6.79174488e-01]\n",
      "Val Loss Meta Info:  [57187.21, 11236.64, 23.726083984375]\n",
      "\n",
      "Epoch: 14, NLL Loss: 1479.31918359375, Val Loss: 72028.078125, Time took: 0.8046677112579346\n",
      "Train loss Meta Info:  [1.42945906e+03 4.92702985e+01 5.89821979e-01]\n",
      "Val Loss Meta Info:  [57041.86, 14977.08375, 9.13205078125]\n",
      "\n",
      "Epoch: 15, NLL Loss: 1473.95875390625, Val Loss: 75109.7421875, Time took: 0.8075673580169678\n",
      "Train loss Meta Info:  [1.42581909e+03 4.79143271e+01 2.25323328e-01]\n",
      "Val Loss Meta Info:  [56951.94, 18150.655, 7.15316650390625]\n",
      "\n",
      "Epoch: 16, NLL Loss: 1471.14942578125, Val Loss: 84528.328125, Time took: 0.7899720668792725\n",
      "Train loss Meta Info:  [1.42357753e+03 4.73948647e+01 1.77019958e-01]\n",
      "Val Loss Meta Info:  [56972.8, 27548.365, 7.166931762695312]\n",
      "\n",
      "Epoch: 17, NLL Loss: 1471.6023515625, Val Loss: 87440.671875, Time took: 0.80135178565979\n",
      "Train loss Meta Info:  [1.42406140e+03 4.73627940e+01 1.78146822e-01]\n",
      "Val Loss Meta Info:  [56937.75, 30495.6425, 7.271434936523438]\n",
      "\n",
      "Epoch: 18, NLL Loss: 1470.68073046875, Val Loss: 96446.734375, Time took: 0.8003289699554443\n",
      "Train loss Meta Info:  [1.42339933e+03 4.71001681e+01 1.81207538e-01]\n",
      "Val Loss Meta Info:  [56936.995, 39502.7325, 7.012473754882812]\n",
      "\n",
      "Epoch: 19, NLL Loss: 1470.07427734375, Val Loss: 103678.140625, Time took: 0.8037521839141846\n",
      "Train loss Meta Info:  [1.42321394e+03 4.66857667e+01 1.74557665e-01]\n",
      "Val Loss Meta Info:  [56902.58, 46769.775, 5.79845947265625]\n",
      "\n",
      "Epoch: 20, NLL Loss: 1469.27440625, Val Loss: 101206.359375, Time took: 0.8217446804046631\n",
      "Train loss Meta Info:  [1.42237034e+03 4.67598315e+01 1.44230304e-01]\n",
      "Val Loss Meta Info:  [56911.825, 44290.25, 4.278203125]\n",
      "\n",
      "Epoch: 21, NLL Loss: 1469.0888125, Val Loss: 107266.734375, Time took: 0.8176884651184082\n",
      "Train loss Meta Info:  [1.42251827e+03 4.64642714e+01 1.06283697e-01]\n",
      "Val Loss Meta Info:  [56885.77, 50377.44, 3.5178179931640625]\n",
      "\n",
      "Epoch: 22, NLL Loss: 1468.077890625, Val Loss: 122382.25, Time took: 0.8215622901916504\n",
      "Train loss Meta Info:  [1.42183732e+03 4.61530256e+01 8.75305943e-02]\n",
      "Val Loss Meta Info:  [56882.59, 65496.365, 3.3095037841796877]\n",
      "\n",
      "Epoch: 23, NLL Loss: 1467.9626171875, Val Loss: 123062.6796875, Time took: 0.8206996917724609\n",
      "Train loss Meta Info:  [1.42172688e+03 4.61531608e+01 8.25817089e-02]\n",
      "Val Loss Meta Info:  [56856.99, 66202.47, 3.2191888427734376]\n",
      "\n",
      "Epoch: 24, NLL Loss: 1466.90763671875, Val Loss: 124065.515625, Time took: 0.8107028007507324\n",
      "Train loss Meta Info:  [1.42115197e+03 4.56752490e+01 8.04148308e-02]\n",
      "Val Loss Meta Info:  [56863.38, 67199.015, 3.1435641479492187]\n",
      "\n",
      "Epoch: 25, NLL Loss: 1467.06417578125, Val Loss: 122850.984375, Time took: 0.7903025150299072\n",
      "Train loss Meta Info:  [1.42133879e+03 4.56468433e+01 7.85387641e-02]\n",
      "Val Loss Meta Info:  [56841.14, 66006.74, 3.11486572265625]\n",
      "\n",
      "Epoch: 26, NLL Loss: 1466.315796875, Val Loss: 123897.890625, Time took: 0.7888128757476807\n",
      "Train loss Meta Info:  [1.42076274e+03 4.54752656e+01 7.78170369e-02]\n",
      "Val Loss Meta Info:  [56840.63, 67054.18, 3.070252685546875]\n",
      "\n",
      "Epoch: 27, NLL Loss: 1465.9190859375, Val Loss: 126614.1171875, Time took: 0.7986330986022949\n",
      "Train loss Meta Info:  [1.42076814e+03 4.50742875e+01 7.66826195e-02]\n",
      "Val Loss Meta Info:  [56823.185, 69787.96, 2.9797564697265626]\n",
      "\n",
      "Epoch: 28, NLL Loss: 1465.18837109375, Val Loss: 119362.515625, Time took: 0.7966091632843018\n",
      "Train loss Meta Info:  [1.42037659e+03 4.47373779e+01 7.43972819e-02]\n",
      "Val Loss Meta Info:  [56841.29, 62518.405, 2.840001220703125]\n",
      "\n",
      "Epoch: 29, NLL Loss: 1465.3748359375, Val Loss: 188187.0, Time took: 0.793006181716919\n",
      "Train loss Meta Info:  [1.42080811e+03 4.44958787e+01 7.08719519e-02]\n",
      "Val Loss Meta Info:  [56840.93, 131343.44, 2.632208251953125]\n",
      "\n",
      "Epoch: 30, NLL Loss: 1469.2431171875, Val Loss: 91155.65625, Time took: 0.8391728401184082\n",
      "Train loss Meta Info:  [1.42073988e+03 4.84376127e+01 6.56190455e-02]\n",
      "Val Loss Meta Info:  [56856.7, 34296.6175, 2.3396319580078124]\n",
      "\n",
      "Epoch: 31, NLL Loss: 1485.790015625, Val Loss: 146153.109375, Time took: 0.8423678874969482\n",
      "Train loss Meta Info:  [1.42114542e+03 6.45863005e+01 5.83100444e-02]\n",
      "Val Loss Meta Info:  [56836.615, 89314.22, 2.279920806884766]\n",
      "\n",
      "Epoch: 32, NLL Loss: 1467.94567578125, Val Loss: 275432.90625, Time took: 0.8458297252655029\n",
      "Train loss Meta Info:  [1.42055919e+03 4.73296982e+01 5.67696651e-02]\n",
      "Val Loss Meta Info:  [56842.59, 218588.0, 2.2735560607910155]\n",
      "\n",
      "Epoch: 33, NLL Loss: 1485.07961328125, Val Loss: 135745.515625, Time took: 0.8132181167602539\n",
      "Train loss Meta Info:  [1.42069345e+03 6.43296151e+01 5.65508171e-02]\n",
      "Val Loss Meta Info:  [56840.975, 78902.27, 2.283868408203125]\n",
      "\n",
      "Epoch: 34, NLL Loss: 1472.0691875, Val Loss: 116191.5078125, Time took: 0.814842939376831\n",
      "Train loss Meta Info:  [1.42075854e+03 5.12535629e+01 5.70838392e-02]\n",
      "Val Loss Meta Info:  [56823.51, 59365.465, 2.5174293518066406]\n",
      "\n",
      "Epoch: 35, NLL Loss: 1481.90355859375, Val Loss: 152957.609375, Time took: 0.8289773464202881\n",
      "Train loss Meta Info:  [1.42032346e+03 6.15169951e+01 6.30750860e-02]\n",
      "Val Loss Meta Info:  [56837.7, 96117.35, 2.5840267944335937]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, NLL Loss: 1472.6558984375, Val Loss: 233686.78125, Time took: 0.912043571472168\n",
      "Train loss Meta Info:  [1.42062735e+03 5.19639509e+01 6.46149240e-02]\n",
      "Val Loss Meta Info:  [56821.565, 176862.7, 2.512484130859375]\n",
      "\n",
      "Epoch: 37, NLL Loss: 1469.76530859375, Val Loss: 303803.25, Time took: 0.9261817932128906\n",
      "Train loss Meta Info:  [1.42019372e+03 4.95087677e+01 6.28020414e-02]\n",
      "Val Loss Meta Info:  [56832.74, 246968.12, 2.417215118408203]\n",
      "\n",
      "Epoch: 38, NLL Loss: 1476.67630859375, Val Loss: 233066.015625, Time took: 0.8218085765838623\n",
      "Train loss Meta Info:  [1.42049880e+03 5.61170577e+01 6.04277351e-02]\n",
      "Val Loss Meta Info:  [56828.6, 176235.14, 2.3116915893554686]\n",
      "\n",
      "Epoch: 39, NLL Loss: 1466.91131640625, Val Loss: 177829.15625, Time took: 0.8085103034973145\n",
      "Train loss Meta Info:  [1.42040465e+03 4.64488681e+01 5.77913826e-02]\n",
      "Val Loss Meta Info:  [56814.39, 121012.58, 2.2045576477050783]\n",
      "\n",
      "Epoch: 40, NLL Loss: 1469.13708984375, Val Loss: 174373.59375, Time took: 0.7892203330993652\n",
      "Train loss Meta Info:  [1.42003468e+03 4.90472590e+01 5.51139132e-02]\n",
      "Val Loss Meta Info:  [56849.23, 117522.29, 2.0971678161621092]\n",
      "\n",
      "Epoch: 41, NLL Loss: 1472.13725390625, Val Loss: 197531.46875, Time took: 0.7866864204406738\n",
      "Train loss Meta Info:  [1.42094255e+03 5.11423051e+01 5.24293468e-02]\n",
      "Val Loss Meta Info:  [56800.715, 140728.79, 1.98814697265625]\n",
      "\n",
      "Epoch: 42, NLL Loss: 1468.5674140625, Val Loss: 236330.796875, Time took: 0.798558235168457\n",
      "Train loss Meta Info:  [1.41970797e+03 4.88097415e+01 4.97025756e-02]\n",
      "Val Loss Meta Info:  [56811.57, 179517.34, 1.8797056579589844]\n",
      "\n",
      "Epoch: 43, NLL Loss: 1467.08576171875, Val Loss: 310740.03125, Time took: 0.7902917861938477\n",
      "Train loss Meta Info:  [1.41999464e+03 4.70440969e+01 4.69887248e-02]\n",
      "Val Loss Meta Info:  [56809.59, 253928.72, 1.77260498046875]\n",
      "\n",
      "Epoch: 44, NLL Loss: 1469.14953515625, Val Loss: 316405.53125, Time took: 0.7920022010803223\n",
      "Train loss Meta Info:  [1.41992247e+03 4.91827571e+01 4.43095649e-02]\n",
      "Val Loss Meta Info:  [56789.66, 259614.22, 1.6661099243164061]\n",
      "\n",
      "Epoch: 45, NLL Loss: 1467.79501953125, Val Loss: 264890.59375, Time took: 0.8115506172180176\n",
      "Train loss Meta Info:  [1.41944061e+03 4.83127624e+01 4.16484032e-02]\n",
      "Val Loss Meta Info:  [56790.55, 208098.44, 1.5615365600585938]\n",
      "\n",
      "Epoch: 46, NLL Loss: 1465.688453125, Val Loss: 228165.59375, Time took: 0.8031177520751953\n",
      "Train loss Meta Info:  [1.41947665e+03 4.61727559e+01 3.90361262e-02]\n",
      "Val Loss Meta Info:  [56787.58, 171376.56, 1.4599699401855468]\n",
      "\n",
      "Epoch: 47, NLL Loss: 1466.59321484375, Val Loss: 215084.25, Time took: 0.7913036346435547\n",
      "Train loss Meta Info:  [1.41939226e+03 4.71644408e+01 3.64982502e-02]\n",
      "Val Loss Meta Info:  [56784.15, 158298.74, 1.3611599731445312]\n",
      "\n",
      "Epoch: 48, NLL Loss: 1467.5644765625, Val Loss: 223290.421875, Time took: 0.7986874580383301\n",
      "Train loss Meta Info:  [1.41934141e+03 4.81890003e+01 3.40283945e-02]\n",
      "Val Loss Meta Info:  [56784.29, 166504.85, 1.264937286376953]\n",
      "\n",
      "Epoch: 49, NLL Loss: 1466.66865625, Val Loss: 260435.65625, Time took: 0.809497594833374\n",
      "Train loss Meta Info:  [1.41935054e+03 4.72865472e+01 3.16229622e-02]\n",
      "Val Loss Meta Info:  [56800.17, 203634.34, 1.1721311950683593]\n",
      "\n",
      "Epoch: 50, NLL Loss: 1465.8693203125, Val Loss: 263413.78125, Time took: 0.7983987331390381\n",
      "Train loss Meta Info:  [1.41972708e+03 4.61129201e+01 2.93028070e-02]\n",
      "Val Loss Meta Info:  [56788.415, 206624.34, 1.0839730834960937]\n",
      "\n",
      "Epoch: 51, NLL Loss: 1465.433015625, Val Loss: 267080.09375, Time took: 0.7985999584197998\n",
      "Train loss Meta Info:  [1.41941368e+03 4.59922587e+01 2.70986161e-02]\n",
      "Val Loss Meta Info:  [56801.365, 210277.7, 1.0004823303222656]\n",
      "\n",
      "Epoch: 52, NLL Loss: 1465.6215625, Val Loss: 266304.40625, Time took: 0.7959539890289307\n",
      "Train loss Meta Info:  [1.41974026e+03 4.58562889e+01 2.50110210e-02]\n",
      "Val Loss Meta Info:  [56786.93, 209516.56, 0.9216726684570312]\n",
      "\n",
      "Epoch: 53, NLL Loss: 1464.95945703125, Val Loss: 246101.21875, Time took: 0.788524866104126\n",
      "Train loss Meta Info:  [1.41934426e+03 4.55921472e+01 2.30406399e-02]\n",
      "Val Loss Meta Info:  [56791.89, 189308.52, 0.8476029968261719]\n",
      "\n",
      "Epoch: 54, NLL Loss: 1464.768203125, Val Loss: 231281.59375, Time took: 0.7980031967163086\n",
      "Train loss Meta Info:  [1.41946034e+03 4.52866396e+01 2.11890176e-02]\n",
      "Val Loss Meta Info:  [56783.93, 174496.92, 0.7782992553710938]\n",
      "\n",
      "Epoch: 55, NLL Loss: 1464.35983203125, Val Loss: 289010.625, Time took: 0.829578161239624\n",
      "Train loss Meta Info:  [1.41925607e+03 4.50843174e+01 1.94567279e-02]\n",
      "Val Loss Meta Info:  [56784.86, 232225.08, 0.7136744689941407]\n",
      "\n",
      "Epoch: 56, NLL Loss: 1464.37125390625, Val Loss: 200069.5625, Time took: 0.8236169815063477\n",
      "Train loss Meta Info:  [1.41930804e+03 4.50454034e+01 1.78415595e-02]\n",
      "Val Loss Meta Info:  [56793.17, 143275.7, 0.6535810852050781]\n",
      "\n",
      "Epoch: 57, NLL Loss: 1465.1112109375, Val Loss: 279402.84375, Time took: 0.7924680709838867\n",
      "Train loss Meta Info:  [1.41951080e+03 4.55840469e+01 1.63398548e-02]\n",
      "Val Loss Meta Info:  [56790.885, 222611.36, 0.5982995223999024]\n",
      "\n",
      "Epoch: 58, NLL Loss: 1464.52105078125, Val Loss: 269797.15625, Time took: 0.8168134689331055\n",
      "Train loss Meta Info:  [1.41944773e+03 4.50583079e+01 1.49582513e-02]\n",
      "Val Loss Meta Info:  [56788.105, 213008.5, 0.5471891784667968]\n",
      "\n",
      "Epoch: 59, NLL Loss: 1464.59698046875, Val Loss: 241352.0, Time took: 0.8415179252624512\n",
      "Train loss Meta Info:  [1.41935772e+03 4.52255717e+01 1.36807083e-02]\n",
      "Val Loss Meta Info:  [56780.37, 184571.12, 0.4998497009277344]\n",
      "\n",
      "Epoch: 60, NLL Loss: 1464.05356640625, Val Loss: 231801.96875, Time took: 0.813215970993042\n",
      "Train loss Meta Info:  [1.41918097e+03 4.48600948e+01 1.24972318e-02]\n",
      "Val Loss Meta Info:  [56789.925, 175011.56, 0.45698596954345705]\n",
      "\n",
      "Epoch: 61, NLL Loss: 1464.35536328125, Val Loss: 266419.6875, Time took: 0.8447399139404297\n",
      "Train loss Meta Info:  [1.41944450e+03 4.48994538e+01 1.14257246e-02]\n",
      "Val Loss Meta Info:  [56788.94, 209630.34, 0.41866584777832033]\n",
      "\n",
      "Epoch: 62, NLL Loss: 1464.00422265625, Val Loss: 172553.59375, Time took: 0.8190221786499023\n",
      "Train loss Meta Info:  [1.41941018e+03 4.45835565e+01 1.04678876e-02]\n",
      "Val Loss Meta Info:  [56793.075, 115760.15, 0.3838892364501953]\n",
      "\n",
      "Epoch: 63, NLL Loss: 1463.92515234375, Val Loss: 176389.171875, Time took: 0.7849404811859131\n",
      "Train loss Meta Info:  [1.41949021e+03 4.44253970e+01 9.59867522e-03]\n",
      "Val Loss Meta Info:  [56779.49, 119609.35, 0.35263092041015626]\n",
      "\n",
      "Epoch: 64, NLL Loss: 1463.19619140625, Val Loss: 174666.453125, Time took: 0.7848820686340332\n",
      "Train loss Meta Info:  [1.41914654e+03 4.40408890e+01 8.81750582e-03]\n",
      "Val Loss Meta Info:  [56777.085, 117889.06, 0.32424339294433596]\n",
      "\n",
      "Epoch: 65, NLL Loss: 1463.12728125, Val Loss: 170158.15625, Time took: 0.7821395397186279\n",
      "Train loss Meta Info:  [1.41910868e+03 4.40104781e+01 8.10813361e-03]\n",
      "Val Loss Meta Info:  [56788.125, 113369.74, 0.29845247268676756]\n",
      "\n",
      "Epoch: 66, NLL Loss: 1463.65335546875, Val Loss: 170736.734375, Time took: 0.791496753692627\n",
      "Train loss Meta Info:  [1.41936011e+03 4.42857374e+01 7.46372525e-03]\n",
      "Val Loss Meta Info:  [56783.34, 113953.13, 0.2751591682434082]\n",
      "\n",
      "Epoch: 67, NLL Loss: 1463.253671875, Val Loss: 172244.21875, Time took: 0.7915029525756836\n",
      "Train loss Meta Info:  [1.41921950e+03 4.40272971e+01 6.88180511e-03]\n",
      "Val Loss Meta Info:  [56781.645, 115462.31, 0.2541900444030762]\n",
      "\n",
      "Epoch: 68, NLL Loss: 1463.45880859375, Val Loss: 161665.859375, Time took: 0.7961914539337158\n",
      "Train loss Meta Info:  [1.41919367e+03 4.42587067e+01 6.35795096e-03]\n",
      "Val Loss Meta Info:  [56773.96, 104891.69, 0.23536979675292968]\n",
      "\n",
      "Epoch: 69, NLL Loss: 1463.14576171875, Val Loss: 157104.375, Time took: 0.7897682189941406\n",
      "Train loss Meta Info:  [1.41898293e+03 4.41568893e+01 5.88769203e-03]\n",
      "Val Loss Meta Info:  [56776.695, 100327.46, 0.21837417602539064]\n",
      "\n",
      "Epoch: 70, NLL Loss: 1463.2621484375, Val Loss: 165198.453125, Time took: 0.7906780242919922\n",
      "Train loss Meta Info:  [1.41905795e+03 4.41987172e+01 5.46303056e-03]\n",
      "Val Loss Meta Info:  [56774.125, 108424.13, 0.20289846420288085]\n",
      "\n",
      "Epoch: 71, NLL Loss: 1462.864671875, Val Loss: 166994.953125, Time took: 0.7893991470336914\n",
      "Train loss Meta Info:  [1.41901233e+03 4.38472937e+01 5.07634714e-03]\n",
      "Val Loss Meta Info:  [56770.675, 110224.08, 0.18902767181396485]\n",
      "\n",
      "Epoch: 72, NLL Loss: 1463.11060546875, Val Loss: 156879.109375, Time took: 0.7851574420928955\n",
      "Train loss Meta Info:  [1.41891575e+03 4.41901259e+01 4.72972475e-03]\n",
      "Val Loss Meta Info:  [56770.57, 100108.36, 0.1766748046875]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, NLL Loss: 1462.6758125, Val Loss: 151667.25, Time took: 0.7836148738861084\n",
      "Train loss Meta Info:  [1.41889889e+03 4.37725499e+01 4.42096000e-03]\n",
      "Val Loss Meta Info:  [56774.05, 94893.01, 0.1654181671142578]\n",
      "\n",
      "Epoch: 74, NLL Loss: 1462.94342578125, Val Loss: 171977.875, Time took: 0.8017199039459229\n",
      "Train loss Meta Info:  [1.41897706e+03 4.39622522e+01 4.13953975e-03]\n",
      "Val Loss Meta Info:  [56768.995, 115208.74, 0.15500106811523437]\n",
      "\n",
      "Epoch: 75, NLL Loss: 1462.580546875, Val Loss: 164839.5625, Time took: 0.8095505237579346\n",
      "Train loss Meta Info:  [1.41883827e+03 4.37383844e+01 3.87902986e-03]\n",
      "Val Loss Meta Info:  [56772.385, 108067.03, 0.14542343139648437]\n",
      "\n",
      "Epoch: 76, NLL Loss: 1462.69693359375, Val Loss: 139525.171875, Time took: 0.8025224208831787\n",
      "Train loss Meta Info:  [1.41891356e+03 4.37798141e+01 3.63939515e-03]\n",
      "Val Loss Meta Info:  [56767.475, 82757.56, 0.13668516159057617]\n",
      "\n",
      "Epoch: 77, NLL Loss: 1462.35306640625, Val Loss: 135727.609375, Time took: 0.8195743560791016\n",
      "Train loss Meta Info:  [1.41880644e+03 4.35431842e+01 3.42067941e-03]\n",
      "Val Loss Meta Info:  [56768.78, 78958.705, 0.12861039161682128]\n",
      "\n",
      "Epoch: 78, NLL Loss: 1462.40112109375, Val Loss: 134898.359375, Time took: 0.835230827331543\n",
      "Train loss Meta Info:  [1.41883392e+03 4.35639197e+01 3.21855401e-03]\n",
      "Val Loss Meta Info:  [56765.15, 78133.095, 0.1210871124267578]\n",
      "\n",
      "Epoch: 79, NLL Loss: 1462.18312109375, Val Loss: 131712.609375, Time took: 0.8329665660858154\n",
      "Train loss Meta Info:  [1.41874577e+03 4.34343682e+01 3.03027228e-03]\n",
      "Val Loss Meta Info:  [56766.315, 74946.19, 0.1141697883605957]\n",
      "\n",
      "Epoch: 80, NLL Loss: 1462.1401015625, Val Loss: 130104.5390625, Time took: 0.8448817729949951\n",
      "Train loss Meta Info:  [1.41875331e+03 4.33839706e+01 2.85717630e-03]\n",
      "Val Loss Meta Info:  [56765.73, 73338.695, 0.10772427558898925]\n",
      "\n",
      "Epoch: 81, NLL Loss: 1462.16492578125, Val Loss: 125355.375, Time took: 0.8362765312194824\n",
      "Train loss Meta Info:  [1.41874251e+03 4.34197501e+01 2.69587204e-03]\n",
      "Val Loss Meta Info:  [56764.73, 68590.56, 0.10166862487792969]\n",
      "\n",
      "Epoch: 82, NLL Loss: 1462.11700390625, Val Loss: 121125.4296875, Time took: 0.8432540893554688\n",
      "Train loss Meta Info:  [1.41872019e+03 4.33943242e+01 2.54432128e-03]\n",
      "Val Loss Meta Info:  [56765.235, 64360.1, 0.09600288391113282]\n",
      "\n",
      "Epoch: 83, NLL Loss: 1462.0726875, Val Loss: 120932.375, Time took: 0.8303842544555664\n",
      "Train loss Meta Info:  [1.41871885e+03 4.33515123e+01 2.40255205e-03]\n",
      "Val Loss Meta Info:  [56764.31, 64167.975, 0.09067310333251953]\n",
      "\n",
      "Epoch: 84, NLL Loss: 1461.93869921875, Val Loss: 118469.6484375, Time took: 0.8339381217956543\n",
      "Train loss Meta Info:  [1.41868338e+03 4.32530595e+01 2.26922275e-03]\n",
      "Val Loss Meta Info:  [56765.31, 61704.245, 0.08565895080566406]\n",
      "\n",
      "Epoch: 85, NLL Loss: 1461.87992578125, Val Loss: 116576.796875, Time took: 0.8608589172363281\n",
      "Train loss Meta Info:  [1.41871101e+03 4.31666998e+01 2.14382686e-03]\n",
      "Val Loss Meta Info:  [56763.675, 59813.04, 0.08092941284179687]\n",
      "\n",
      "Epoch: 86, NLL Loss: 1461.8574140625, Val Loss: 116740.0390625, Time took: 0.8146729469299316\n",
      "Train loss Meta Info:  [1.41865743e+03 4.31979711e+01 2.02558696e-03]\n",
      "Val Loss Meta Info:  [56764.05, 59975.91, 0.0765103530883789]\n",
      "\n",
      "Epoch: 87, NLL Loss: 1461.88132421875, Val Loss: 113408.4609375, Time took: 0.8281004428863525\n",
      "Train loss Meta Info:  [1.41868204e+03 4.31974329e+01 1.91515864e-03]\n",
      "Val Loss Meta Info:  [56763.38, 56645.015, 0.0723002815246582]\n",
      "\n",
      "Epoch: 88, NLL Loss: 1461.79897265625, Val Loss: 113757.0703125, Time took: 0.8363072872161865\n",
      "Train loss Meta Info:  [1.41866309e+03 4.31340144e+01 1.80997558e-03]\n",
      "Val Loss Meta Info:  [56762.51, 56994.51, 0.06834507942199707]\n",
      "\n",
      "Epoch: 89, NLL Loss: 1461.71691796875, Val Loss: 112814.0, Time took: 0.853949785232544\n",
      "Train loss Meta Info:  [1.41863973e+03 4.30755252e+01 1.71114096e-03]\n",
      "Val Loss Meta Info:  [56763.24, 56050.7, 0.06459516048431396]\n",
      "\n",
      "Epoch: 90, NLL Loss: 1461.7044375, Val Loss: 108819.0859375, Time took: 0.8259477615356445\n",
      "Train loss Meta Info:  [1.41865570e+03 4.30471473e+01 1.61735988e-03]\n",
      "Val Loss Meta Info:  [56762.385, 52056.64, 0.06102606773376465]\n",
      "\n",
      "Epoch: 91, NLL Loss: 1461.644609375, Val Loss: 109915.234375, Time took: 0.8241560459136963\n",
      "Train loss Meta Info:  [1.41862871e+03 4.30143469e+01 1.52801797e-03]\n",
      "Val Loss Meta Info:  [56762.2, 53152.98, 0.05768857479095459]\n",
      "\n",
      "Epoch: 92, NLL Loss: 1461.63784765625, Val Loss: 106822.7265625, Time took: 0.8297996520996094\n",
      "Train loss Meta Info:  [1.41862909e+03 4.30073854e+01 1.44443124e-03]\n",
      "Val Loss Meta Info:  [56762.21, 50060.48, 0.05451704978942871]\n",
      "\n",
      "Epoch: 93, NLL Loss: 1461.60560546875, Val Loss: 107215.84375, Time took: 0.8321030139923096\n",
      "Train loss Meta Info:  [1.41862009e+03 4.29841049e+01 1.36497729e-03]\n",
      "Val Loss Meta Info:  [56763.09, 50452.705, 0.05153693675994873]\n",
      "\n",
      "Epoch: 94, NLL Loss: 1461.58291015625, Val Loss: 104347.4609375, Time took: 0.834047794342041\n",
      "Train loss Meta Info:  [1.41862971e+03 4.29519382e+01 1.29031009e-03]\n",
      "Val Loss Meta Info:  [56761.78, 47585.62, 0.048725371360778806]\n",
      "\n",
      "Epoch: 95, NLL Loss: 1461.58841015625, Val Loss: 105126.0859375, Time took: 0.8366312980651855\n",
      "Train loss Meta Info:  [1.41860304e+03 4.29841348e+01 1.21984540e-03]\n",
      "Val Loss Meta Info:  [56761.435, 48364.615, 0.0460775089263916]\n",
      "\n",
      "Epoch: 96, NLL Loss: 1461.5482578125, Val Loss: 102476.046875, Time took: 0.8374452590942383\n",
      "Train loss Meta Info:  [1.41859573e+03 4.29514092e+01 1.15351839e-03]\n",
      "Val Loss Meta Info:  [56761.77, 45714.24, 0.04357597351074219]\n",
      "\n",
      "Epoch: 97, NLL Loss: 1461.62457421875, Val Loss: 106542.8671875, Time took: 0.8578159809112549\n",
      "Train loss Meta Info:  [1.41860970e+03 4.30137811e+01 1.09087785e-03]\n",
      "Val Loss Meta Info:  [56761.755, 49781.08, 0.04122496604919434]\n",
      "\n",
      "Epoch: 98, NLL Loss: 1461.57530859375, Val Loss: 101807.0546875, Time took: 0.8313932418823242\n",
      "Train loss Meta Info:  [1.41860182e+03 4.29723809e+01 1.03214471e-03]\n",
      "Val Loss Meta Info:  [56761.68, 45045.34, 0.03899370431900025]\n",
      "\n",
      "Epoch: 99, NLL Loss: 1461.52394140625, Val Loss: 104739.640625, Time took: 0.8411531448364258\n",
      "Train loss Meta Info:  [1.41859294e+03 4.29300723e+01 9.76429334e-04]\n",
      "Val Loss Meta Info:  [56762.19, 47977.405, 0.03691556930541992]\n",
      "\n",
      "Epoch: 100, NLL Loss: 1461.3776484375, Val Loss: 106293.4296875, Time took: 0.8198838233947754\n",
      "Train loss Meta Info:  [1.41859294e+03 4.27837650e+01 9.24663853e-04]\n",
      "Val Loss Meta Info:  [56762.1, 49531.31, 0.03496350049972534]\n",
      "\n",
      "Epoch: 101, NLL Loss: 1461.38252734375, Val Loss: 100572.109375, Time took: 0.8388910293579102\n",
      "Train loss Meta Info:  [1.41858421e+03 4.27973972e+01 8.76108222e-04]\n",
      "Val Loss Meta Info:  [56762.68, 43809.395, 0.0331231689453125]\n",
      "\n",
      "Epoch: 102, NLL Loss: 1461.4815546875, Val Loss: 104877.796875, Time took: 0.8001296520233154\n",
      "Train loss Meta Info:  [1.41860382e+03 4.28769587e+01 8.30363519e-04]\n",
      "Val Loss Meta Info:  [56762.535, 48115.235, 0.03140942573547363]\n",
      "\n",
      "Epoch: 103, NLL Loss: 1461.38788671875, Val Loss: 98492.3046875, Time took: 0.8244774341583252\n",
      "Train loss Meta Info:  [1.41858963e+03 4.27974737e+01 7.87857473e-04]\n",
      "Val Loss Meta Info:  [56761.765, 41730.5175, 0.029773621559143065]\n",
      "\n",
      "Epoch: 104, NLL Loss: 1461.2857890625, Val Loss: 101082.1796875, Time took: 0.7984795570373535\n",
      "Train loss Meta Info:  [1.41857721e+03 4.27077932e+01 7.47172656e-04]\n",
      "Val Loss Meta Info:  [56762.0, 44320.15, 0.028220286369323732]\n",
      "\n",
      "Epoch: 105, NLL Loss: 1461.1711171875, Val Loss: 100385.5859375, Time took: 0.8178448677062988\n",
      "Train loss Meta Info:  [1.41858138e+03 4.25890503e+01 7.08484193e-04]\n",
      "Val Loss Meta Info:  [56761.695, 43623.865, 0.026735687255859376]\n",
      "\n",
      "Epoch: 106, NLL Loss: 1461.10128515625, Val Loss: 97297.390625, Time took: 0.8284397125244141\n",
      "Train loss Meta Info:  [1.41857539e+03 4.25252736e+01 6.71370890e-04]\n",
      "Val Loss Meta Info:  [56761.95, 40535.41, 0.025332951545715333]\n",
      "\n",
      "Epoch: 107, NLL Loss: 1461.12555859375, Val Loss: 107282.109375, Time took: 0.8258168697357178\n",
      "Train loss Meta Info:  [1.41858378e+03 4.25411387e+01 6.36180822e-04]\n",
      "Val Loss Meta Info:  [56763.075, 50519.02, 0.02398360013961792]\n",
      "\n",
      "Epoch: 108, NLL Loss: 1461.428328125, Val Loss: 90186.234375, Time took: 0.797950267791748\n",
      "Train loss Meta Info:  [1.41859672e+03 4.28309916e+01 6.02329466e-04]\n",
      "Val Loss Meta Info:  [56763.96, 33422.2625, 0.022726287841796877]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109, NLL Loss: 1462.52032421875, Val Loss: 113844.515625, Time took: 0.8265259265899658\n",
      "Train loss Meta Info:  [1.41863086e+03 4.38888154e+01 5.70653412e-04]\n",
      "Val Loss Meta Info:  [56766.93, 57077.56, 0.02152087688446045]\n",
      "\n",
      "Epoch: 110, NLL Loss: 1462.68553515625, Val Loss: 98876.3359375, Time took: 0.8267881870269775\n",
      "Train loss Meta Info:  [1.41869123e+03 4.39938277e+01 5.40515340e-04]\n",
      "Val Loss Meta Info:  [56763.47, 42112.845, 0.020397939682006837]\n",
      "\n",
      "Epoch: 111, NLL Loss: 1462.720203125, Val Loss: 108804.890625, Time took: 0.7865138053894043\n",
      "Train loss Meta Info:  [1.41861566e+03 4.41040575e+01 5.12210951e-04]\n",
      "Val Loss Meta Info:  [56761.98, 52042.89, 0.019310375452041628]\n",
      "\n",
      "Epoch: 112, NLL Loss: 1461.52734375, Val Loss: 127624.4375, Time took: 0.7904365062713623\n",
      "Train loss Meta Info:  [1.41857416e+03 4.29526973e+01 4.85025334e-04]\n",
      "Val Loss Meta Info:  [56764.8, 70859.625, 0.018296420574188232]\n",
      "\n",
      "Epoch: 113, NLL Loss: 1464.18470703125, Val Loss: 104005.890625, Time took: 0.8037028312683105\n",
      "Train loss Meta Info:  [1.41864327e+03 4.55409573e+01 4.59828136e-04]\n",
      "Val Loss Meta Info:  [56768.63, 47237.235, 0.01728017449378967]\n",
      "\n",
      "Epoch: 114, NLL Loss: 1464.34471875, Val Loss: 111200.03125, Time took: 0.8219118118286133\n",
      "Train loss Meta Info:  [1.41874827e+03 4.55959761e+01 4.34123745e-04]\n",
      "Val Loss Meta Info:  [56762.0, 54438.005, 0.016369421482086182]\n",
      "\n",
      "Epoch: 115, NLL Loss: 1462.67005859375, Val Loss: 145438.796875, Time took: 0.8100926876068115\n",
      "Train loss Meta Info:  [1.41857846e+03 4.40911566e+01 4.11530138e-04]\n",
      "Val Loss Meta Info:  [56776.745, 88662.04, 0.015555531978607177]\n",
      "\n",
      "Epoch: 116, NLL Loss: 1463.86109765625, Val Loss: 136981.453125, Time took: 0.7812654972076416\n",
      "Train loss Meta Info:  [1.41893651e+03 4.49242264e+01 3.91650459e-04]\n",
      "Val Loss Meta Info:  [56763.68, 80217.79, 0.01472588062286377]\n",
      "\n",
      "Epoch: 117, NLL Loss: 1462.00073828125, Val Loss: 120695.8359375, Time took: 0.7803597450256348\n",
      "Train loss Meta Info:  [1.41862257e+03 4.33778721e+01 3.70932399e-04]\n",
      "Val Loss Meta Info:  [56781.575, 63914.265, 0.013926464319229125]\n",
      "\n",
      "Epoch: 118, NLL Loss: 1463.0653125, Val Loss: 123253.7109375, Time took: 0.7801744937896729\n",
      "Train loss Meta Info:  [1.41907081e+03 4.39941984e+01 3.51014611e-04]\n",
      "Val Loss Meta Info:  [56764.585, 66489.105, 0.01319720983505249]\n",
      "\n",
      "Epoch: 119, NLL Loss: 1462.164765625, Val Loss: 144429.609375, Time took: 0.793736457824707\n",
      "Train loss Meta Info:  [1.41862606e+03 4.35384110e+01 3.33285492e-04]\n",
      "Val Loss Meta Info:  [56787.79, 87641.83, 0.01254143238067627]\n",
      "\n",
      "Epoch: 120, NLL Loss: 1462.51273828125, Val Loss: 143553.171875, Time took: 0.8192319869995117\n",
      "Train loss Meta Info:  [1.41920771e+03 4.33047175e+01 3.17487506e-04]\n",
      "Val Loss Meta Info:  [56764.64, 86788.52, 0.011926779747009278]\n",
      "\n",
      "Epoch: 121, NLL Loss: 1461.92957421875, Val Loss: 125515.1953125, Time took: 0.8058924674987793\n",
      "Train loss Meta Info:  [1.41864258e+03 4.32866932e+01 3.02347837e-04]\n",
      "Val Loss Meta Info:  [56788.84, 68726.35, 0.011345341205596923]\n",
      "\n",
      "Epoch: 122, NLL Loss: 1462.31365625, Val Loss: 122248.234375, Time took: 0.8172116279602051\n",
      "Train loss Meta Info:  [1.41925567e+03 4.30576766e+01 2.87877765e-04]\n",
      "Val Loss Meta Info:  [56766.18, 65482.035, 0.010773735046386719]\n",
      "\n",
      "Epoch: 123, NLL Loss: 1461.7538359375, Val Loss: 134401.734375, Time took: 0.824429988861084\n",
      "Train loss Meta Info:  [1.41867438e+03 4.30791693e+01 2.73905232e-04]\n",
      "Val Loss Meta Info:  [56786.57, 77615.18, 0.010194250345230103]\n",
      "\n",
      "Epoch: 124, NLL Loss: 1462.1123359375, Val Loss: 127663.875, Time took: 0.8248138427734375\n",
      "Train loss Meta Info:  [1.41915911e+03 4.29529171e+01 2.59766094e-04]\n",
      "Val Loss Meta Info:  [56767.42, 70896.44, 0.009647864699363708]\n",
      "\n",
      "Epoch: 125, NLL Loss: 1461.5618046875, Val Loss: 117703.9609375, Time took: 0.8153080940246582\n",
      "Train loss Meta Info:  [1.41868475e+03 4.28767139e+01 2.46018550e-04]\n",
      "Val Loss Meta Info:  [56778.255, 60925.695, 0.00915367305278778]\n",
      "\n",
      "Epoch: 126, NLL Loss: 1461.89761328125, Val Loss: 119463.2109375, Time took: 0.8442656993865967\n",
      "Train loss Meta Info:  [1.41897414e+03 4.29232917e+01 2.33439559e-04]\n",
      "Val Loss Meta Info:  [56768.235, 62694.965, 0.008670324683189392]\n",
      "\n",
      "Epoch: 127, NLL Loss: 1461.50193359375, Val Loss: 125875.0859375, Time took: 0.8387002944946289\n",
      "Train loss Meta Info:  [1.41871339e+03 4.27883626e+01 2.21460089e-04]\n",
      "Val Loss Meta Info:  [56771.97, 69103.09, 0.00823872685432434]\n",
      "\n",
      "Epoch: 128, NLL Loss: 1461.65403515625, Val Loss: 119679.734375, Time took: 0.8419013023376465\n",
      "Train loss Meta Info:  [1.41878083e+03 4.28730635e+01 2.11035256e-04]\n",
      "Val Loss Meta Info:  [56769.55, 62910.155, 0.007826855778694153]\n",
      "\n",
      "Epoch: 129, NLL Loss: 1461.355046875, Val Loss: 110152.296875, Time took: 0.8179435729980469\n",
      "Train loss Meta Info:  [1.41870363e+03 4.26512515e+01 2.01007328e-04]\n",
      "Val Loss Meta Info:  [56766.585, 53385.705, 0.007417775392532348]\n",
      "\n",
      "Epoch: 130, NLL Loss: 1461.43169921875, Val Loss: 121725.9296875, Time took: 0.7886173725128174\n",
      "Train loss Meta Info:  [1.41864275e+03 4.27887713e+01 1.91040534e-04]\n",
      "Val Loss Meta Info:  [56769.6, 64956.315, 0.007053873538970947]\n",
      "\n",
      "Epoch: 131, NLL Loss: 1461.28145703125, Val Loss: 126073.734375, Time took: 0.8005344867706299\n",
      "Train loss Meta Info:  [1.41871793e+03 4.25633533e+01 1.82418992e-04]\n",
      "Val Loss Meta Info:  [56764.44, 69309.3, 0.006726016402244568]\n",
      "\n",
      "Epoch: 132, NLL Loss: 1461.238796875, Val Loss: 116708.0078125, Time took: 0.8088352680206299\n",
      "Train loss Meta Info:  [1.41858419e+03 4.26544313e+01 1.74690153e-04]\n",
      "Val Loss Meta Info:  [56768.965, 59939.045, 0.006391539573669434]\n",
      "\n",
      "Epoch: 133, NLL Loss: 1461.1811953125, Val Loss: 116208.5703125, Time took: 0.8009505271911621\n",
      "Train loss Meta Info:  [1.41867815e+03 4.25028739e+01 1.66461091e-04]\n",
      "Val Loss Meta Info:  [56765.65, 59442.91, 0.0060642421245574955]\n",
      "\n",
      "Epoch: 134, NLL Loss: 1461.0571796875, Val Loss: 125897.65625, Time took: 0.789189338684082\n",
      "Train loss Meta Info:  [1.41859200e+03 4.24650022e+01 1.58155049e-04]\n",
      "Val Loss Meta Info:  [56767.19, 69130.45, 0.005744587182998657]\n",
      "\n",
      "Epoch: 135, NLL Loss: 1461.147328125, Val Loss: 115642.9375, Time took: 0.8039810657501221\n",
      "Train loss Meta Info:  [1.41863268e+03 4.25145025e+01 1.49925574e-04]\n",
      "Val Loss Meta Info:  [56766.03, 58876.9, 0.005431591272354126]\n",
      "\n",
      "Epoch: 136, NLL Loss: 1460.97710546875, Val Loss: 113450.25, Time took: 0.7865259647369385\n",
      "Train loss Meta Info:  [1.41860253e+03 4.23744360e+01 1.41792018e-04]\n",
      "Val Loss Meta Info:  [56765.82, 56684.435, 0.005135545134544372]\n",
      "\n",
      "Epoch: 137, NLL Loss: 1460.93578125, Val Loss: 129613.0234375, Time took: 0.7846508026123047\n",
      "Train loss Meta Info:  [1.41858973e+03 4.23458655e+01 1.34071450e-04]\n",
      "Val Loss Meta Info:  [56765.545, 72847.485, 0.004854265451431274]\n",
      "\n",
      "Epoch: 138, NLL Loss: 1460.98858203125, Val Loss: 104066.71875, Time took: 0.7831053733825684\n",
      "Train loss Meta Info:  [1.41856571e+03 4.24227151e+01 1.26702272e-04]\n",
      "Val Loss Meta Info:  [56765.73, 47300.965, 0.00460476666688919]\n",
      "\n",
      "Epoch: 139, NLL Loss: 1460.97460546875, Val Loss: 114611.5859375, Time took: 0.7948997020721436\n",
      "Train loss Meta Info:  [1.41858404e+03 4.23904219e+01 1.20129449e-04]\n",
      "Val Loss Meta Info:  [56763.125, 57848.465, 0.0043730628490448]\n",
      "\n",
      "Epoch: 140, NLL Loss: 1460.74467578125, Val Loss: 114432.0390625, Time took: 0.8007004261016846\n",
      "Train loss Meta Info:  [1.41851572e+03 4.22288015e+01 1.14172355e-04]\n",
      "Val Loss Meta Info:  [56766.84, 57665.18, 0.00416610449552536]\n",
      "\n",
      "Epoch: 141, NLL Loss: 1460.78471875, Val Loss: 98887.3984375, Time took: 0.8171331882476807\n",
      "Train loss Meta Info:  [1.41859844e+03 4.21861068e+01 1.08922753e-04]\n",
      "Val Loss Meta Info:  [56762.645, 42124.76, 0.003983646333217621]\n",
      "\n",
      "Epoch: 142, NLL Loss: 1460.787046875, Val Loss: 128282.2109375, Time took: 0.8131499290466309\n",
      "Train loss Meta Info:  [1.41849848e+03 4.22883964e+01 1.04353301e-04]\n",
      "Val Loss Meta Info:  [56766.5, 71515.725, 0.0038156002759933473]\n",
      "\n",
      "Epoch: 143, NLL Loss: 1461.105671875, Val Loss: 91726.8984375, Time took: 0.821225643157959\n",
      "Train loss Meta Info:  [1.41857203e+03 4.25334536e+01 1.00341894e-04]\n",
      "Val Loss Meta Info:  [56763.64, 34963.265, 0.0036520513892173766]\n",
      "\n",
      "Epoch: 144, NLL Loss: 1461.6177265625, Val Loss: 128913.015625, Time took: 0.8155620098114014\n",
      "Train loss Meta Info:  [1.41851082e+03 4.31067693e+01 9.61961516e-05]\n",
      "Val Loss Meta Info:  [56764.63, 72148.4, 0.00350678950548172]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, NLL Loss: 1461.4047421875, Val Loss: 91369.0, Time took: 0.8151271343231201\n",
      "Train loss Meta Info:  [1.41851662e+03 4.28880074e+01 9.27737650e-05]\n",
      "Val Loss Meta Info:  [56764.09, 34604.905, 0.0033290630578994753]\n",
      "\n",
      "Epoch: 146, NLL Loss: 1461.3312265625, Val Loss: 111276.2578125, Time took: 0.8181271553039551\n",
      "Train loss Meta Info:  [1.41852264e+03 4.28085059e+01 8.79193179e-05]\n",
      "Val Loss Meta Info:  [56763.08, 54513.18, 0.0031751957535743713]\n",
      "\n",
      "Epoch: 147, NLL Loss: 1460.66658203125, Val Loss: 109094.140625, Time took: 0.8416290283203125\n",
      "Train loss Meta Info:  [1.41847478e+03 4.21917319e+01 8.38501276e-05]\n",
      "Val Loss Meta Info:  [56764.61, 52329.535, 0.003019447922706604]\n",
      "\n",
      "Epoch: 148, NLL Loss: 1460.6030703125, Val Loss: 92733.328125, Time took: 0.8080394268035889\n",
      "Train loss Meta Info:  [1.41850906e+03 4.20939410e+01 7.95103858e-05]\n",
      "Val Loss Meta Info:  [56762.94, 35970.385, 0.0028577205538749696]\n",
      "\n",
      "Epoch: 149, NLL Loss: 1460.91134765625, Val Loss: 124015.25, Time took: 0.8218348026275635\n",
      "Train loss Meta Info:  [1.41847406e+03 4.24372446e+01 7.49364735e-05]\n",
      "Val Loss Meta Info:  [56763.44, 67251.815, 0.002726273536682129]\n",
      "\n",
      "Epoch: 150, NLL Loss: 1461.02625, Val Loss: 99154.28125, Time took: 0.8154633045196533\n",
      "Train loss Meta Info:  [1.41848093e+03 4.25452625e+01 7.13720656e-05]\n",
      "Val Loss Meta Info:  [56763.4, 42390.87, 0.0025748246908187866]\n",
      "\n",
      "Epoch: 151, NLL Loss: 1460.7729296875, Val Loss: 110512.4765625, Time took: 0.8136053085327148\n",
      "Train loss Meta Info:  [1.41848159e+03 4.22913511e+01 6.71698814e-05]\n",
      "Val Loss Meta Info:  [56762.54, 53749.94, 0.002451246380805969]\n",
      "\n",
      "Epoch: 152, NLL Loss: 1460.46531640625, Val Loss: 115825.359375, Time took: 0.8028748035430908\n",
      "Train loss Meta Info:  [1.41845214e+03 4.20131480e+01 6.38794666e-05]\n",
      "Val Loss Meta Info:  [56763.67, 59061.69, 0.002328890860080719]\n",
      "\n",
      "Epoch: 153, NLL Loss: 1460.63876171875, Val Loss: 96451.3359375, Time took: 0.8175208568572998\n",
      "Train loss Meta Info:  [1.41847000e+03 4.21687104e+01 6.07321355e-05]\n",
      "Val Loss Meta Info:  [56762.76, 39688.58, 0.002207351326942444]\n",
      "\n",
      "Epoch: 154, NLL Loss: 1460.81361328125, Val Loss: 121402.7109375, Time took: 0.8014023303985596\n",
      "Train loss Meta Info:  [1.41845017e+03 4.23634199e+01 5.76702070e-05]\n",
      "Val Loss Meta Info:  [56762.695, 64640.015, 0.0020647788047790526]\n",
      "\n",
      "Epoch: 155, NLL Loss: 1460.64577734375, Val Loss: 105852.46875, Time took: 0.7971177101135254\n",
      "Train loss Meta Info:  [1.41844539e+03 4.22004037e+01 5.43026138e-05]\n",
      "Val Loss Meta Info:  [56762.18, 49090.28, 0.0019584682583808897]\n",
      "\n",
      "Epoch: 156, NLL Loss: 1460.42471484375, Val Loss: 102744.5, Time took: 0.803396463394165\n",
      "Train loss Meta Info:  [1.41844659e+03 4.19781294e+01 5.15458120e-05]\n",
      "Val Loss Meta Info:  [56762.37, 45982.135, 0.0018553538620471955]\n",
      "\n",
      "Epoch: 157, NLL Loss: 1460.43599609375, Val Loss: 120549.328125, Time took: 0.7988040447235107\n",
      "Train loss Meta Info:  [1.41842916e+03 4.20068367e+01 4.89652889e-05]\n",
      "Val Loss Meta Info:  [56763.39, 63785.955, 0.0017554590106010437]\n",
      "\n",
      "Epoch: 158, NLL Loss: 1460.59615234375, Val Loss: 90348.109375, Time took: 0.8110668659210205\n",
      "Train loss Meta Info:  [1.41843943e+03 4.21566990e+01 4.66393666e-05]\n",
      "Val Loss Meta Info:  [56762.29, 33585.81, 0.0016701819002628326]\n",
      "\n",
      "Epoch: 159, NLL Loss: 1460.60788671875, Val Loss: 114517.59375, Time took: 0.810056209564209\n",
      "Train loss Meta Info:  [1.41842360e+03 4.21842752e+01 4.45274164e-05]\n",
      "Val Loss Meta Info:  [56762.595, 57755.015, 0.0015861596167087554]\n",
      "\n",
      "Epoch: 160, NLL Loss: 1460.49153125, Val Loss: 95034.0703125, Time took: 0.8046727180480957\n",
      "Train loss Meta Info:  [1.41841850e+03 4.20730314e+01 4.26783125e-05]\n",
      "Val Loss Meta Info:  [56762.765, 38271.3, 0.0015078695118427277]\n",
      "\n",
      "Epoch: 161, NLL Loss: 1460.34913671875, Val Loss: 99245.359375, Time took: 0.8291430473327637\n",
      "Train loss Meta Info:  [1.41842326e+03 4.19258817e+01 4.07109126e-05]\n",
      "Val Loss Meta Info:  [56762.685, 42482.675, 0.0014358599483966826]\n",
      "\n",
      "Epoch: 162, NLL Loss: 1460.253265625, Val Loss: 97757.6171875, Time took: 0.8243165016174316\n",
      "Train loss Meta Info:  [1.41841017e+03 4.18430896e+01 3.89047709e-05]\n",
      "Val Loss Meta Info:  [56762.9, 40994.7175, 0.0013668344914913178]\n",
      "\n",
      "Epoch: 163, NLL Loss: 1460.2722578125, Val Loss: 87843.75, Time took: 0.8113021850585938\n",
      "Train loss Meta Info:  [1.41841938e+03 4.18528827e+01 3.70737080e-05]\n",
      "Val Loss Meta Info:  [56762.41, 31081.3425, 0.0012973441183567046]\n",
      "\n",
      "Epoch: 164, NLL Loss: 1460.36572265625, Val Loss: 116338.7890625, Time took: 0.7977886199951172\n",
      "Train loss Meta Info:  [1.41840909e+03 4.19566450e+01 3.51242278e-05]\n",
      "Val Loss Meta Info:  [56763.04, 59575.755, 0.0012388215959072114]\n",
      "\n",
      "Epoch: 165, NLL Loss: 1460.60438671875, Val Loss: 82497.8359375, Time took: 0.7889788150787354\n",
      "Train loss Meta Info:  [1.41840464e+03 4.21997465e+01 3.36025149e-05]\n",
      "Val Loss Meta Info:  [56763.25, 25734.575, 0.0011734689772129059]\n",
      "\n",
      "Epoch: 166, NLL Loss: 1461.27662109375, Val Loss: 128636.75, Time took: 0.7987933158874512\n",
      "Train loss Meta Info:  [1.41841388e+03 4.28627402e+01 3.16590279e-05]\n",
      "Val Loss Meta Info:  [56763.45, 71873.3, 0.0011275798082351685]\n",
      "\n",
      "Epoch: 167, NLL Loss: 1461.69301953125, Val Loss: 86720.1015625, Time took: 0.7982745170593262\n",
      "Train loss Meta Info:  [1.41841100e+03 4.32820182e+01 3.05682199e-05]\n",
      "Val Loss Meta Info:  [56762.6, 29957.4975, 0.0010710305720567704]\n",
      "\n",
      "Epoch: 168, NLL Loss: 1461.60443359375, Val Loss: 110795.9765625, Time took: 0.811377763748169\n",
      "Train loss Meta Info:  [1.41839638e+03 4.32080447e+01 2.88161180e-05]\n",
      "Val Loss Meta Info:  [56762.88, 54033.09, 0.001027662307024002]\n",
      "\n",
      "Epoch: 169, NLL Loss: 1460.37875, Val Loss: 113361.140625, Time took: 0.8604636192321777\n",
      "Train loss Meta Info:  [1.41839620e+03 4.19825609e+01 2.77987193e-05]\n",
      "Val Loss Meta Info:  [56763.33, 56597.82, 0.0009921632707118988]\n",
      "\n",
      "Epoch: 170, NLL Loss: 1460.7259296875, Val Loss: 97408.1796875, Time took: 0.8128540515899658\n",
      "Train loss Meta Info:  [1.41839126e+03 4.23346745e+01 2.69785942e-05]\n",
      "Val Loss Meta Info:  [56763.355, 40644.8225, 0.0009628155082464218]\n",
      "\n",
      "Epoch: 171, NLL Loss: 1460.9997890625, Val Loss: 103501.21875, Time took: 0.7959456443786621\n",
      "Train loss Meta Info:  [1.41839129e+03 4.26084638e+01 2.62104975e-05]\n",
      "Val Loss Meta Info:  [56762.99, 46738.215, 0.0009376154839992523]\n",
      "\n",
      "Epoch: 172, NLL Loss: 1460.3810078125, Val Loss: 115724.046875, Time took: 0.794041633605957\n",
      "Train loss Meta Info:  [1.41837616e+03 4.20048359e+01 2.57210846e-05]\n",
      "Val Loss Meta Info:  [56764.21, 58959.85, 0.0009093227237462997]\n",
      "\n",
      "Epoch: 173, NLL Loss: 1461.05261328125, Val Loss: 98056.7265625, Time took: 0.7982327938079834\n",
      "Train loss Meta Info:  [1.41839964e+03 4.26529694e+01 2.51489824e-05]\n",
      "Val Loss Meta Info:  [56763.455, 41293.27, 0.0008836568892002106]\n",
      "\n",
      "Epoch: 174, NLL Loss: 1460.58222265625, Val Loss: 98868.25, Time took: 0.7961876392364502\n",
      "Train loss Meta Info:  [1.41837825e+03 4.22039374e+01 2.43677554e-05]\n",
      "Val Loss Meta Info:  [56763.27, 42104.985, 0.0008607357740402222]\n",
      "\n",
      "Epoch: 175, NLL Loss: 1460.50776171875, Val Loss: 118449.2109375, Time took: 0.7913126945495605\n",
      "Train loss Meta Info:  [1.41837940e+03 4.21283429e+01 2.38114026e-05]\n",
      "Val Loss Meta Info:  [56763.57, 61685.64, 0.0008446703851222992]\n",
      "\n",
      "Epoch: 176, NLL Loss: 1460.80603515625, Val Loss: 96736.6171875, Time took: 0.7949936389923096\n",
      "Train loss Meta Info:  [1.41837606e+03 4.24299680e+01 2.35973281e-05]\n",
      "Val Loss Meta Info:  [56763.6, 39973.02, 0.0008382702618837356]\n",
      "\n",
      "Epoch: 177, NLL Loss: 1460.22671484375, Val Loss: 89384.046875, Time took: 0.7905769348144531\n",
      "Train loss Meta Info:  [1.41836548e+03 4.18612344e+01 2.34390852e-05]\n",
      "Val Loss Meta Info:  [56763.39, 32620.66, 0.0008325479924678802]\n",
      "\n",
      "Epoch: 178, NLL Loss: 1460.4321171875, Val Loss: 107744.28125, Time took: 0.7921528816223145\n",
      "Train loss Meta Info:  [1.41836228e+03 4.20698660e+01 2.33725231e-05]\n",
      "Val Loss Meta Info:  [56764.23, 50980.045, 0.0008264786005020142]\n",
      "\n",
      "Epoch: 179, NLL Loss: 1460.6471953125, Val Loss: 87661.859375, Time took: 0.7986485958099365\n",
      "Train loss Meta Info:  [1.41836299e+03 4.22841981e+01 2.33836255e-05]\n",
      "Val Loss Meta Info:  [56764.1, 30897.755, 0.0008118028193712235]\n",
      "\n",
      "Epoch: 180, NLL Loss: 1460.24863671875, Val Loss: 89894.8671875, Time took: 0.7948293685913086\n",
      "Train loss Meta Info:  [1.41835833e+03 4.18902877e+01 2.28819838e-05]\n",
      "Val Loss Meta Info:  [56763.91, 33130.96, 0.0008001868426799774]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181, NLL Loss: 1460.1328828125, Val Loss: 105614.28125, Time took: 0.8182809352874756\n",
      "Train loss Meta Info:  [1.41835580e+03 4.17770632e+01 2.25267973e-05]\n",
      "Val Loss Meta Info:  [56764.64, 48849.66, 0.0007879181206226349]\n",
      "\n",
      "Epoch: 182, NLL Loss: 1460.454734375, Val Loss: 84346.578125, Time took: 0.8206558227539062\n",
      "Train loss Meta Info:  [1.41836198e+03 4.20927329e+01 2.22260865e-05]\n",
      "Val Loss Meta Info:  [56764.27, 27582.305, 0.0007685727626085281]\n",
      "\n",
      "Epoch: 183, NLL Loss: 1460.49633984375, Val Loss: 103949.5546875, Time took: 0.7859094142913818\n",
      "Train loss Meta Info:  [1.41835362e+03 4.21427414e+01 2.16277951e-05]\n",
      "Val Loss Meta Info:  [56764.09, 47185.465, 0.0007667206972837448]\n",
      "\n",
      "Epoch: 184, NLL Loss: 1460.11751953125, Val Loss: 95732.8984375, Time took: 0.787747859954834\n",
      "Train loss Meta Info:  [1.41834431e+03 4.17732163e+01 2.16699491e-05]\n",
      "Val Loss Meta Info:  [56764.13, 38968.76, 0.000762847512960434]\n",
      "\n",
      "Epoch: 185, NLL Loss: 1460.01125, Val Loss: 84505.3203125, Time took: 0.8196208477020264\n",
      "Train loss Meta Info:  [1.41834327e+03 4.16679661e+01 2.15792647e-05]\n",
      "Val Loss Meta Info:  [56764.04, 27741.2675, 0.0007533396780490875]\n",
      "\n",
      "Epoch: 186, NLL Loss: 1460.2718125, Val Loss: 119805.125, Time took: 0.8056836128234863\n",
      "Train loss Meta Info:  [1.41833646e+03 4.19353599e+01 2.12895815e-05]\n",
      "Val Loss Meta Info:  [56764.72, 63040.41, 0.0007629299908876419]\n",
      "\n",
      "Epoch: 187, NLL Loss: 1460.82760546875, Val Loss: 81688.0390625, Time took: 0.8031468391418457\n",
      "Train loss Meta Info:  [1.41834371e+03 4.24838875e+01 2.15787849e-05]\n",
      "Val Loss Meta Info:  [56764.65, 24923.3825, 0.0007335470616817475]\n",
      "\n",
      "Epoch: 188, NLL Loss: 1461.23983203125, Val Loss: 112775.15625, Time took: 0.819056510925293\n",
      "Train loss Meta Info:  [1.41834226e+03 4.28975401e+01 2.06169962e-05]\n",
      "Val Loss Meta Info:  [56765.01, 56010.15, 0.0007465294003486633]\n",
      "\n",
      "Epoch: 189, NLL Loss: 1460.3889921875, Val Loss: 106884.296875, Time took: 0.8126957416534424\n",
      "Train loss Meta Info:  [1.41833929e+03 4.20497092e+01 2.10257425e-05]\n",
      "Val Loss Meta Info:  [56764.945, 50119.345, 0.0007450753450393677]\n",
      "\n",
      "Epoch: 190, NLL Loss: 1460.1181015625, Val Loss: 99273.296875, Time took: 0.8311388492584229\n",
      "Train loss Meta Info:  [1.41833715e+03 4.17809534e+01 2.09474091e-05]\n",
      "Val Loss Meta Info:  [56764.88, 42508.415, 0.0007571837306022644]\n",
      "\n",
      "Epoch: 191, NLL Loss: 1460.5761875, Val Loss: 107090.7578125, Time took: 0.8179736137390137\n",
      "Train loss Meta Info:  [1.41833579e+03 4.22404081e+01 2.11883177e-05]\n",
      "Val Loss Meta Info:  [56764.85, 50325.91, 0.0007815851271152496]\n",
      "\n",
      "Epoch: 192, NLL Loss: 1460.17965625, Val Loss: 105063.875, Time took: 0.8324921131134033\n",
      "Train loss Meta Info:  [1.41832785e+03 4.18518390e+01 2.19594585e-05]\n",
      "Val Loss Meta Info:  [56764.7, 48299.17, 0.0008077540248632431]\n",
      "\n",
      "Epoch: 193, NLL Loss: 1460.125546875, Val Loss: 98998.515625, Time took: 0.8160035610198975\n",
      "Train loss Meta Info:  [1.41832483e+03 4.18007066e+01 2.26408710e-05]\n",
      "Val Loss Meta Info:  [56765.115, 42233.4, 0.0008273199945688247]\n",
      "\n",
      "Epoch: 194, NLL Loss: 1460.40077734375, Val Loss: 108052.1953125, Time took: 0.8250086307525635\n",
      "Train loss Meta Info:  [1.41832305e+03 4.20777311e+01 2.30152022e-05]\n",
      "Val Loss Meta Info:  [56765.525, 51286.67, 0.0008393774926662445]\n",
      "\n",
      "Epoch: 195, NLL Loss: 1460.03946484375, Val Loss: 106275.046875, Time took: 0.7954778671264648\n",
      "Train loss Meta Info:  [1.41832275e+03 4.17167173e+01 2.33942654e-05]\n",
      "Val Loss Meta Info:  [56765.315, 49509.75, 0.000849732756614685]\n",
      "\n",
      "Epoch: 196, NLL Loss: 1459.96308984375, Val Loss: 81363.1171875, Time took: 0.8087203502655029\n",
      "Train loss Meta Info:  [1.41831618e+03 4.16468865e+01 2.36284561e-05]\n",
      "Val Loss Meta Info:  [56765.1, 24598.01, 0.0008730859309434891]\n",
      "\n",
      "Epoch: 197, NLL Loss: 1460.29258203125, Val Loss: 102286.5390625, Time took: 0.8148601055145264\n",
      "Train loss Meta Info:  [1.41831752e+03 4.19750544e+01 2.41366758e-05]\n",
      "Val Loss Meta Info:  [56765.85, 45520.675, 0.0009005376696586609]\n",
      "\n",
      "Epoch: 198, NLL Loss: 1460.352671875, Val Loss: 79478.8125, Time took: 0.8281581401824951\n",
      "Train loss Meta Info:  [1.41831928e+03 4.20334117e+01 2.49939543e-05]\n",
      "Val Loss Meta Info:  [56765.645, 22713.1675, 0.0009162931144237518]\n",
      "\n",
      "Epoch: 199, NLL Loss: 1460.2400546875, Val Loss: 92160.796875, Time took: 0.8079607486724854\n",
      "Train loss Meta Info:  [1.41831297e+03 4.19270845e+01 2.52277787e-05]\n",
      "Val Loss Meta Info:  [56766.125, 35394.6725, 0.0009328173100948333]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=hrmtpp, data=data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
